<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[command_pattern]]></title>
    <url>%2F2018%2F11%2F19%2Fcommand-pattern%2F</url>
    <content type="text"><![CDATA[命令模式 Ebcapsulate a request as an object, thereby letting you parameterize clients with different requests, queue or log requests, and support undoable operations.将一个请求封装成一个对象, 从而让你使用不同的请求把客户端参数化, 对请求排队或者记录请求日志, 可以提供命令的撤销和恢复功能 通用的命令模式类图 通用类图 命令模式中的角色Receive接收者角色实际执行操作的角色 Command命令角色需要执行的命令都在这里 Invoker调用者角色接受命令, 执行命令 通用代码123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172// 通用Receiverpublic abstract class Receiver &#123; // 抽象接受者, 每个接收者都必须完成的任务 public abstract void doSomething();&#125;// 具体的Receiverpublic class ConcreteReceiver1 extends Receiver &#123; // 每个接收者必须处理一定的业务逻辑 public void doSomething() &#123; &#125;&#125;// 具体的Receiverpublic class ConcreteReceiver2 extends Receiver &#123; // 每个接收者必须处理一定的业务逻辑 public void doSomething() &#123; &#125;&#125;// 抽象的Commandpublic abstract class Command &#123; // 每一个命令类都必须有一个执行命令的方法 public abstract void execute();&#125;// 具体的Command类, 可以有多个public class ConcretCommand1 extends Command &#123; // 对哪个Receiver进行命令处理 private Receiver receiver; // 构造函数传递接收者 public ConcretCommand1(Receiver receiver) &#123; this.receiver = receiver; &#125; // 实现命令 public void execute() &#123; // 业务处理 this.receiver.doSomething(); &#125;&#125;// 调用者Invokerpublic class Invoker &#123; private Command command; // 传入命令 public void setCommand(Command command) &#123; this.command = command; &#125; // 执行命令 public void action() &#123; this.command.execute(); &#125;&#125;// 场景类public class Client &#123; public static void main(String... args) &#123; // 声明invoker Invoker invoker = new Invoker(); // 定义接收者 Receiver receiver = new ConcreteReceiver(); // 定义发送给接收者的命令 Command command = new ConcreteCommand1(receiver); // 把命令交给调用者去执行 invoker.setCommand(command); invoker.action(); &#125;&#125; 开发项目的例子 类图demo类图 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230/** * 抽象组 * @author zonzie * @date 2018/11/19 12:43 PM */public abstract class Group &#123; //找到group public abstract void find(); // 增加功能 abstract void add(); // 删除功能 abstract void delete(); // 修改功能 abstract void change(); // 给出所有的变更计划 abstract void plan();&#125;/** * 代码组 * @author zonzie * @date 2018/11/19 12:54 PM */public class CodeGroup extends Group &#123; @Override public void find() &#123; System.out.println("找到代码组"); &#125; @Override void add() &#123; System.out.println("添加功能"); &#125; @Override void delete() &#123; System.out.println("删除功能"); &#125; @Override void change() &#123; System.out.println("修改功能"); &#125; @Override void plan() &#123; System.out.println("代码变更计划"); &#125;&#125;/** * 需求组 * @author zonzie * @date 2018/11/19 12:49 PM */public class RequirementGroup extends Group &#123; /** * 找到需求组 */ @Override public void find() &#123; System.out.println("找到需求组"); &#125; @Override void add() &#123; System.out.println("增加一项需求"); &#125; @Override void delete() &#123; System.out.println("修改需求"); &#125; @Override void change() &#123; System.out.println("修改需求"); &#125; @Override void plan() &#123; System.out.println("需求变更计划"); &#125;&#125;/** * 美工组 * @author zonzie * @date 2018/11/19 12:52 PM */public class PageGroup extends Group &#123; @Override public void find() &#123; System.out.println("找到美工组"); &#125; @Override void add() &#123; System.out.println("增加一个页面"); &#125; @Override void delete() &#123; System.out.println("删除页面"); &#125; @Override void change() &#123; System.out.println("修改页面"); &#125; @Override void plan() &#123; System.out.println("页面变更计划"); &#125;&#125;/** * 抽象命令类 * @author zonzie * @date 2018/11/19 1:39 PM */public abstract class Command &#123; // 定义好, 子类可以直接使用 /** * 需求 */ protected RequirementGroup rg = new RequirementGroup(); /** * 美工 */ protected PageGroup pg = new PageGroup(); /** * 代码 */ protected CodeGroup cg = new CodeGroup(); /** * 执行命令的方法 */ public abstract void execute();&#125;/** * 添加需求的命令 * @author zonzie * @date 2018/11/19 1:44 PM */public class AddRequirementCommond extends Command &#123; @Override public void execute() &#123; super.pg.find(); super.pg.add(); super.pg.plan(); &#125;&#125;/** * 删除页面的命令 * @author zonzie * @date 2018/11/19 1:47 PM */public class DeletePageCommand extends Command &#123; @Override public void execute() &#123; pg.find(); pg.delete(); pg.plan(); &#125;&#125;/** * 负责人类 * @author zonzie * @date 2018/11/19 1:48 PM */public class Invoker &#123; /** * 要执行的命令 */ private Command command; public void setCommand(Command command) &#123; this.command = command; &#125; /** * 执行客户的命令 */ public void action() &#123; this.command.execute(); &#125;&#125;/** * 场景类 * @author zonzie * @date 2018/11/19 1:51 PM */public class Client &#123; public static void main(String[] args) &#123; // 定义负责人 Invoker invoker = new Invoker(); // 增加一项需求 System.out.println("增加一项需求...."); // 命令 AddRequirementCommond addRequirementCommond = new AddRequirementCommond(); // 负责人收到命令 invoker.setCommand(addRequirementCommond); // 执行命令 invoker.action(); &#125;&#125; 命令模式的优点 类间解耦调用者和接收者之间没有任何依赖关系, 调用者实现功能只需要调用Command抽象类的execute方法, 不需要了解是哪个接收者 可扩展性Command的子类可以非常容易的扩展, 调用者Invoker和高层次的模块Client不产生严重的代码耦合 结合其他模式可以结合责任链模式, 实现命令族的解析任务, 结合模板方法模式, 可以减少Command子类的膨胀问题 缺点命令越多, Command子类就会越来越多 使用场景是命令的地方就可以使用命令模式]]></content>
      <categories>
        <category>design pattern</category>
      </categories>
      <tags>
        <tag>design pattern</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[elasticSearch操作笔记]]></title>
    <url>%2F2018%2F09%2F18%2FelasticSearch-operation-note%2F</url>
    <content type="text"><![CDATA[es中的一些基本概念Near RealTime(NRT近实时)elasticSearch是一个近实时的搜索平台, 从索引一个文档开始直到它可以被查询会有轻微的延迟 cluster(集群)cluster是一个或者多个节点的集合, 它们一起保存数据并且提供所有的节点联合索引以及搜索功能. 集群存在一个唯一的名字身份且默认为”elasticSearch”. 这个名字很重要, 如果节点安装时, 通过自己的名字加入到集群中的话, 那么一个节点只能是一个集群的一部分 Node(节点)节点是一个单独的服务器, 是集群的一部分, 存储数据, 参与集群中的索引和搜索功能, 节点可以单独运行, 形成单节点集群 index(索引)index是具有稍微类似特征文档的集合. 比如一个消费者数据的索引, 产品目录的索引, 订单数据的索引. 索引通过名字(小写)来标识, 并且名字在对document(文档)执行indexing(索引), search(搜索), update(更新), delete(删除)操作时会涉及到. 一个单独的集群中, 可以定义想要的索引 Type(类型)在index(索引)中, 可以定义一个或者多个类型. 一个类型是索引中的一个逻辑的种类/分区,语义完全取决于自己. 一般情况下, 一个类型被定义成一组常见的文档. 假设我们在一个单独的索引中存储了一个博客平台的所有数据, 在这个索引中, 可能定义了一个用户数据类, 博客数据类型和评论数据类型 Document(文档)document是索引信息的基本单位. 例如存储customer数据的文档,存储product数据的文档,存储order数据的文档 Shards &amp; Replicas (分片 &amp; 副本)索引可以存储大量的数据, 可以超过单个节点的硬件限制. 为了解决这个问题, elasticSearch提供了把index(索引)拆分到多个Shard(分片)中的能力. 在创建索引时, 可以简单的定义Shard(分片)的数量. 每个Shard本身就是一个fully-functional(全功能的)和独立的”index”, Shard可以存储到集群中的任何节点 Sharding(分片) 非常重要的理由: 水平的拆分/扩展 分布式的并行跨Shard操作(可能在多个节点), 从而提高了性能/吞吐量每个索引可以被拆分成多个分片, 一个索引可以0个或者多个副本,开启副本后, 将会有主分片和副本分片,分片和副本的数量可以在索引被创建时指定,也可以在任何时候修改副本的数量, 但是不能修改分片的数量默认情况下, es中的每个索引分配了5个主分片和1个副本,如果集群中有两个节点, 则会有5个主分片和5个副本分片 基本的一些命令查看集群的健康程度curl -XGET &#39;localhost:9200/_cat/health?v&amp;pretty&#39; 获取集群节点的列表curl -XGET &#39;localhost:9200/_cat/nodes?v&amp;pretty&#39; 列出所有的索引curl -XGET &#39;localhost:9200/_cat/indices?v&amp;pretty&#39; 创建索引customercurl -XPUT &#39;localhost:9200/customer?pretty&amp;pretty&#39; 创建一个customer文档到customer索引中, ‘external’类型, ID为11234curl -H "Content-Type:application/json" -XPUT 'localhost:9200/customer/external/1?pretty&amp;pretty' -d `&#123; "name": "john doe"&#125;` 删除索引curl -XDELETE &#39;localhost:9200/customer?pretty&amp;pretty&#39; 不指定id可以用POST请求创建一个新的文档,id会自动生成1234curl -H "Content-Type:application/json" -XPOST 'localhost:9200/customer/external?pretty&amp;pretty' -d'&#123; "name": "John Doe"&#125;` 更新文档使用POST方法,修改name,添加age字段1234567curl -H "Content-Type:application/json" -XPOST 'localhost:9200/customer/external/1/_update?pretty&amp;pretty' -d ' "doc": &#123; "name": "Jane Doe", "age": 20 &#125;&#125;' 使用PUT方法,修改name,添加age字段1234curl -H "Content-Type:application/json" -XPUT 'localhost:9200/customer/external/1/_update?pretty&amp;pretty' -d '&#123; "name": "james Doe"&#125;' 使用脚本更新年龄1234curl -H "Content-Type:application/json" -XPOST 'localhost:9200/customer/external/1/_udpate?pretty&amp;pretty' -d '&#123; "script": "ctx._source.age += 5"&#125;' 删除文档1curl -XDELETE &apos;localhost:9200/customer/external/2?pretty&amp;pretty&apos; 批量操作批量插入数据123456curl -H "Content-Type:application/json" -XPOST '192.168.198.88:9200/customer/external/_bulk?pretty&amp;pretty' -d '&#123;"index": &#123;"_id": "5"&#125;&#125;&#123;"name": "john dow"&#125;&#123;"index": &#123;"_id": "6"&#125;&#125;&#123;"name": "jane wick"&#125;' 批量更新数据123456curl -H "Content-Type:application/json" -XPUT '192.168.198.88:9200/customer/external/_bulk?pretty&amp;pretty' -d '&#123;"index": &#123;"_id": "5"&#125;&#125;&#123;"name": "john dow"&#125;&#123;"index": &#123;"_id": "6"&#125;&#125;&#123;"name": "jane wick"&#125;' 更新id=5的文档, 删除id=6的文档12345curl -H "Content-Type:application/json" -XPOST '192.168.198.88:9200/customer/external/_bulk?pretty&amp;pretty' -d '&#123;"update": &#123;"_id":"5"&#125;&#125;&#123;"doc": &#123;"name": "John doe becomes Jane Doe"&#125;&#125;&#123;"delete": &#123;"_id":"6"&#125;&#125;' 数据探索部分使用REST reqeust URI发送搜索参数查询index为customer下的所有的文档1curl -XGET 'localhost:9200/customer/_search?pretty' 使用REST request body发送请求, 使用POST或者GET, 一般浏览器会默认抛弃掉GET请求的请求体, 使用POST比较保险1234curl -H "Content-Type:application/json" -XPOST 'localhost:9200/customer/_search?pretty' -d '&#123; "query": &#123;"match_all": &#123;&#125;&#125;&#125;' 返回的数据主要有以下几部分: took: es执行搜索的耗时(ms) time_out: 搜索是否超时 _shards: 告诉我们搜索了多少分片,统计了成功/失败的分片 hits: 搜索的结果 hits.hits: 实际的搜索结果数组(默认为前10的文档) sort: 结果的排序key(没有则按照score排序) score DSL(Domain-Specific Language, 领域特定语言)elasticSearch提供了可执行查询的Json风格的DSL. 这个查询语言非常全面,我们从基础开始查询customer中的一条数据123456curl -H "Content-Type:application/json" -XGET '192.168.198.88:9200/customer/_search?pretty' -d '&#123; "query": &#123; "match_all": &#123;&#125; &#125;&#125;' 添加查询的分页,from:指定文档开始的编号,size:返回的条数,sort:指定排序的字段和规则1234567891011curl -H "Content-Type:application/json" -XGET 'localhost:9200/customer/_search?pretty' -d '&#123; "query": &#123;"match_all": &#123;&#125;&#125;, "from": 10, "size": 10, "sort": &#123; "age": &#123; "order": "desc" &#125; &#125;&#125;' 返回指定字段name和age1234567curl -H "Content-Type:application/json" -XGET 'localhost:9200/customer/_search?pretty' -d '&#123; "query": &#123; "match_all": &#123;&#125; &#125; "_source": ["name", "age"]&#125;' 返回年龄为20的customer12345678curl -H "Content-Type:application/json" -XGET 'localhost:9200/customer/_search?pretty' -d '&#123; "query": &#123; "match": &#123; "age": 20 &#125; &#125;&#125;' 返回所有name中包含john的customer, 不是精确匹配1234567curl -H "Content-Type:application/json" -XGET 'localhost:9200/customer/_search?pretty' -d '&#123; "query": &#123; "match": &#123; "name": "john" &#125; &#125;&#125;' 精确匹配一个单词或者短语12345curl -H "Content-Type:application/json" -XGET 'localhost:9200/customer/_search?pretty' -d '&#123; "query": &#123;"match_phrase": &#123; "name": "john" &#125;&#125;&#125;' bool查询使用boolean逻辑构建较小的查询到更大的查询中去返回name中同时包含john和jane的文档12345678910curl -H "Contetn-Type:application/json" -XGET 'localhost:9200/customer/_search?pretty' -d ' "query": &#123; "bool": &#123; "must": [ &#123;"match": &#123;"name": "john"&#125;&#125;, &#123;"match": &#123;"name": "jane"&#125;&#125; ] &#125; &#125;&#125;' 上面的例子中, bool must 语句指定了所有的查询必须为true时匹配到的文档如果两个名字是或的关系,例子如下12345678910curl -H "Contetn-Type:application/json" -XGET 'localhost:9200/customer/_search?pretty' -d '&#123; "query": &#123; "bool": &#123; "should": [ &#123;"match": &#123;"name": "john"&#125;&#125;, &#123;"match": &#123;"name": "jane"&#125;&#125; ] &#125; &#125;&#125;' bool should中只要有一个为true就会匹配到如果两者都不想匹配到12345678910curl -H "Content-Type:application/json" -XGET 'localhost:9200/customer/_search?pretty' -d '&#123; "query": &#123; "bool": &#123; "must_not": [ &#123;"match": &#123;"name": "john"&#125;&#125;, &#123;"match": &#123;"name": "jane"&#125;&#125; ] &#125; &#125;&#125;' 以上如果条件都不为true才会匹配到文档我们可以在bool查询中同时联合使用must, should, must_not123456789101112curl -H "Content-Type:application/json" -XGET 'localhost:9200/customer/_search?pretty' -d '&#123; "query": &#123; "bool": &#123; "must": [ &#123;"match": &#123;"age": 40&#125;&#125; ], "must_not": [ &#123;"match": &#123;"name": "jane"&#125;&#125; ] &#125; &#125;&#125;' 过滤查询]]></content>
      <categories>
        <category>elasticSearch</category>
      </categories>
      <tags>
        <tag>elasticSearch</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[缓存系统的问题]]></title>
    <url>%2F2018%2F09%2F17%2Fcache-problem%2F</url>
    <content type="text"><![CDATA[高并发系统中缓存可能会遇到的问题 缓存穿透 缓存雪崩 缓存击穿 缓存穿透 查询一个一定不存在的key, 由于缓存是没有命中时被动写入的, 一般查不到这个key就不写入缓存, 这将导致不存在的key每次请求都会到达持久层去查询, 在流量大时, 对系统性能会有影响, 可能导致数据库崩溃 解决方案: 使用布隆过滤器,计算所有的可能的key的多种hash值,存入位数组中,一个一定不存在的key会直接被拦截掉, 从而避免了请求到达持久层, 占用数据库资源 将value为空的key也存入缓存,可以设置较短的过期时间 缓存雪崩 指的是缓存中的数据在同一个时间一起失效, 导致大量的请求直接到达数据库层面, 导致数据库直接崩溃 解决方案: 在缓存失效时, 对访问数据库的操作加锁,只允许单个线程访问数据库中的同一条数据 在设置缓存失效时间时, 加一个随机数, 错开所有的缓存的失效时间, 避免集体失效事件 缓存击穿 某些热点数据在某些时间被超高并发的访问, 此时缓存失效, 同样会导致大量的请求涌向数据库, 在重建缓存未完成时, db瞬间被大量的请求压垮 解决方案: 同一条数据在同一时间只允许单个线程访问数据库 在即将过期之前更新缓存 设置服务降级 以lettuce为例解决redis缓存击穿问题:lettuce的jar包:1234567&lt;dependencies&gt; &lt;dependency&gt; &lt;groupid&gt;biz.paluch.redis&lt;/groupid&gt; &lt;artifactid&gt;lettuce&lt;/artifactid&gt; &lt;version&gt;5.0.0.beta1&lt;/version&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 代码实现:123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105import com.lambdaworks.redis.*;import com.lambdaworks.redis.api.statefulredisconnection;import com.lambdaworks.redis.api.async.redisasynccommands;import com.lambdaworks.redis.api.sync.rediscommands;import java.util.concurrent.arrayblockingqueue;import java.util.concurrent.executionexception;import java.util.concurrent.threadpoolexecutor;import java.util.concurrent.timeunit;/** * @author zonzie * @date 2018/8/10 17:25 */public class lettuceclient &#123; // lettuce connection对象 private static statefulredisconnection&lt;string, string&gt; connection; // 线程池 private static threadpoolexecutor poolexecutor; // 互斥锁的key private static final string mutex_key = "mutex_key"; static &#123; // 初始化connection redisclient client = redisclient.create(redisuri.create("redis://192.168.198.128:6379")); connection = client.connect(); // 初始化线程池 poolexecutor = new threadpoolexecutor(5, 10, 200, timeunit.seconds, new arrayblockingqueue&lt;runnable&gt;(5), new threadpoolexecutor.discardoldestpolicy()); &#125; /** * 解决缓存击穿问题, 方法一 * 为了解决缓存击穿的问题, 业界常用的做法--设置mutex key * @param key 互斥锁的key */ public string mutexget(string key) throws interruptedexception &#123; rediscommands&lt;string, string&gt; sync = connection.sync(); string value = sync.get(key); if(value == null) &#123; string set = sync.set(mutex_key, "1", setargs.builder.nx().px(3 * 60)); if("ok".equalsignorecase(set)) &#123; // 从数据库获取value value = "getvaluebykey"; sync.set(key, value, setargs.builder.px(1000 * 60 * 60 * 2)); sync.del(mutex_key); return value; &#125; else &#123; thread.sleep(50); // 递归重试 mutexget(key); &#125; &#125; return value; &#125; /** * 解决缓存击穿的问题,方法二 * 提前更新key * @param key */ public string get(final string key) throws interruptedexception &#123; final rediscommands&lt;string, string&gt; sync = connection.sync(); string value = sync.get(key); long ttl = sync.ttl(key); // 如果key已经过期,立即从数据库获取新的value if(value == null) &#123; string set = sync.set(mutex_key, "1", setargs.builder.nx().px(3 * 60)); if("ok".equalsignorecase(set)) &#123; // 从数据库获取value string var = "getvaluebykeyfromdb"; sync.set(key, var, setargs.builder.px(1000 * 60 * 60 * 2)); sync.del(mutex_key); // 返回新的值 return var; &#125; else &#123; thread.sleep(50); // 递归重试 get(key); &#125; &#125; // 如果10秒后key过期 if(ttl &lt; 10) &#123; // 异步执行缓存更新操作 poolexecutor.execute(new runnable() &#123; public void run() &#123; // 设置互斥锁 string set = sync.set(mutex_key, "1", setargs.builder.nx().px(3 * 60)); if("ok".equalsignorecase(set)) &#123; // 从数据库获取value string var = "getvaluebykeyfromdb"; // 设置新的value sync.setex(key, 2*60*60, var); // 删除互斥锁 sync.del(mutex_key); &#125; &#125; &#125;); // 返回旧的值 return value; &#125; return value; &#125;&#125; 参考内容: 缓存中的热点key的问题]]></content>
      <categories>
        <category>redis</category>
      </categories>
      <tags>
        <tag>redis</tag>
        <tag>cache</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[中介者模式]]></title>
    <url>%2F2018%2F09%2F11%2Fmediator-pattern%2F</url>
    <content type="text"><![CDATA[定义 Define an object that encapsulates how a set of objects interact. Mediator Promotes loose coupling by keeping objects from referring to each other explicitly, and it lets you vary their interation independently.用一个中介对象封装一系列的对象交互,中介者使各个对象不需要显式的相互作用, 从而使其耦合松散, 而且可以独立的改变他们的交互 一个不使用中介者模式的进销存的例子这个例子中, 我们简单创建几个部分: 采购管理, 销售管理, 库存管理部分,实现货物的基本的采购,销售,库存管理的功能采购管理部分:12345678910111213141516171819202122232425262728/** * 采购管理 * @author zonzie * @date 2018/9/10 18:58 */public class Purchase &#123; /** 采购IBM电脑 */ public void buyIBMComputer(int number) &#123; // 访问库存 Stock stock = new Stock(); // 访问销售 Sale sale = new Sale(); // 电脑的销售情况 int saleStatus = sale.getSaleStatus(); if(saleStatus &gt; 80) &#123; System.out.println("采购电脑: " + number + "台"); &#125; else &#123; // 销售情况不好 int buyNumber = number / 2; System.out.println("采购IBM电脑: " + buyNumber + "台"); &#125; &#125; /** 不再采购 */ public void refuseBuyIBM() &#123; System.out.println("不再采购IBM电脑"); &#125;&#125; 销售管理:12345678910111213141516171819202122232425262728293031323334/** * 销售管理 * @author zonzie * @date 2018/9/10 19:06 */public class Sale &#123; /** 销售IBM电脑 */ public void sellIBMComputer(int number) &#123; // 访问库存 Stock stock = new Stock(); // 访问采购 Purchase purchase = new Purchase(); if(stock.getStockNumber() &lt; number) &#123; purchase.buyIBMComputer(number); &#125; System.out.println("销售IBM电脑" + number + "台"); stock.decrease(number); &#125; /** 反馈销售情况 */ public int getSaleStatus() &#123; Random random = new Random(System.currentTimeMillis()); int saleStatus = random.nextInt(100); System.out.println("IBM电脑的销售情况是: " + saleStatus); return saleStatus; &#125; /** 折价处理 */ public void offSale() &#123; Stock stock = new Stock(); System.out.println("电脑折价销售: " + stock.getStockNumber() + "台"); &#125;&#125; 库存管理:12345678910111213141516171819202122232425262728293031323334353637/** * 库存管理 * @author zonzie * @date 2018/9/10 19:00 */public class Stock &#123; /** 100台电脑 */ private static int COMPUTER_NUMBER = 100; /** 库存增加 */ public void increase(int number) &#123; COMPUTER_NUMBER += number; System.out.println("库存数量为: " + COMPUTER_NUMBER); &#125; /** 库存减少 */ public void decrease(int number) &#123; COMPUTER_NUMBER -= number; System.out.println("库存数量为: " + COMPUTER_NUMBER); &#125; /** 获得库存数量 */ public int getStockNumber() &#123; return COMPUTER_NUMBER; &#125; /** 存货压力增大, 清库存 */ public void clearStock() &#123; Purchase purchase = new Purchase(); Sale sale = new Sale(); System.out.println("清理库存数量: " + COMPUTER_NUMBER); // 要求折价销售 sale.offSale(); // 要求采购人员不要采购 purchase.refuseBuyIBM(); &#125;&#125; 场景类:12345678910111213141516171819202122/** * 场景类 * @author zonzie * @date 2018/9/10 19:36 */public class Client &#123; public static void main(String[] args) &#123; // 采购人员采购电脑 System.out.println("采购人员采购电脑"); Purchase purchase = new Purchase(); purchase.buyIBMComputer(100); // 销售电脑 System.out.println("销售电脑"); Sale sale = new Sale(); sale.sellIBMComputer(1); // 库存扣减 System.out.println("清理库存"); Stock stock = new Stock(); stock.clearStock(); &#125;&#125; 在这个例子中, 三个对象之间互相调用, 每个部分要实现功能都必须依赖其他的部分完成,如果再加入物流,资产等管理模块, 代码整体会更加的复杂, 维护成本将越来越大这里, 引入中介者的概念, 不同模块之间, 只处理自己的逻辑, 其余部分交给中介者去管理各个部分之间的复杂关系: 中介者模式(也叫调停者模式)中的组成部分 Mediator 抽象中介者角色, 定义统一的接口, 用于各同事角色之间的通信 Concrete Mediator 具体中介者角色, 协调各同事角色实现协作行为, 必须依赖各个同事角色 Colleague 同事角色, 每个同事角色,都知道中介者的角色, 而且, 在需要与其他同事角色交互时, 必须通过中介者与其他角色交互,同事类的行为分为两种: 自发行为: 同事自身的行为, 比如, 改变对象自身的状态, 处理自身的行为 依赖方法: 依赖中介者才能完成的行为 使用中介者模式的进销存的例子抽象的中介者:1234567891011121314151617181920/** * 抽象的中介者 * @author zonzie * @date 2018/9/10 19:47 */public abstract class AbstractMediator &#123; protected Purchase purchase; protected Sale sale; protected Stock stock; // 使用构造函数注入同事类, 这里如果不是必须的同事类, 可以使用setter/getter注入 public AbstractMediator() &#123; this.purchase = new Purchase(this); this.sale = new Sale(this); this.stock = new Stock(this); &#125; // 中介者最重要的方法, 处理多个对象之间的关系 public abstract void execute(String str, Object... objects);&#125; 在抽象类Mediator中只定义了同事类的注入, 为什么使用同事类注入, 而不使用同事类的实现类注入呢? 那是因为同事类虽然有抽象, 但是没有每个同事类必须要完成的业务方法, 当然, 如果每个同事类都有相同的方法, 比如execute, handler, 当然要注入抽象类, 做到依赖倒置 具体的中介者,一般只有一个:123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657/** * 中介者 * @author zonzie * @date 2018/9/10 20:08 */public class Mediator extends AbstractMediator &#123; @Override public void execute(String str, Object... objects) &#123; // 采购电脑 if("purchase.buy".equals(str)) &#123; this.buyComputer((Integer) objects[0]); // 销售电脑 &#125; else if("sale.sell".equals(str)) &#123; this.sellComputer((Integer) objects[0]); // 折价销售 &#125; else if("sale.offset".equals(str)) &#123; this.offSail(); // 出清 &#125; else if("stock.clear".equals(str)) &#123; this.clearStock(); &#125; &#125; /** 采购电脑 */ private void buyComputer(int number) &#123; int saleStatus = super.sale.getSaleStatus(); if(saleStatus &gt; 80) &#123; System.out.println("采购IBM电脑" + number + "台"); super.stock.increase(number); &#125; else &#123; int buyNumber = number / 2; // 折半采购 System.out.println("采购IBM电脑" + buyNumber + "台"); &#125; &#125; /** 销售电脑 */ public void sellComputer(int number) &#123; if(super.stock.getStockNumber() &lt; number) &#123; // 库存数量不够销售 super.purchase.buyIBMComputer(number); &#125; super.stock.decrease(number); &#125; /** 折价销售电脑 */ public void offSail() &#123; System.out.println("折价销售IBM电脑" + stock.getStockNumber() + "台"); &#125; /** 清仓处理 */ private void clearStock() &#123; // 要求清仓销售 super.sale.offSale(); // 要求采购人员不要采购 super.purchase.refuseBuyIBM(); &#125;&#125; 抽象的同事类:123456789101112/** * 抽象的同事类 * @author zonzie * @date 2018/9/10 19:58 */public abstract class AbstractColleague &#123; protected AbstractMediator mediator; public AbstractColleague(AbstractMediator mediator) &#123; this.mediator = mediator; &#125;&#125; 采购管理:123456789101112131415161718192021/** * 修改后的采购管理 * @author zonzie * @date 2018/9/10 19:56 */public class Purchase extends AbstractColleague &#123; public Purchase(AbstractMediator mediator) &#123; super(mediator); &#125; // 采购电脑 public void buyIBMComputer(int number) &#123; super.mediator.execute("purchase.buy", number); &#125; // 不再采购电脑 public void refuseBuyIBM() &#123; System.out.println("不再采购电脑"); &#125;&#125; 销售管理:123456789101112131415161718192021222324252627282930313233import java.util.Random;/** * 销售管理 * @author zonzie * @date 2018/9/10 20:03 */public class Sale extends AbstractColleague &#123; public Sale(AbstractMediator mediator) &#123; super(mediator); &#125; /** 销售电脑 */ public void sellIBMComputer(int number) &#123; this.mediator.execute("sale.sell", number); System.out.println("销售电脑" + number + "台"); &#125; /** 销售情况 */ public int getSaleStatus() &#123; Random random = new Random(System.currentTimeMillis()); int saleStatus = random.nextInt(100); this.sellIBMComputer(saleStatus); System.out.println("电脑的销售情况: " + saleStatus); return saleStatus; &#125; /** 出清 */ public void offSale() &#123; this.mediator.execute("sale.offsale"); &#125;&#125; 库存管理:12345678910111213141516171819202122232425262728293031323334353637/** * 库存管理 * @author zonzie * @date 2018/9/10 20:03 */public class Stock extends AbstractColleague&#123; public Stock(AbstractMediator mediator) &#123; super(mediator); &#125; // 100台电脑 private static int COMPUTER_NUMBER = 100; // 库存增加 public void increase(int number) &#123; COMPUTER_NUMBER += number; System.out.println("库存数量为" + COMPUTER_NUMBER + "台"); &#125; // 库存降低 public void decrease(int number) &#123; COMPUTER_NUMBER -= number; System.out.println("库存数量为" + COMPUTER_NUMBER + "台"); &#125; // 获得库存数量 public int getStockNumber() &#123; return COMPUTER_NUMBER; &#125; // 存货压力大, 通知采购人员不要采购, 销售人员尽快销售 public void clearStock() &#123; System.out.println("清理存货数量为: " + COMPUTER_NUMBER); super.mediator.execute("stock.clear"); &#125;&#125; 同事类必须有中介者, 所以用构造函数注入, 而中介者可以只有部分同事类, 因此,可以使用setter/getter注入使用中介者模式后, 形成的星型结构: 中介者模式的优点减少类间的依赖,把原有的一对多的依赖变成了一对一的依赖, 同事类只依赖中介者, 减少了依赖,当然同时也降低了类间的耦合 中介者模式的缺点中介者会膨胀的很大, 而且逻辑复杂, 原本多个对象的逻辑会全部放在中介者中,同事类越多, 中介者的逻辑就越复杂 中介者模式的使用场景中介者模式容易被误用, 一个对象与多个对象存在依赖关系是必然的情况, 但是并不代表就要使用中介者模式, 中介者模式适用于多个对象之间紧密耦合的情况, 紧密耦合的标准是,在类图中出现了蜘蛛网状结构,这种情况下一定要考虑使用中介者模式,这有利于把蜘蛛网状的结构梳理为星型结构,使原本复杂混乱的关系变得清晰简单 实际应用 机场调度中心 MVC框架 其中的C(Controller) 就是一个中介者,叫做前端控制器, 作用就是把M(Model)和V(view)隔离开, 并且把M运行的结果和V代表的视图糅合成前端可以展示的页面,减少M和V的依赖关系 媒体网关 中介服务 内容来自: &laquo;设计模式之禅&raquo;]]></content>
      <categories>
        <category>design pattern</category>
      </categories>
      <tags>
        <tag>design pattern</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[原型模式]]></title>
    <url>%2F2018%2F09%2F08%2Fprototype-pattern%2F</url>
    <content type="text"><![CDATA[定义 Specify the kinds of objects to create using a prototypical instance, and craete new objects by copying this prototype用原型模式制定创建对象的种类, 并且通过拷贝这些原型创建新的对象 原型模式的核心是clone方法, 通过该方法进行对象的拷贝, java提供了一个Cloneable接口来标示这个对象是可以拷贝的, Cloneable只是一个标识, Cloneable自身没有任何方法, 同样的接口还有Serializable, 这样的接口只是起到一个标记作用, 然后, 只需要重写Object的clone方法就可以了 原型模式的应用优点1. 性能优良原型模式是在内存中二进制流的拷贝, 要比直接new一个对象性能好很多,特别是要在循环体内产生大量的对象时, 原型模式可以更好的体现其优点 2. 逃避构造函数的约束是优点也是缺点, 直接在内存中拷贝, 构造函数是不会执行的 使用场景1. 资源优化场景类的初始化需要消耗太多的资源 2. 性能和安全要求的场景new一个对象需要非常繁琐的数据准备, 使用原型模式避免new对象 3. 一个对象多个修改者的场景一个对象需要提供给多个调用者,并且都需要修改其值的时候,可以使用原型模式 在真实的项目中, 原型模式很少单独出现, 一般是和工厂方法模式一起出现, 通过clone创建一个对象, 然后由工厂方法提供给调用者. 原型模式的例子批量发送广告邮件的例子: 广告信模板1234567891011121314151617181920212223242526/** * 广告信模板 * @author zonzie * @date 2018/9/8 10:12 */public class AdvTemplate &#123; private String advSubject = "信用卡抽奖活动"; private String advContent = "抽奖通知: 刷卡就送一百万!!!"; public String getAdvSubject() &#123; return advSubject; &#125; public void setAdvSubject(String advSubject) &#123; this.advSubject = advSubject; &#125; public String getAdvContent() &#123; return advContent; &#125; public void setAdvContent(String advContent) &#123; this.advContent = advContent; &#125;&#125; 邮件类12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788/** * 邮件类 * @author zonzie * @date 2018/9/8 10:16 */public class Mail implements Cloneable, Serializable &#123; // 收件人 private String receiver; // 邮件名称 private String subject; // 称谓 private String application; // 内容 private String context; // 邮件的尾部 private String tail; public Mail(AdvTemplate advTemplate) &#123; this.context = advTemplate.getAdvContent(); this.subject = advTemplate.getAdvSubject(); &#125; /** * 复写的clone方法 * @throws CloneNotSupportedException */ @Override protected Mail clone() throws CloneNotSupportedException &#123; return (Mail) super.clone(); &#125; public String getReceiver() &#123; return receiver; &#125; public void setReceiver(String receiver) &#123; this.receiver = receiver; &#125; public String getSubject() &#123; return subject; &#125; public void setSubject(String subject) &#123; this.subject = subject; &#125; public String getApplication() &#123; return application; &#125; public void setApplication(String application) &#123; this.application = application; &#125; public String getContext() &#123; return context; &#125; public void setContext(String context) &#123; this.context = context; &#125; public String getTail() &#123; return tail; &#125; public void setTail(String tail) &#123; this.tail = tail; &#125; @Override public String toString() &#123; final StringBuilder sb = new StringBuilder("Mail&#123;"); sb.append("receiver='").append(receiver).append('\''); sb.append(", subject='").append(subject).append('\''); sb.append(", application='").append(application).append('\''); sb.append(", context='").append(context).append('\''); sb.append(", tail='").append(tail).append('\''); sb.append('&#125;'); return sb.toString(); &#125;&#125; 场景测试类1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253import org.junit.Test;import java.util.Random;/** * 场景测试类 * @author zonzie * @date 2018/9/8 10:30 */public class Client &#123; /** * 发送的数量 */ private int maxCount = 10; @Test public void sendTest() throws CloneNotSupportedException &#123; // 发送邮件 int i = 0; // 定义发送模板 Mail mail = new Mail(new AdvTemplate()); mail.setTail("xx公司版权所有"); while(i++ &lt; maxCount) &#123; // 邮件不同的地方 Mail clone = mail.clone(); clone.setApplication(randomString(5) + " Mr/Mrs"); clone.setReceiver(randomString(5) + "@" + randomString(8) + ".com"); sendMail(clone); &#125; &#125; /** * 发送邮件 */ private void sendMail(Mail mail) &#123; System.out.println(mail); &#125; /** * 生成随机的字符串 */ public String randomString(int i) &#123; Random random = new Random(); StringBuilder stringBuilder = new StringBuilder(); for(int j = 0; j &lt;= i; j++) &#123; int randNum = random.nextInt(26) + 97; stringBuilder.append((char) randNum); &#125; return stringBuilder.toString(); &#125;&#125; 注意事项考虑深拷贝和浅拷贝的区别 Object对象提供的clone方法只是拷贝本对象, 对象内部的数组, 引用都不拷贝, 还是还是指向原生对象的内部元素地址,这种拷贝就叫做浅拷贝 使用原型模式, 引用类型的成员变量只有满足两个条件才不能拷贝: 类的成员变量,而不是方法内部的变量 必须是一个可变的引用对象, 而不是一个原始类型或者不可变对象 浅拷贝的例子123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051import org.junit.Test;import java.util.ArrayList;/** * 浅拷贝 * @author zonzie * @date 2018/9/8 12:54 */public class ShallowCopy implements Cloneable &#123; /** * 引用类型的变量 */ private ArrayList&lt;String&gt; list = new ArrayList&lt;&gt;(); @Override protected ShallowCopy clone() throws CloneNotSupportedException &#123; return (ShallowCopy) super.clone(); &#125; public ArrayList&lt;String&gt; getList() &#123; return list; &#125; public void setValue(String value) &#123; this.list.add(value); &#125; @Override public String toString() &#123; final StringBuilder sb = new StringBuilder("ShallowCopy&#123;"); sb.append("list=").append(list); sb.append('&#125;'); return sb.toString(); &#125; /** * 测试方法 * 运行结果: ShallowCopy&#123;list=[jack, tom]&#125; */ @Test public void shallowTest() throws CloneNotSupportedException &#123; ShallowCopy shallowCopy = new ShallowCopy(); shallowCopy.setValue("jack"); // 拷贝对象 ShallowCopy clone = shallowCopy.clone(); clone.setValue("tom"); // 打印原始对象 System.out.println(shallowCopy); &#125;&#125; 深拷贝的例子123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354import org.junit.Test;import java.util.ArrayList;/** * 深拷贝 * @author zonzie * @date 2018/9/8 12:54 */public class DeepCopy implements Cloneable &#123; /** * 引用类型的成员变量 */ private ArrayList&lt;String&gt; list = new ArrayList&lt;&gt;(); @Override protected DeepCopy clone() throws CloneNotSupportedException &#123; DeepCopy clone = (DeepCopy) super.clone(); clone.list = (ArrayList&lt;String&gt;) this.list.clone(); return clone; &#125; public ArrayList&lt;String&gt; getList() &#123; return list; &#125; public void setValue(String value) &#123; this.list.add(value); &#125; @Override public String toString() &#123; final StringBuilder sb = new StringBuilder("DeepCopy&#123;"); sb.append("list=").append(list); sb.append('&#125;'); return sb.toString(); &#125; /** * 测试方法 * 运行结果: DeepCopy&#123;list=[jack]&#125; */ @Test public void shallowTest() throws CloneNotSupportedException &#123; DeepCopy deepCopy = new DeepCopy(); deepCopy.setValue("jack"); // 拷贝对象 DeepCopy clone = deepCopy.clone(); clone.setValue("tom"); // 打印原始对象 System.out.println(deepCopy); &#125;&#125; 对象的clone和final是有冲突的, 如果变量被final修饰, 是不可以被克隆的, 想要克隆对象, 需要去掉final关键字总之,就是先产生出一个包含大量的共有信息的类, 然后可以拷贝出副本, 再修正副本的细节 内容来自: &laquo;设计模式之禅&raquo; — 秦小波]]></content>
      <categories>
        <category>design pattern</category>
      </categories>
      <tags>
        <tag>design pattern</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[一致性哈希:原理和Java实现]]></title>
    <url>%2F2018%2F09%2F06%2Fconsistent-hash%2F</url>
    <content type="text"><![CDATA[算法的提出 一致性哈希算法是在1997年由MIT提出的一种分布式哈希算法, 设计目标是为了解决因特网中的热点问题, 喂鸡百颗的解释: 点这里 一致性哈希算法提出了在动态变化的cache中,判定hash算法好换的四个定义 平衡性: 指的是哈希的结果能够尽可能的分布到所有的缓存中去,这样可以使得所有的缓冲空间都得到利用 单调性: 如果已经有一些内容通过哈希分派到了相应的缓存中, 又有新的缓存加入到了系统. 哈希的结果能够保证原有的已分配的内容可以映射到原有的或者新的缓存中去,但是不会映射到旧的缓存区 分散性 负载 在分布式集群中,机器的添加删除,故障后自动脱离集群这些操作是分布式集群管理中最基本的功能,如果采用一般的hash(object)%N的算法,在集群节点稍有变动的情况下, 原有的数据就再也找不到了, 这样严重违反了单调性原则 一致性哈希的解释 按照常用的哈希算法将对应的key映射到一个具有2^32个桶的空间中, 将这些数字头尾相连,想象成一个闭合的环 将节点的标识通过hash算法处理后映射到环上,如图,计算三个节点node1-node3的hash值,映射到hash环上 将要存储的key计算hash值后,也映射到环上,按照顺时针(或者逆时针)一个方向,将数据存储到最近的一个节点上, 如图所示 如果加入了新的节点, 失效的缓存只有很少的一部分, 只有key4的缓存失效了,因为它的hash值会映射到node4上,其他的则保持不变 如果有节点挂掉, 同样失效的缓存也是只有很少的一部分, node4挂掉后, 也只有key4会受到影响,其他部分保持不变 但是,哈希算法并不能保证平衡性,也就是说,通过key计算的hash值, 并不一定能均匀的分布在整个环中, 这样有可能会导致大量的key分布在同一个节点中,如果节点挂掉,就会导致其他节点的压力更大, 从而导致雪崩式的节点崩溃,图中node2承接了来自node3的压力 因此,所有的节点必须均匀分布在整个哈希环中,因此提出了虚拟节点的概念, 虚拟节点是真实节点在哈希空间中的复制品, 一个真实节点可以有很多个虚拟节点, 虚拟节点越多, 整个哈希环中的节点分布就越均匀,图中node1的虚拟节点对应node1_v1和node1_v2, node2对应node2_v1和node2_v2 hash算法的选取这里选用的hash算法必须具有很好的分散性,java中的Object的hashcode实现,变化程度太小,例如,需要计算哈希值的key为”node-1”,”node-2”, 计算结果为-1040172250, -1040172249, 计算结果过于集中, 这会使所有的节点分布在哈希环上很小的范围内, 导致缓存无法均匀分布在各个节点上,因此需要选取合适的hash算法, 推荐使用CRC32_HASH、FNV1_32_HASH、 KETAMA_HASH、murmur_hash 不带虚拟节点的代码实现1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859import java.util.SortedMap;import java.util.TreeMap;/** * 一致性哈希 * @author zonzie * @date 2018/9/5 19:37 */public class ConsistentHashingWithoutVirtualNode &#123; /** 缓存服务器列表 */ private static String[] servers = &#123;"192.168.198.128:111", "192.168.198.128:112", "192.168.198.128:113", "192.168.198.128:114", "192.168.198.128:115"&#125;; /** key表示服务器的hash值, value表示服务器的名称 */ private static SortedMap&lt;Integer, String&gt; sortedMap = new TreeMap&lt;&gt;(); static &#123; for (String server : servers) &#123; int hash = hash(server); System.out.println("[" + server + "] 加入集合中, hash值为" + hash); sortedMap.put(hash, server); &#125; &#125; /** 使用FNV1_32_HASH算法计算服务器的Hash值*/ private static int hash(String str) &#123; final int p = 16777619; int hash = (int) 2166136261L; for(int i = 0; i &lt; str.length(); i++) hash = (hash ^ str.charAt(i)) * p; hash += hash &lt;&lt; 13; hash ^= hash &gt;&gt; 7; hash += hash &lt;&lt; 3; hash ^= hash &gt;&gt; 17; hash += hash &lt;&lt; 5; // 算出来值为负数就取绝对值 if(hash &lt; 0) hash = Math.abs(hash); return hash; &#125; /**得到应当路由的节点*/ private static String getServer(String node) &#123; int hash = hash(node); // 大于这个hash值得所有的节点 SortedMap&lt;Integer, String&gt; tailMap = sortedMap.tailMap(hash); // 第一个key就是离node最近的那个节点 Integer integer = tailMap.firstKey(); return tailMap.get(integer); &#125; public static void main(String[] args) &#123; String[] nodes = &#123;"127.0.0.1:1111", "221.226.0.1:2222", "10.211.0.1:3333"&#125;; for (String node : nodes) &#123; System.out.println("节点:" + node + " 哈希值: " + hash(node) + ", 被路由到节点:" + getServer(node)); &#125; &#125;&#125; 带有虚拟节点的java实现123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207import org.junit.Test;import java.nio.ByteBuffer;import java.nio.ByteOrder;import java.util.*;/** * 添加虚拟节点的一致性哈希 * @author zonzie * @date 2018/9/5 20:14 */public class ConsistentHashingWithVirtualNode &#123; /** * 真实的服务器列表 */ private static String[] servers = &#123;"192.168.198.128:111", "192.168.198.128:112", "192.168.198.128:113", "192.168.198.128:114", "192.168.198.128:115"&#125;; /** * 真实节点列表 */ private static List&lt;String&gt; realNodes = new LinkedList&lt;&gt;(); /** * 虚拟节点列表 */ private static SortedMap&lt;Long, String&gt; virtualNodes = new TreeMap&lt;&gt;(); /** * 虚拟节点的数目 */ private static final int VIRTUAL_NODES = 100; /** * 分隔符 */ private static final String SEPARATOR = "=&gt;"; // 初始化节点数据 static &#123; // 先添加原始的服务器到真实的节点列表 realNodes.addAll(Arrays.asList(servers)); // 添加虚拟节点 addVirtualNode(realNodes.toArray(realNodes.toArray(new String[]&#123;&#125;))); &#125; /** * 使用 * FNV1_32_HASH或者murmurHash * 计算Hash值 */ private static long hash(String str) &#123; int hash = murmurHash(str); return Math.abs(hash); &#125; /** * 应当路由到的节点 */ private static String getServer(String node) &#123; long hash = hash(node); SortedMap&lt;Long, String&gt; tailMap = virtualNodes.tailMap(hash); Long i = null; String virtualNode = null; if(tailMap.size() == 0) &#123; i = virtualNodes.firstKey(); virtualNode = virtualNodes.get(i); &#125; else &#123; i = tailMap.firstKey(); virtualNode = tailMap.get(i); &#125; // 第一个key就是顺时针过去离node最近的节点 // 返回虚拟节点的名称 return virtualNode.substring(0, virtualNode.indexOf(SEPARATOR)); &#125; /** * 动态添加节点 */ private static void addNode(String... nodes) &#123; // 添加真实的节点 realNodes.addAll(Arrays.asList(nodes)); // 添加虚拟节点 addVirtualNode(nodes); &#125; /** * 删除一个节点 */ private static void removeNode(String... nodes) &#123; // 移除真实节点 realNodes.removeAll(Arrays.asList(nodes)); // 移除虚拟节点 for (String node : nodes) &#123; for(int i = 0; i &lt; VIRTUAL_NODES; i++) &#123; String virtualNodeName = node + SEPARATOR + i; long hash = hash(virtualNodeName); System.out.println("移除虚拟节点:" + virtualNodeName + " hash值为: " + hash); virtualNodes.remove(hash); &#125; &#125; &#125; /** * 添加虚拟节点 */ private static void addVirtualNode(String... nodes) &#123; // 添加虚拟节点 for (String s : nodes) &#123; for(int i = 0; i &lt; VIRTUAL_NODES; i++) &#123; String virtualNodeName = s + SEPARATOR + i; long hash = hash(virtualNodeName); System.out.println("虚拟节点[" + virtualNodeName + "]被添加, hash值为" + hash); virtualNodes.put(hash, virtualNodeName); &#125; &#125; &#125; /** * FNV1_32_HASH */ private static int fnvHash(String str) &#123; final int p = 16777619; int hash = (int) 2166136261L; for(int i = 0; i &lt; str.length(); i++) hash = (hash ^ str.charAt(i)) * p; hash += hash &lt;&lt; 13; hash ^= hash &gt;&gt; 7; hash += hash &lt;&lt; 3; hash ^= hash &gt;&gt; 17; hash += hash &lt;&lt; 5; // 算出来值为负数就取绝对值 if(hash &lt; 0) hash = Math.abs(hash); return hash; &#125; /** * murmurHash: 非加密hash算法, 速度快, 碰撞少, 随机分布特征表现良好 */ private static int murmurHash(String key) &#123; ByteBuffer buf = ByteBuffer.wrap(key.getBytes()); int seed = 0x1234ABCD; ByteOrder byteOrder = buf.order(); buf.order(ByteOrder.LITTLE_ENDIAN); long m = 0xc6a4a7935bd1e995L; int r = 47; long h = seed ^ (buf.remaining() * m); long k; while (buf.remaining() &gt;= 8) &#123; k = buf.getLong(); k *= m; k ^= k &gt;&gt;&gt; r; k *= m; h ^= k; h *= m; &#125; if (buf.remaining() &gt; 0) &#123; ByteBuffer finish = ByteBuffer.allocate(8).order( ByteOrder.LITTLE_ENDIAN); finish.put(buf).rewind(); h ^= finish.getLong(); h *= m; &#125; h ^= h &gt;&gt;&gt; r; h *= m; h ^= h &gt;&gt;&gt; r; buf.order(byteOrder); return (int) h; &#125; /** * 测试 */ @Test public void consistentHashTest &#123; HashMap&lt;String, Integer&gt; hashMap = new HashMap&lt;&gt;(); ArrayList&lt;String&gt; list = new ArrayList&lt;&gt;(); for(int i = 0; i &lt; 100000; i++) &#123; list.add(UUID.randomUUID().toString()); &#125; for(int i = 0; i &lt; list.size(); i++) &#123; String server = getServer(list.get(i)); Integer integer = hashMap.get(server); if(integer == null) &#123; hashMap.put(server, i); &#125; else &#123; hashMap.put(server, integer+1); &#125; &#125; Set&lt;String&gt; strings = hashMap.keySet(); for (String string : strings) &#123; System.out.println("节点[" +string+"]分配到的元素个数为"+ hashMap.get(string)); &#125; &#125;&#125; 参考内容:http://m.elecfans.com/article/717709.html https://www.cnblogs.com/shangxiaofei/p/6859904.htmlhttps://coderxing.gitbooks.io/architecture-evolution/di-san-pian-ff1a-bu-luo/631-yi-zhi-xing-ha-xi.htmlhash算法: https://www.cnblogs.com/wanghetao/p/4658471.html]]></content>
      <categories>
        <category>hash</category>
      </categories>
      <tags>
        <tag>hash</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[springboot中的动态数据源配置]]></title>
    <url>%2F2018%2F09%2F03%2Fspringboot%E4%B8%AD%E7%9A%84%E5%8A%A8%E6%80%81%E6%95%B0%E6%8D%AE%E6%BA%90%E9%85%8D%E7%BD%AE%2F</url>
    <content type="text"><![CDATA[在项目中使用多数据源 使用多数据源一般有两种解决办法 在数据库之上加一层,项目在访问数据时,直接访问中间层,中间层解析sql,确定访问哪个数据库实例,或者访问多个实例,然后再汇总数据 如果是简单的配置多数据源,或者配置读写分离,可以采用spring的动态数据源配置 这里只说使用动态数据源的方法 spring提供的动态数据源配置非常简单 基本思路如下: 分别初始化每个数据源 将所有的数据源全部放入spring提供的动态数据源对象中 将dao层使用的原本的数据源切换为动态数据源对象 在执行dao层的方法时,确定具体要访问的数据源 下面的例子基于springboot项目 初始化数据源这里只添加两个数据源,做一个简单的读写分离配置1 首先是application.yml的配置123456789101112131415161718192021222324252627282930# 数据源使用druiddruidconfig: &amp;druidconfig type: com.alibaba.druid.pool.DruidDataSource driver-class-name: com.mysql.jdbc.Driver initialSize: 5 minIdle: 5 maxActive: 21 maxWait: 60001 timeBetweenEvictionRunsMillis: 60001 minEvictableIdleTimeMillis: 300001 validationQuery: SELECT 1 FROM DUAL testWhileIdle: true testOnBorrow: false testOnReturn: false poolPreparedStatements: true maxPoolPreparedStatementPerConnectionSize: 20 filters: stat,wall,log4j connectionProperties: druid.stat.mergeSql=true;druid.stat.slowSqlMillis=5000 useGlobalDataSourceStat: truespring: datasource: url: jdbc:mysql://192.168.198.128:3306/operation?characterEncoding=utf8&amp;useSSL=false username: root password: root &lt;&lt;: *druidconfig readSource: url: jdbc:mysql://192.168.198.128:3306/operation?characterEncoding=utf8&amp;useSSL=false username: root password: root &lt;&lt;: *druidconfig 2 然后是初始化数据源配置12345678910111213141516171819202122232425262728293031323334import com.alibaba.druid.pool.DruidDataSource;import org.springframework.boot.context.properties.ConfigurationProperties;import org.springframework.context.annotation.Bean;import org.springframework.context.annotation.Configuration;import org.springframework.context.annotation.Primary;import javax.sql.DataSource;/** * @author itw_yaobq * @date 2018/2/28 17:12 */@Configurationpublic class LoadDataSource &#123; /** * 写库 */ @Primary @Bean(name = "writeDataSource") @ConfigurationProperties(prefix = "spring.dataSource") public DataSource writeDataSource() &#123; return new DruidDataSource(); &#125; /** * 读库 */ @Bean(name = "readDataSource") @ConfigurationProperties(prefix = "spring.readSource") public DataSource readDataSource() &#123; return new DruidDataSource(); &#125;&#125; 3 jpa数据源配置123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263import org.springframework.boot.autoconfigure.orm.jpa.JpaProperties;import org.springframework.boot.orm.jpa.EntityManagerFactoryBuilder;import org.springframework.context.annotation.Bean;import org.springframework.context.annotation.Configuration;import org.springframework.context.annotation.Primary;import org.springframework.data.jpa.repository.config.EnableJpaRepositories;import org.springframework.orm.jpa.LocalContainerEntityManagerFactoryBean;import org.springframework.transaction.PlatformTransactionManager;import javax.annotation.Resource;import javax.persistence.EntityManagerFactory;import javax.sql.DataSource;/** * 修改jpa的自动配置,添加动态数据源 * * @author itw_yaobq * @date 2018/2/28 17:22 */@Configuration@EnableJpaRepositories(value = "com.taikang.operation.*.repository")public class InitialDataSource &#123; /** * 加载yml中的配置 */ @Resource private JpaProperties jpaProperties; /** * 这里的DataSource,注入动态数据源 */ @Resource(name = "routingDataSource") private DataSource dataSource; /** * 设置动态数据源,属性配置,扫描entity的位置 */ @Bean(name = "entityManagerFactoryBean") @Primary public LocalContainerEntityManagerFactoryBean entityManagerFactoryBean(EntityManagerFactoryBuilder builder) &#123; return builder.dataSource(dataSource).properties(jpaProperties.getProperties()).packages("com.taikang.operation.*.repository.entity") // .persistenceUnit("") .build(); &#125; /** * 配置实体工厂 */ @Bean(name = "entityManagerFactory") public EntityManagerFactory entityManagerFactory(EntityManagerFactoryBuilder builder) &#123; return this.entityManagerFactoryBean(builder).getObject(); &#125; /** * 事务配置 */ @Bean(name = "transactionManager") public PlatformTransactionManager transactionManager(EntityManagerFactoryBuilder builder) &#123; MyJpaTransactionManager myJpaTransactionManager = new MyJpaTransactionManager(); myJpaTransactionManager.setEntityManagerFactory(this.entityManagerFactory(builder)); return myJpaTransactionManager; &#125;&#125; 4 事务管理类1234567891011121314151617181920212223242526272829303132333435import com.taikang.operation.core.common.constant.DataSourceType;import com.taikang.operation.core.config.readwriteseparationconfig.dynamicdatasourceconfig.DynamicDataSourceHolder;import lombok.extern.slf4j.Slf4j;import org.springframework.orm.jpa.JpaTransactionManager;import org.springframework.transaction.TransactionDefinition;import org.springframework.transaction.support.DefaultTransactionStatus;/** * @author itw_yaobq * @date 2018/2/28 17:16 */@Slf4jpublic class MyJpaTransactionManager extends JpaTransactionManager &#123; @Override protected void doBegin(Object transaction, TransactionDefinition definition) &#123; boolean readOnly = definition.isReadOnly(); if (!readOnly) &#123; DynamicDataSourceHolder.setDataSource(DataSourceType.write.getType()); &#125; if (log.isDebugEnabled()) &#123; log.info("transaction-readOnly?: &#123;&#125;", readOnly); &#125; super.doBegin(transaction, definition); &#125; @Override protected void doCommit(DefaultTransactionStatus status) &#123; String dataSource = DynamicDataSourceHolder.getDataSource(); if (log.isDebugEnabled()) &#123; log.info("dataSource: &#123;&#125;", dataSource); &#125; super.doCommit(status); &#125;&#125; 配置动态数据源1 先创建一个读写库的标识12345678910111213141516171819202122232425262728293031323334/** * @author itw_yaobq * @date 2018/4/1 13:44 */public enum DataSourceType &#123; /** * 读写分离标识 */ read("read", "读库"), write("write", "写库"); private String type; private String name; DataSourceType(String type, String name) &#123; this.type = type; this.name = name; &#125; public String getType() &#123; return type; &#125; public void setType(String type) &#123; this.type = type; &#125; public String getName() &#123; return name; &#125; public void setName(String name) &#123; this.name = name; &#125;&#125; 2 创建动态数据源,并且设置数据源的切换策略1234567891011121314151617181920212223242526import com.taikang.operation.core.common.constant.DataSourceType;import lombok.extern.slf4j.Slf4j;import org.springframework.jdbc.datasource.lookup.AbstractRoutingDataSource;import org.springframework.util.StringUtils;/** * @author itw_yaobq * @date 2018/2/28 16:49 */@Slf4jpublic class DynamicDataSource extends AbstractRoutingDataSource &#123; /** * 切换数据源的名称标识 */ @Override protected Object determineCurrentLookupKey() &#123; String dataSource = DynamicDataSourceHolder.getDataSource(); if (StringUtils.isEmpty(dataSource)) &#123; dataSource = DataSourceType.write.getType(); &#125; log.info("dataSource: " + dataSource); DynamicDataSourceHolder.clearDataSource(); return dataSource; &#125;&#125; 3 创建动态数据源12345678910111213141516171819202122232425262728293031import com.taikang.operation.core.common.constant.DataSourceType;import org.springframework.beans.factory.annotation.Qualifier;import org.springframework.beans.factory.annotation.Value;import org.springframework.context.annotation.Bean;import org.springframework.context.annotation.Configuration;import org.springframework.jdbc.datasource.lookup.AbstractRoutingDataSource;import javax.sql.DataSource;import java.util.HashMap;/** * 配置动态数据源,将所有的数据源都放入DynamicDataSource中 * @author itw_yaobq * @date 2018/2/28 16:49 */@Configurationpublic class DataSourceRouting &#123; @Bean("routingDataSource") public AbstractRoutingDataSource routingDataSource(@Qualifier("readDataSource") DataSource readDataSource, @Qualifier("writeDataSource") DataSource writeDataSource) &#123; DynamicDataSource dynamicDataSource = new DynamicDataSource(); HashMap&lt;Object, Object&gt; map = new HashMap&lt;&gt;(2); map.put(DataSourceType.read.getType(), readDataSource); map.put(DataSourceType.write.getType(), writeDataSource); dynamicDataSource.setTargetDataSources(map); // 设置默认的数据源 dynamicDataSource.setDefaultTargetDataSource(writeDataSource); return dynamicDataSource; &#125;&#125; 4 将读写库的标识存到ThreadLocal中12345678910111213141516171819202122/** * 绑定当前线程和特定的数据源 * * @author itw_yaobq * @date 2018/2/28 16:49 */public class DynamicDataSourceHolder &#123; private static final ThreadLocal&lt;String&gt; DATASOURCE = new ThreadLocal&lt;&gt;(); public static String getDataSource() &#123; return DATASOURCE.get(); &#125; public static void setDataSource(String dataSourceName) &#123; DATASOURCE.set(dataSourceName); &#125; public static void clearDataSource() &#123; DATASOURCE.remove(); &#125;&#125; 5 在切面中根据方法名称判断要切换的数据源1234567891011121314151617181920212223242526272829303132333435363738394041424344import com.taikang.operation.core.common.constant.DataSourceType;import com.taikang.operation.core.config.readwriteseparationconfig.dynamicdatasourceconfig.DynamicDataSourceHolder;import lombok.extern.slf4j.Slf4j;import org.aspectj.lang.ProceedingJoinPoint;import org.aspectj.lang.annotation.Around;import org.aspectj.lang.annotation.Aspect;import org.aspectj.lang.reflect.MethodSignature;import org.springframework.stereotype.Component;import org.springframework.transaction.annotation.Transactional;/** * @author itw_yaobq * @date 2018/2/28 16:47 */@Aspect@Component@Slf4jpublic class DynamicDataSourceAspect &#123; @Around("execution(* com.taikang.operation.*.service.impl.*.select*(..)) || execution(* com.taikang.operation.*.service.impl.*.find*(..)) " + "|| execution(* com.taikang.operation.*.service.impl.*.get*(..)) || execution(* com.taikang.operation.*.service.impl.*.query*(..))") public Object setReadDataSourceType(ProceedingJoinPoint pjp) throws Throwable &#123; MethodSignature signature = (MethodSignature) pjp.getSignature(); Class declaringType = signature.getDeclaringType(); boolean annotationPresent = declaringType.isAnnotationPresent(Transactional.class); if (!annotationPresent) &#123; DynamicDataSourceHolder.setDataSource(DataSourceType.read.getType()); &#125; if (log.isDebugEnabled()) &#123; log.info("数据源切面: &#123;&#125;", "read"); &#125; return pjp.proceed(); &#125; @Around("execution(* com.taikang.operation.*.service.impl.*.delete*(..)) || execution(* com.taikang.operation.*.service.impl.*.update*(..)) " + "|| execution(* com.taikang.operation.*.service.impl.*.insert*(..))") public Object setWriteDataSourceType(ProceedingJoinPoint pjp) throws Throwable &#123; // MethodSignature signature = (MethodSignature) pjp.getSignature(); DynamicDataSourceHolder.setDataSource(DataSourceType.write.getType()); if (log.isDebugEnabled()) &#123; log.info("数据源切面: &#123;&#125;", "write"); &#125; return pjp.proceed(); &#125;&#125; 这里只是给出了两个数据源读写分离的配置,数据库的主从复制需要另外处理,除此之外,配置mybatis的动态数据源与此类似,还可以将代码改为支持多数据源配置的方法,只需要添加新的数据源, 至于具体选择哪个数据源,可以将根据方法名切换数据源的方式修改为根据自定义注解的方式切换数据源,在此不再赘述]]></content>
      <categories>
        <category>springboot</category>
      </categories>
      <tags>
        <tag>mysql</tag>
        <tag>springboot</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[elasticsearch和ELK的安装使用]]></title>
    <url>%2F2018%2F09%2F01%2FhowToUseEsAndELK%2F</url>
    <content type="text"><![CDATA[es安装 下载es 下载es,地址: https://www.elastic.co/cn/downloads/elasticsearch,可以下载tarball或者zip文件 es不能在root目录下运行,需要一个普通账户 解压后进入bin目录,./elasticsearch,就可以启动es 安装ik分词器 下载地址: https://github.com/medcl/elasticsearch-analysis-ik/releases 可以使用plugin直接安装,但是需要安装对应的版本,我这里下载的是6.3.2: ./elasticsearch-plugin install https://oiw0skz2u.qnssl.com/o_1cl0qgokl4aq1gof9ii1qch1r5k7.zip?attname=elasticsearch-analysis-ik-6.3.2.zip 我这里无法直接下载安装,只能手动安装: 下载zip文件: wget https://oiw0skz2u.qnssl.com/o_1cl0qgokl4aq1gof9ii1qch1r5k7.zip?attname=elasticsearch-analysis-ik-6.3.2.zip 解压文件,指定目录: unzip -d ./ikanalyzer elasticsearch-analysis-ik-6.3.2.zip 进入目录,打包,需要maven环境: mvn clean package 打包完毕后,找到target/release/目录下的zip文件,复制到es的plugin目录下 解压这个文件,指定目录: unzip -d ./ikanalyzer elasticsearch-analysis-ik-6.3.2.zip 删除zip文件 再次启动es,ikAnalyzer会自动被加载 es没有界面,可以使用head插件,head插件需要node环境 安装node,去官网下载node 解压 配置环境变量: vim /etc/profile 12export NODE=/opt/node/export PATH=$NODE/bin:$PATH 切换npm源: npm config set registry https://registry.npm.taobao.org 下载head插件, 地址: https://github.com/mobz/elasticsearch-head.git 使用yum安装git,使用git clone: git clone https://github.com/mobz/elasticsearch-head.git 拉下代码后, 进入目录,运行npm install 因为没有phantomJs,会报错,再执行npm install phantomjs-prebuilt@2.1.16 --ignore-scripts 可以启动了: npm run start 但是打开浏览器,还是无法连接es,需要在config/elasticsearch.yml中添加配置: 12http.cors.enabled: truehttp.cors.allow-origin: "*" es集群配置 需要修改/config/elasticsearch.yml 12345678910111213141516171819# 需要修改的配置# 集群名称cluster.name: es-cluster# 节点名称,每个节点要不一样node.name: node-1# 是否可以作为masternode.master: true# 是否可以作为数据节点node.data: true# 本机的ip地址network.host: 192.168.198.88# 要监听的端口http.port: 9201# 集群的端口transport.tcp.port: 9301# 集群中的其他节点的host,因为都在一台机器上,集群端口不一样,这里配置两个实例的单机集群discovery.zen.ping.unicast.hosts: ["192.168.198.88:9301","192.168.198.88:9302"]# 最小集群节点数,为了避免集群脑裂, 集群中的节点数应该为 半数+1discovery.zen.minimum_master_nodes: 2 依次启动各个节点即可组成集群 ELK的基本安装整合使用,以及和logback整合使用简介 ELK是当前流行的日志分析系统,是由三个部分组成ElasticSearch, LogStash, Kibana组成, 三个部分都是elastic的开源产品,Logstash是一个用来收集分析过滤日志的工具,它可以从各种来源收集日志,输出到各种其他的组件之中,Kibana是一个基于web的图形化界面, 主要用于数据的可视化展示, ELK三者基本都做到了零配置,开箱即用 官网上有各个部分的使用文档: https://www.elastic.co/cn/products ELK三者的版本需要保持一致 配置logstash的配置: logstash依赖jdk1.8,使用之前需要配置好jdk环境 logstash通过管道进行运作,管道有两个必须的元素,输入和输出,还有一个可选的元素,过滤器 输出部分从数据源获取数据,过滤器根据用户指定的数据格式修改数据,输出插件则将数据写入到目的地,如图: 一个简单的例子,启动logstash 1./bin/logstash -e 'input &#123; stdin &#123;&#125;&#125; output &#123; stdout &#123;&#125;&#125;' 启动后,键入的输入都会作为logstash的输入并且返回结果 这里添加一个新的配置文件logstash-logback.conf 123456789101112131415161718input &#123; tcp &#123; host =&gt; &quot;192.168.198.128&quot; port =&gt; 9760 mode =&gt; &quot;server&quot; tags =&gt; [&quot;tags&quot;] codec =&gt; json_lines &#125;&#125;output &#123; stdout &#123; codec =&gt; rubydebug &#125; elasticsearch &#123; hosts =&gt; &quot;192.168.198.88:9200&quot; &#125;&#125; 上面的input内容会接收发送到host:port的内容,host是本机的ip,output中有两个输出,一个输出到标准控制台,另一个输出到es 带配置文件启动: ./bin/logstash -f ./config/logstash-logback.conf Kibana的配置 解压下载包后, 找到config目录下的kibana.yml 开启配置 1234server.port: 5601server.host: "0.0.0.0"elasticsearch.url: "http://192.168.198.88:9200"kibana.index: ".kibana" 直接启动bin目录下的kibana.bat,就可以直接使用了 访问kibana的页面: localhost:5601 由于logstash默认的索引是以logstash-开头, 后面为当前的日期,因此create index pattern 添加logstash-* 项目中的日志配置 pom文件中添加jar 12345&lt;dependency&gt; &lt;groupId&gt;net.logstash.logback&lt;/groupId&gt; &lt;artifactId&gt;logstash-logback-encoder&lt;/artifactId&gt; &lt;version&gt;4.11&lt;/version&gt;&lt;/dependency&gt; 在日志配置的文件logback.xml中添加配置 12345678&lt;appender name="LOGSTASH" class="net.logstash.logback.appender.LogstashTcpSocketAppender"&gt; &lt;destination&gt;192.168.198.128:9760&lt;/destination&gt; &lt;encoder charset="UTF-8" class="net.logstash.logback.encoder.LogstashEncoder"/&gt;&lt;/appender&gt;&lt;root level="INFO"&gt; &lt;appender-ref ref="LOGSTASH"/&gt;&lt;/root&gt; 至此,开启ELK,可以在kibana的界面上看到项目的日志了,可以根据自己想看的内容添加filter,过滤日志内容 参考内容: https://www.cnblogs.com/yuhuLin/p/7018858.html https://blog.csdn.net/y_y_y_k_k_k_k/article/details/72772223 https://www.cnblogs.com/moonlightL/p/7760512.html]]></content>
      <categories>
        <category>es</category>
      </categories>
      <tags>
        <tag>elasticSearch</tag>
        <tag>logstash</tag>
        <tag>kibana</tag>
        <tag>ELK</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[建造者模式]]></title>
    <url>%2F2018%2F08%2F20%2Fbuilder-pattern%2F</url>
    <content type="text"><![CDATA[建造者模式(生成器模式) separate the construction of a complex object from its representation so that the same construction process can create diffrent representations将一个复杂对象的构建和表示分离,使得同样的构建过程可以创建不同的表示 建造者中的角色Product产品类要创建的复杂对象,通常实现了模板方法模式,也就是有模板方法和普通方法 Builder抽象建造者规范产品的构建, 一般由子类实现 ConcreteBuilder具体建造者实现具体的构建方法, 返回一个组建好的对象 Director导演类负责安排已有模块的建造顺序, 然后告诉builder开始建造 使用场景 相同的方法,不同的执行顺序, 产生的事件的结果不同,可以使用建造者模式 多个部件和零件, 都可以装配到一个对象中, 但是产生的运行结果又不相同时, 可以使用该模式 产品类字段很多, 不同的调用顺序产生不同的效能时,使用建造者模式非常合适 一个建造者模式的demo首先提供产品类1234567891011121314151617181920212223242526272829303132333435363738394041424344/** * 组装一台电脑,假设它有三个部件 * @author zonzie * @date 2018/9/3 20:44 */public class Computer &#123; private String cpu; private String mainBoard; private String ram; public String getCpu() &#123; return cpu; &#125; public void setCpu(String cpu) &#123; this.cpu = cpu; &#125; public String getMainBoard() &#123; return mainBoard; &#125; public void setMainBoard(String mainBoard) &#123; this.mainBoard = mainBoard; &#125; public String getRam() &#123; return ram; &#125; public void setRam(String ram) &#123; this.ram = ram; &#125; @Override public String toString() &#123; final StringBuilder sb = new StringBuilder("Computer&#123;"); sb.append("cpu='").append(cpu).append('\''); sb.append(", mainBoard='").append(mainBoard).append('\''); sb.append(", ram='").append(ram).append('\''); sb.append('&#125;'); return sb.toString(); &#125;&#125; 然后是抽象的builder1234567891011/** * 一个抽象的建造者 * @author zonzie * @date 2018/9/3 20:49 */public abstract class AbstractBuilder &#123; public abstract void buildCpu(String cpu); public abstract void buildMainBoard(String mainBoard); public abstract void buildRam(String ram); public abstract Computer create();&#125; 建造者的具体实现123456789101112131415161718192021222324252627282930/** * 建造者的实现类 * @author zonzie * @date 2018/9/3 20:52 */public class ComputerBuilder extends AbstractBuilder&#123; // 创建一个computer对象 private Computer computer = new Computer(); @Override public void buildCpu(String cpu) &#123; computer.setCpu(cpu); &#125; @Override public void buildMainBoard(String mainBoard) &#123; computer.setMainBoard(mainBoard); &#125; @Override public void buildRam(String ram) &#123; computer.setRam(ram); &#125; @Override public Computer create() &#123; return this.computer; &#125;&#125; 导演类,指挥建造者建造的流程123456789101112131415161718192021222324252627/** * 指挥者类,指挥建造流程 * @author zonzie * @date 2018/9/3 20:57 */public class Director &#123; private ComputerBuilder build = null; public Director(ComputerBuilder build) &#123; this.build = build; &#125; /** * 返回建造好的实体 * @param cpu * @param mainBoard * @param ram * @return */ public Computer createComputer(String cpu, String mainBoard, String ram) &#123; // 规范建造流程 this.build.buildMainBoard(mainBoard); this.build.buildCpu(cpu); this.build.buildRam(ram); return build.create(); &#125;&#125; 测试12345678910111213141516import org.junit.Test;/** * @author zonzie * @date 2018/9/3 21:03 */public class BuilderTest &#123; @Test public void buildTest() &#123; ComputerBuilder computerBuilder = new ComputerBuilder(); Director director = new Director(computerBuilder); Computer computer = director.createComputer("i7", "intel主板", "8G"); System.out.println(computer); &#125;&#125; 建造者模式的优点 封装性: 使用者不需要关注产品内部的实现细节 建造者独立,容易扩展 便于控制细节风险, 具体的建造者是独立的, 可以对建造过程逐步细化, 不对其他模块产生影响 其他在实际开发中,往往会省略Director角色, 直接使用builder对象直接进行组装]]></content>
      <categories>
        <category>design pattern</category>
      </categories>
      <tags>
        <tag>design pattern</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[JDK中的Map]]></title>
    <url>%2F2018%2F08%2F14%2FJDK%E4%B8%AD%E7%9A%84HashMap%2F</url>
    <content type="text"><![CDATA[jdk1.7的hashMap源码注释123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316317318319320321322323324325326327328329330331332333334335336337338339340341342343344345346347348349350351352353354355356357358359360361import sun.security.action.GetPropertyAction;import java.security.AccessController;import java.util.Map;import java.util.Objects;/** * jdk1.7 HashMap的实现 * @author zonzie * @date 2018/7/9 19:50 */public class TestHashMap7&lt;K, V&gt; &#123; /** 初始容量, 默认16 */ static final int DEFAULT_INITIAL_CAPACITY = 1 &lt;&lt; 4; /** 最大初始容量, 2^30 */ static final int MAXIMUM_CAPACITY = 1 &lt;&lt; 30; /** 负载因子, 默认0.75, 负载因子越小, hash冲突几率越低 */ static final float DEFAULT_LOAD_FACTOR = 0.75f; /** 初始化一个Entry数组 */ static final Entry&lt;?,?&gt;[] EMPTY_TABLE = &#123;&#125;; /** 将初始化好的空数组赋值给table, table数组是hashMap实际存储数据的地方,并不在EMPTY_TABLE数组中 */ transient Entry&lt;K, V&gt;[] table = (Entry&lt;K, V&gt;[]) EMPTY_TABLE; /** HashMap实际存储的元素个数 */ transient int size; /** 临界值(HashMap实际能存储的大小), 公式为(threshold = capacity * loadFactor) */ int threshold = 1; /** 负载因子 */ final float loadFactor; /** HashMap 的结构被修改的次数, 用于迭代器 */ transient int modCount; /**散列的默认阈值*/ static final int ALTERNATIVE_HASHING_THRESHOLD_DEFAULT = Integer.MAX_VALUE; int hashSeed = 0; // holds values which can't be initialized until after VM is booted. private static class Holder &#123; //Table capacity above which to switch to use alternative hashing. static final int ALTERNATIVE_HASHING_THRESHOLD; static &#123;// 关于AccessController.doPrivileged的解释 http://www.blogjava.net/DLevin/archive/2012/11/02/390637.html// 关于jdk.map.althashing.threshold https://my.oschina.net/huangy/blog/1619144 String altThreshold = AccessController.doPrivileged(new GetPropertyAction(("jdk.map.althashing.threshold"))); int threshold; try &#123; threshold = (null != altThreshold) ? Integer.parseInt(altThreshold) : ALTERNATIVE_HASHING_THRESHOLD_DEFAULT; // disable alternative hashing if -1 if(threshold == -1) &#123; threshold = Integer.MAX_VALUE; &#125; if(threshold &lt; 0) &#123; throw new IllegalArgumentException("value must be positive"); &#125; &#125; catch (IllegalArgumentException failed) &#123; throw new Error("Illegal value for 'jdk.map.althashing.threshold'", failed); &#125; ALTERNATIVE_HASHING_THRESHOLD = threshold; &#125; &#125; // 指定初始化容量和负债因子的构造 public TestHashMap7(int initialCapacity, float loadFactor) &#123; // 判断设置的容量和负载因子合不合理 if(initialCapacity &lt; 0) throw new IllegalArgumentException("illegal initial capacity: " + initialCapacity); if(initialCapacity &gt; MAXIMUM_CAPACITY) initialCapacity = MAXIMUM_CAPACITY; if(loadFactor &lt;= 0 || Float.isNaN(loadFactor)) throw new IllegalArgumentException("Illegal load factor: " + loadFactor); // 设置负载因子,临界值此时为默认大小, 后面第一次put时由inflateTable(int toSize) 方法初始化一个数组table this.loadFactor = loadFactor; threshold = initialCapacity; &#125; public TestHashMap7(int initialCapacity) &#123; this(initialCapacity, DEFAULT_LOAD_FACTOR); &#125; // 根据已有的map创建一个新的相应容量的map public TestHashMap7(Map&lt;? extends K, ? extends V&gt; m) &#123; this(Math.max((int) (m.size() / DEFAULT_LOAD_FACTOR) + 1, DEFAULT_INITIAL_CAPACITY), DEFAULT_LOAD_FACTOR); &#125; public TestHashMap7() &#123; this(DEFAULT_INITIAL_CAPACITY, DEFAULT_LOAD_FACTOR); &#125; /** *初始化表的长度 * @param toSize */ private void inflateTable(int toSize) &#123; int capacity = roundUpToPowerOf2(toSize); threshold = (int) Math.min(capacity * loadFactor, MAXIMUM_CAPACITY + 1); // 创建一个Entry数组,作为最初的table table = new Entry[capacity]; // 是否需要改变hashSeed的值 initHashSeedAsNeeded(capacity); &#125; // 判断是否需要给hashSeed重新赋值,如果重新赋值,需要重新计算hash值和桶的位置 final boolean initHashSeedAsNeeded(int capacity) &#123; boolean currentAltHashing = hashSeed != 0; boolean useAltHashing = sun.misc.VM.isBooted() &amp;&amp; (capacity &gt;= Holder.ALTERNATIVE_HASHING_THRESHOLD); boolean switching = currentAltHashing ^ useAltHashing; if(switching) &#123; hashSeed = useAltHashing ? sun.misc.Hashing.randomHashSeed(this) : 0; &#125; return switching; &#125; // 计算容量的大小 private static int roundUpToPowerOf2(int number) &#123; return number &gt;= MAXIMUM_CAPACITY ? MAXIMUM_CAPACITY : (number &gt; 1) ? Integer.highestOneBit((number-1) &lt;&lt; 1) : 1; &#125; // 计算hash值 final int hash(Object k) &#123; int h = hashSeed; if(0 != h &amp;&amp; k instanceof String) &#123; return sun.misc.Hashing.stringHash32((String) k); &#125; h ^= k.hashCode(); h ^= (h &gt;&gt;&gt; 20) ^ (h &gt;&gt;&gt; 12); return h ^ (h &gt;&gt;&gt; 7) ^ (h &gt;&gt;&gt; 4); &#125; // 计算索引,桶的位置 static int indexFor(int h, int length) &#123; int i = h &amp; (length - 1); return i; &#125; // map的尺寸 public int size() &#123; return size; &#125; // 判断是否为空 public boolean isEmpty() &#123; return size == 0; &#125; // 获取null key的值 private V getForNullKey() &#123; if(size == 0) &#123; return null; &#125; for(Entry&lt;K,V&gt; e = table[0]; e != null; e = e.next) &#123; if(e.key == null) return e.value; &#125; return null; &#125; // 判断是否存在key public boolean containsKey(Object key) &#123; return getEntry(key) != null; &#125; // 获取一个Entry private Entry&lt;K,V&gt; getEntry(Object key) &#123; if(size == 0) &#123; return null; &#125; int hash = (key == null) ? 0 : hash(key); int i = indexFor(hash, table.length); // 遍历索引值为i的位置的entry的所有的元素 for(Entry&lt;K,V&gt; e = table[i]; e != null; e = e.next) &#123; Object k; // 判断key的hash值是否相等,同时key的equals方法需要返回true if(e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) return e; &#125; return null; &#125; public V put(K key, V value) &#123; if(table == EMPTY_TABLE) &#123; // 如果没有初始化table的长度,赋予默认值16,表的容量是16*0.75=12 inflateTable(threshold); &#125; if(key == null) return putForNullKey(value); int hash = hash(key); int i = indexFor(hash, table.length); // 遍历索引为i的entry for(Entry&lt;K,V&gt; e = table[i]; e != null; e = e.next) &#123; Object k; // 如果key的hash值相等同时key值也相等,用新的value替换旧的value,并返回 if(e.hash == hash &amp;&amp; ((k = e.key) == key || key.equals(k))) &#123; V oldValue = e.value; e.value = value; return oldValue; &#125; &#125; // 修改次数加1 modCount++; // 添加一个新的entry addEntry(hash, key, value, i); return null; &#125; // null值null键单独处理 private V putForNullKey(V value) &#123; for(Entry&lt;K,V&gt; e = table[0]; e != null; e = e.next) &#123; if(e.key == null) &#123; V oldValue = e.value; e.value = value;// e.recordAccess(this); return oldValue; &#125; &#125; modCount++; addEntry(0, null, value, 0); return null; &#125; public V get(Object key) &#123; if(key == null) return getForNullKey(); Entry&lt;K,V&gt; entry = getEntry(key); return null == entry ? null : entry.getValue(); &#125; // 静态内部类Entry,链表结构,1.7的hashMap使用拉链法解决hash碰撞 static class Entry&lt;K, V&gt; implements Map.Entry&lt;K,V&gt; &#123; final K key; V value; Entry&lt;K,V&gt; next; int hash; /** * 创建一个Entry * @param h key的hash值 * @param k key * @param v value * @param n 下一个节点 */ Entry(int h, K k, V v, Entry&lt;K,V&gt; n) &#123; value = v; next = n; key = k; hash = h; &#125; public K getKey() &#123; return key; &#125; public V getValue() &#123; return value; &#125; // 设置新值,返回旧值 public V setValue(V newValue) &#123; V oldValue = value; value = newValue; return oldValue; &#125; public final boolean equals(Object o) &#123; if(!(o instanceof Map.Entry)) return false; Map.Entry e = (Map.Entry)o; Object k1 = getKey(); Object k2 = e.getKey(); if(k1 == k2 || (k1 != null &amp;&amp; k1.equals(k2))) &#123; Object v1 = getValue(); Object v2 = e.getValue(); if(v1 == v2 || v1 != null &amp;&amp; v1.equals(v2)) return true; &#125; return false; &#125; public final int hashCode() &#123; return Objects.hashCode(getKey()) ^ Objects.hashCode(getValue()); &#125; public final String toString() &#123; return getKey() + "=" + getValue(); &#125; &#125; void addEntry(int hash, K key, V value, int bucketIndex) &#123; // 如果table的长度大于临界值同时桶的位置至少有一个元素,需要对表进行扩容 if((size &gt;= threshold) &amp;&amp; (null != table[bucketIndex])) &#123; resize(2 * table.length); // 扩容以后需要重新计算hash值 hash = (null != key) ? hash(key) : 0; // 重新计算桶的位置 bucketIndex = indexFor(hash, table.length); &#125; // 创建一个新的entry createEntry(hash, key, value, bucketIndex); &#125; // 根据给定的参数创建一个新的entry void createEntry(int hash, K key, V value, int bucketIndex) &#123; // 取出指定位置的entry Entry&lt;K,V&gt; e = table[bucketIndex]; // 创建的新的entry放在指定的桶的位置上 table[bucketIndex] = new Entry&lt;&gt;(hash, key, value, e); // map元素个数加1 size++; &#125; // 表扩容 void resize(int newCapacity) &#123; Entry[] oldTable = table; int oldCapacity = oldTable.length; // 如果容量达到最大值,不再扩容,直接返回 if(oldCapacity == MAXIMUM_CAPACITY) &#123; threshold = Integer.MAX_VALUE; return; &#125; // 创建新的table,指定新的容量 Entry[] newTable = new Entry[newCapacity]; // 迁移数据到新的表 transfer(newTable, initHashSeedAsNeeded(newCapacity)); table = newTable; // 重新指定阈值 threshold = (int)Math.min(newCapacity * loadFactor, MAXIMUM_CAPACITY+1); &#125; // 将旧表的数据迁移到新的扩容后的表,同时确定是否需要重新计算hash值 void transfer(Entry[] newTable, boolean rehash) &#123; int newCapacity = newTable.length; // 遍历旧的表 for(Entry&lt;K,V&gt; e : table) &#123; while (null != e) &#123; Entry&lt;K,V&gt; next = e.next; if(rehash) &#123; // 使用新的hsahseed 重新计算hash值 e.hash = null == e.key ? 0 : hash(e.key); &#125; // 根据hash值重新计算桶的位置 int i = indexFor(e.hash, newCapacity); // 将entry中的next赋值为i处的元素 e.next = newTable[i]; // 再将i处的元素重新赋值为整个entry newTable[i] = e; // 指向旧表中entry的下一个节点 e = next; &#125; &#125; &#125;&#125; ThreadLocal的源码注释123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316317318319320321322323324325326327328329330331332333334335336337338339340341342343344345346347348349350351352353354355356357358359360361362363364365366367368369370371372373374375376377378379380381382383384385386387388389390391392393394395396397398399400401402403404405406407408409410411412413414415416417418419420421422423424425426427428429430431432433434435436437438439440441442443444445446447448449450451452453454455456457458459460461462463464465466467468469470471472473474475476477478479480481482483484485486487488489490491492493494495496497498499500501502503504505506507508509510511512513514515516517518519520521522523524525526527528529530531532533534535536537538539540541542543544545import java.lang.ref.WeakReference;import java.util.concurrent.atomic.AtomicInteger;/** * @author zonzie * @date 2018/8/27 15:24 */public class ThreadLocalTest&lt;T&gt; &#123; /** * threadLocals基于每一个线程的线性检测哈希映射附加到每一个线程上, * ThreadLocal对象本身作为key, 通过threadLocalHashCode搜索, * 这是一个自定义的hashcode, 消除了在相同线程数使用连续构造的threadLocal的常见情况下的冲突,同时在不太常见的情况下保持良好的行为 */ private final int threadLocalHashCode = nextHashCode(); /** * 给出下一个hashcode,从零开始 */ private static AtomicInteger nextHashCode = new AtomicInteger(); /** * magic number ,以这个数为间隙的数值与2^n取模得到的数值可以均匀的分布在整个哈希表中 * ThreadLocalMap使用的解决冲突的方法是 "线性探测法", * 均匀分布的好处是可以很快就探测到下一个临近的可用的slot,从而保证效率,因此哈希表的大小要保证是2^n * 和连续增长的hashcode不同, 0x61c88647 更适合长度为2^n的表 */ private static final int HASH_INCREMENT = 0x61c88647; /** * 返回下一个hashcode */ private static int nextHashCode() &#123; return nextHashCode.getAndAdd(HASH_INCREMENT); &#125; /** * 为threadLocal初始化一个值 */ protected T initialValue() &#123; return null; &#125; /** * 创建一个thread local 变量 */ public ThreadLocalTest() &#123; &#125; /** * 返回当前线程的此线程局部变量副本中的值 * 如果变量没有当前线程的值，则首先将其初始化为调用initialValue方法返回的值 * @return */ public T get() &#123; Thread t = Thread.currentThread(); ThreadLocalMap map = getMap(t); if(map != null) &#123; ThreadLocalMap.Entry e = map.getEntry(this); if(e != null) return (T) e.value; &#125; return setInitialValue(); &#125; /** * * @return */ private T setInitialValue() &#123; T value = initialValue(); Thread t = Thread.currentThread(); ThreadLocalMap map = getMap(t); if(map != null) map.set(this,value); else createMap(t, value); return value; &#125; public void set(T value) &#123; Thread t = Thread.currentThread(); ThreadLocalMap map = getMap(t); if (map != null) map.set(this, value); else createMap(t, value); &#125; /** * 获取和一个线程关联的map * @param t * @return */ private ThreadLocalMap getMap(Thread t) &#123; return t.threadLocals; &#125; /** * 移除一个元素 */ private void remove() &#123; ThreadLocalMap m = getMap(Thread.currentThread()); if(m != null) m.remove(this); &#125; /** * 创建一个和threadLocal关联的map * @param t * @param firstValue */ void createMap(Thread t, T firstValue) &#123; t.threadLocals = new ThreadLocalMap(this, firstValue); &#125; static ThreadLocalMap createInheritedMap(ThreadLocalMap parentMap) &#123; return new ThreadLocalMap(parentMap); &#125; T childValue(T parentValue) &#123; throw new UnsupportedOperationException(); &#125; /** * threadLocalMap 是个自定义的哈希映射,仅适合维护threadLocal的值, * 为了帮助处理非常大且长寿命的用法，哈希表条目使用WeakReferences作为键, * 但是，由于未使用引用队列，因此只有在表开始空间不足时才能保证删除过时条目 */ static class ThreadLocalMap &#123; /** * 这个entries 在这个哈希映射中继承自WeakReference, * 使用主要引用字段作为key(总会是一个threadLocal对象) * 需要注意的是key是null时,意味着这个key不再被引用, 所以这个这个entry会从表中擦除, * 这些entries被称为 "陈旧的entry(stale entries)" * -------------------------------------------- * 使用弱引用: java中的四级引用中的第三级,一个对象,如果没有强引用链可达,一般活不过下一次GC * 这里使用弱引用,在threadLocal没有强引用可达时, 会被GC回收, 在ThreadLocalMap里对应的Entry会失效,这为垃圾清理提供便利 */ static class Entry extends WeakReference&lt;ThreadLocalTest&gt; &#123; // ThreadLocal中实际存储的数据 Object value; public Entry(ThreadLocalTest k, Object v) &#123; super(k); value = v; &#125; &#125; /** * 初始化容量 -- 必须是2^n次方 */ private static final int INITIAL_CAPACITY = 16; /** * 这个table * table.length 必须是2^n次方 */ private Entry[] table; /** * 表中的entry的个数 */ private int size = 0; /** * 需要扩容的阈值,默认是0 */ private int threshold; /** * 设置阈值,最坏情况下 2/3 负载因子 */ private void setThreshold(int len) &#123; threshold = len * 2 / 3; &#125; /** * 上一个索引 */ private static int nextIndex(int i, int len) &#123; return ((i + 1 &lt; len) ? i + 1 : 0); &#125; /** * 下一个索引 */ private static int prevIndex(int i, int len) &#123; return ((i -1) &gt;= 0 ? i - 1 : len - 1); &#125; /** * 构建一个新的map,初始化容量 (firstKey, firstValue) * ThreadLocalMaps是延迟构建的,只有在至少有一个entry的时候去构建一个ThreadLocalMaps */ ThreadLocalMap(ThreadLocalTest firstKey, Object firstValue) &#123; // 初始化table数组 table = new Entry[INITIAL_CAPACITY]; // 用firstKey的threadLocalhashCode与初始化大小16取模得到哈希值,使用"&amp;(2^n - 1)"代替"%(2^n)",加快计算效率 int i = firstKey.threadLocalHashCode &amp; (INITIAL_CAPACITY - 1); // 创建这个节点 table[i] = new Entry(firstKey, firstValue); // 设置节点表的大小 = 1 size = 1; // 设定需要扩容的阈值 setThreshold(INITIAL_CAPACITY); &#125; /** * 构建一个新的map, 包含所有的继承的ThreadLocals,只会被createInheritedMap调用 * @param parentMap */ private ThreadLocalMap(ThreadLocalMap parentMap) &#123; Entry[] parentTable = parentMap.table; int len = parentTable.length; setThreshold(len); table = new Entry[len]; for(int j = 0; j &lt; len; j++) &#123; Entry e = parentTable[j]; if(e != null) &#123; ThreadLocalTest key = e.get(); if(key != null) &#123; Object value = key.childValue(e.value); Entry c = new Entry(key, value); int h = key.threadLocalHashCode &amp; (len - 1); while (table[h] != null) h = nextIndex(h, len); table[h] = c; size++; &#125; &#125; &#125; &#125; /** * 获取和这个entry关联的key,这里只处理直接命中的情况, * 其他情况由getEntryAfterMiss处理,这里被设计为最大化直接命中的性能 * @param key threadLocalTest 对象 * @return 与key关联的entry */ private Entry getEntry(ThreadLocalTest key) &#123; // 根据key获取索引 int i = key.threadLocalHashCode &amp; (table.length - 1); Entry e = table[i]; // 对应的Entry存在并且没有失效且弱引用指向的ThreadLocal就是key,则命中返回 if(e != null &amp;&amp; e.get() == key) return e; else // 没有直接命中,继续向后找 return getEntryAfterMiss(key, i, e); &#125; /** * 当getEntry方法没有直接在哈希槽中发现这个值时被调用 * @param key threadLocalTest object * @param i key 的 hashcode * @param e 在table中的entry * @return 返回值 */ private Entry getEntryAfterMiss(ThreadLocalTest key, int i, Entry e) &#123; Entry[] tab = table; int len = tab.length; // 基于线性探测法不断向后探测直到遇到空的entry while(e != null) &#123; ThreadLocalTest k = e.get(); // 命中返回 if(k == key) return e; // key已经被回收,调用expungeStaleEntry清理无效的entry if(k == null) expungeStaleEntry(i); else // 继续往后走 i = nextIndex(i, len); &#125; return null; &#125; /** * 设置与这个key关联的值 * @param key threadLocalTest 对象 * @param value 要关联的值 */ private void set(ThreadLocalTest key, Object value) &#123; // 这里没有像getEntry的时候一样, 使用一个fast path, // 因为使用set去创建一个对象和替换一个已经存在的的对象一样常见 // 因此, fast path会更容易失败 Entry[] tab = table; int len = tab.length; int i = key.threadLocalHashCode &amp; (len - 1); // 线性探测, 基于一个索引向后找 for(Entry e = table[i]; e != null; e = tab[i = nextIndex(i, len)]) &#123; ThreadLocalTest k = e.get(); // 找到返回 if(k == key) &#123; e.value = value; return; &#125; // 替换失效的entry if(k == null) &#123; replaceStableEntry(key, value, i); return; &#125; &#125; table[i] = new Entry(key, value); int sz = ++size; if(!cleanSomeSlots(i,sz) &amp;&amp; sz &gt;= threshold) rehash(); &#125; /** * 移除这个key的entry */ private void remove(ThreadLocalTest key) &#123; Entry[] tab = table; int len = tab.length; int i = key.threadLocalHashCode &amp; (len - 1); for(Entry e = tab[i]; e != null; e = tab[i = nextIndex(i, len)]) &#123; // 显示的断开弱引用 e.clear(); // 进行段清理 expungeStaleEntry(i); return; &#125; &#125; /** * 将set操作期间遇到的陈旧entry替换为指定键的entry。 * 无论指定键的entry是否已存在，value参数中传递的值都存储在entry中 * * 作为副作用，此方法将清除包含所有的过时entry的。两个空槽之间的一系列entry都会被清除 * @param key the key * @param value the value associated with key * @param staleSlot 搜索key的时候遇到的第一个陈旧的entry */ private void replaceStableEntry(ThreadLocalTest key, Object value, int staleSlot) &#123; Entry[] tab = table; int len = tab.length; Entry e; // 先备份,再清理过时的entry // 避免由于GC释放串中的refs（即，每当GC运行时）不断进行增量重复。 // 向前扫描, 查找最前的一个无效的slot int slotToExpunge = staleSlot; for(int i = prevIndex(staleSlot, len); (e = tab[i]) != null; i = prevIndex(i, len)) &#123; if(e.get() == null) &#123; slotToExpunge = i; &#125; &#125; // Find either the key or trailing null slot of run, whichever // occurs first for(int i = nextIndex(staleSlot, len); (e = tab[i]) != null; i = nextIndex(i, len)) &#123; ThreadLocalTest k = e.get(); // 如果我们找到键，那么我们需要将它与旧的entry交换以维护哈希表顺序 // 旧的哈希槽将会被送到expungeStaleEntry去移除或者rehash if(k == key) &#123; // 更新value的值 e.value = value; tab[i] = tab[staleSlot]; tab[staleSlot] = e; // 如果存在,就开始擦除前面旧entry // 如果在扫描过程中(一开始的向前扫描和i之前的向后扫描) // 找到了之前的无效slot,则以那个位置作为清理的起点,否则以当前的i作为清理的起点 if(slotToExpunge == staleSlot) slotToExpunge = i; // 从slotToExpunge开始做一次连续段的清理,再做一次启发式的清理 cleanSomeSlots(expungeStaleEntry(slotToExpunge), len); return; &#125; // If we didn't find stale entry on backward scan, the // first stale entry seen while scanning for key is the // first still present in the run. // 如果当前的slot已经无效,并且向前扫描过程中没有无效的slot,则更新slotToExpunge为当前位置 if(k == null &amp;&amp; slotToExpunge == staleSlot) slotToExpunge = i; &#125; // 如果没有发现key, 把新的entry放到旧的槽中 tab[staleSlot].value = null; tab[staleSlot] = new Entry(key, value); // If there are any other stale entries in run, expunge them // 如果当前的slot已经无效,并且向前扫描过程中没有无效的slot,则做一次清理 if(slotToExpunge != staleSlot) cleanSomeSlots(expungeStaleEntry(slotToExpunge), len); &#125; /** * 核心清理函数 从staleSlot开是遍历,将无效(弱引用指向对象被回收)的entry清理(先将对应的value置空,再将table[i]置空,直到扫到空的entry) * 另外,对非空的entry做rehash * 这个函数的作用: 从staleSlot开始清理连续段的slot(断开强引用 rehash slot) * ----------- * 通过重新处理staleSlot和下一个空槽之间的任何可能碰撞的条目来清除过时的entry * 这也会删除在尾随空值之前遇到的任何其他陈旧entry * @param staleSlot * @return */ private int expungeStaleEntry(int staleSlot) &#123; Entry[] tab = table; int len = tab.length; // 擦除旧的槽中的entry,显示的断开强引用 tab[staleSlot].value = null; // 显示的设置entry为null, 以便于垃圾回收 tab[staleSlot] = null; size--; // rehash直到遇到null Entry e; int i; // 从i开始连续清理直到遇到为null的entry for(i = nextIndex(staleSlot, len); (e = tab[i]) != null; i = nextIndex(i ,len)) &#123; ThreadLocalTest k = e.get(); if(k == null) &#123; e.value = null; tab[i] = null; size--; &#125; else &#123; /* * 对于还没有被回收的情况,需要做一次rehash * * 如果rehash后,新的hashcode h != i, 则从h向后线性探测到第一个空的slot,把当前的entry放进去 */ int h = k.threadLocalHashCode &amp; (len - 1); if(h != i) &#123; tab[i] = null; // Unlike Knuth 6.4 Algorithm R, we must scan until // null because multiple entries could have been stale. // 源码注释表示: 不能套用Knuth高德纳的著作TAOCP6.4章中的R算法 // R算法描述了如何从使用线性探测的散列表中删除一个元素, R算法维护了一个上次删除元素的index, // 当在某个非空连续段中扫描到某个entry的哈希值取模后的索引,还没遍历到时, 会将entry挪到index那个位置,并且 // 更新当前位置为新的index,然后继续向后扫描直到遇到空的entry // 由于使用了弱引用,每个slot的状态有 有效,无效,空,不能直接使用R算法 // expungeStaleEntry函数在扫描过程中会对无效的slot清理将之转换为空的slot // 直接使用R算法, 可能会出现具有相同的哈希值的entry之间断开(中间有空的entry) while (tab[h] != null) h = nextIndex(h, len); tab[h] = e; &#125; &#125; &#125; // 返回staleSlot之后第一个空的slot索引 return i; &#125; /** * 启发式扫描一些旧的entry的slot。 * 添加新元素或删除另一个旧元素时会调用此方法。 * 它执行对数扫描，作为无扫描（快速但保留垃圾）和与元素数量成比例的多个扫描之间的平衡， * 这将找到所有垃圾但会导致一些插入花费O（n）时间。 * 这个函数会有两处会被调用, 一处是插入的时候可能会被调用,另外是在替换无效slot的时候可能会被调用 * 区别是前者传入的n为元素的个数, 后者为table的容量 * @param i 一个已知没有旧的entry的位置。 扫描从i之后的元素开始。 * @param n 扫描控制次数 正常情况下,如果扫描了log n次,没有发现无效的slot,函数也就结束了 * 但这里如果发现了无效的slot,会将n置为table的长度len,做一次连续段的清理,再从下一个空的slot开始继续扫描 * @return true if any stale entries have been removed. */ private boolean cleanSomeSlots(int i, int n) &#123; boolean removed = false; Entry[] tab = table; int len = tab.length; do &#123; // i 在任何情况下自己都不会是一个无效的slot,所以从下一个开始判断 i = nextIndex(i, len); Entry e = tab[i]; if(e != null &amp;&amp; e.get() == null) &#123; n = len; removed = true; i = expungeStaleEntry(i); &#125; &#125; while ((n &gt;&gt;&gt;= 1) != 0); return removed; &#125; /** * 首先扫描整个表,删除无用的entry * 如果不足以缩小表的大小, 则表的大小加倍 */ private void rehash() &#123; expungeStaleEntries(); if(size &gt;= threshold - threshold / 4) &#123; resize(); &#125; &#125; /** * 扩容 * 表的容量加倍 */ private void resize() &#123; Entry[] oldTab = table; int oldLen = oldTab.length; int newLen = oldLen * 2; Entry[] newTab = new Entry[newLen]; int count = 0; for(int j = 0; j &lt; oldLen; ++j) &#123; Entry e = oldTab[j]; if(e != null) &#123; ThreadLocalTest k = e.get(); if(k == null) &#123; e.value = null; &#125; else &#123; int h = k.threadLocalHashCode &amp; (newLen - 1); while (newTab[h] != null) h = nextIndex(h, newLen); newTab[h] = e; count++; &#125; &#125; &#125; setThreshold(newLen); size = count; table = newTab; &#125; /** * 擦除表中的所有的无用的节点 */ private void expungeStaleEntries() &#123; Entry[] tab = table; int len = tab.length; for(int j = 0; j &lt; len; j++) &#123; Entry e = tab[j]; if(e != null &amp;&amp; e.get() == null) expungeStaleEntry(j); &#125; &#125; &#125;&#125; 参考内容: http://www.blogjava.net/DLevin/archive/2012/11/02/390637.html https://my.oschina.net/huangy/blog/1619144 拉链法: http://www.cnblogs.com/lizhanwu/p/4303410.html 为啥是31: https://blog.csdn.net/qq_38182963/article/details/78940047 https://stackoverflow.com/questions/299304/why-does-javas-hashcode-in-string-use-31-as-a-multiplier%EF%BC%89 https://crossoverjie.top/2018/07/23/java-senior/ConcurrentHashMap/ https://www.cnblogs.com/chenssy/p/3521565.html ThreadLocal解释: https://www.cnblogs.com/micrari/p/6790229.html java中的引用:https://www.cnblogs.com/huajiezh/p/5835618.html]]></content>
      <categories>
        <category>hashMap</category>
      </categories>
      <tags>
        <tag>hash算法</tag>
        <tag>HashMap</tag>
        <tag>threadLocal</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[redis实现分布式锁]]></title>
    <url>%2F2018%2F08%2F13%2Fredis%E5%AE%9E%E7%8E%B0%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81%2F</url>
    <content type="text"><![CDATA[redis实现分布式锁基本的实现思路 一个线程,在redis中存入一个加锁的key,和一个特有的value,表示获取到了锁 线程需要加锁的操作结束后, 再删除这个key,删除之前需要比对value是否一致 其他线程在操作相同的资源之前,也去存入相同的key,如果这个key已经存在,则存入key失败,即获取锁失败,一直重试直到获取锁成功,或者达到超时时间放弃获取锁 redis实现的并不可靠的方法 这里使用的spring提供的redisTemplate,需要做一些简单的配置 由于redisTemplate没有提供同时设置NX,PX参数的方法,因此这里使用lua脚本实现 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162/** * 加锁 * @param key * @param value * @return */@GetMapping(value = "lock")public Object lock(String key, String value) &#123; String script = "local key = KEYS[1]; local value = ARGV[1]; if redis.call('set', key, value, 'NX' ,'PX', 5000) then return 1 else return 0 end"; DefaultRedisScript&lt;Long&gt; redisScript = new DefaultRedisScript&lt;&gt;(script, Long.class); Object execute = redisTemplate.execute(redisScript, Collections.singletonList(key), Collections.singletonList(value)); System.out.println(execute); return execute;&#125;/** * 阻塞锁 */@GetMapping(value = "blockLock")public String blockLock(String key, String value) throws InterruptedException &#123; // 被阻塞的时间超过5秒就停止获取锁 int blockTime = 5000; // 默认的间隔时间 int defaultTime = 1000; for(;;) &#123; if(blockTime &gt;= 0) &#123; String script = "local key = KEYS[1]; local value = ARGV[1]; if redis.call('set', key, value, 'NX' ,'PX', 5000) then return 1 else return 0 end"; DefaultRedisScript&lt;Long&gt; redisScript = new DefaultRedisScript&lt;&gt;(script, long.class); Long result = redisTemplate.execute(redisScript, Collections.singletonList(key), value); System.out.println("try lock ... ,result: "+result); if(result != null &amp;&amp; result == 1) &#123; // 得到了锁 return "lock success"; &#125; else &#123; blockTime -= defaultTime; Thread.sleep(1000); &#125; &#125; else &#123; // 已经超时 return "lock timeout..., please retry later..."; &#125; &#125;&#125;/** * 解锁 * @param key * @param value */@GetMapping("unlock")public String unlock(String key, String value) &#123; String script = "if redis.call('get', KEYS[1]) == ARGV[1] then return redis.call('del',KEYS[1]) else return 0 end"; DefaultRedisScript&lt;Long&gt; redisScript = new DefaultRedisScript&lt;&gt;(script, Long.class); Long execute = redisTemplate.execute(redisScript, Collections.singletonList(key), value); System.out.println("unlock result: "+execute); if(execute != null &amp;&amp; execute != 0) &#123; // 解锁成功 return "unlock success"; &#125; else &#123; return "unlock failed"; &#125;&#125; 缺点: 仅适合没有slave的单节点redis,因为slave和master之间的数据是异步复制的,有可能并不一致,只要不是单节点,不推荐使用 redis官方推荐的方法-redLockredLock-参考文档:https://redis.io/topics/distlock redis把分布式锁的算法称之为redLock-红锁, 红锁需要N个(N&gt;=3)redis独立节点,节点之间没有任何联系,保持独立即可. 基本实现思路: 客户端在每个redis实例上获取锁,只要大多数实例上获取锁成功就算加锁成功, redLock的算法实现各种语言的版本有很多,java的实现是redisson,可以直接引入使用 客户端获取锁的基本流程 首先客户端记录当前的时间,用于计算获取锁的耗时 客户端使用相同的key和随机的value,从所有的redis节点上获取锁.客户端在每个实例上设置锁的过程,需要设置超时时间(5-50ms),不成功就换下一个实例继续设置锁,用来防止客户端阻塞在一个down掉的实例上 客户端需要计算获得锁的总耗时.客户端从至少N/2+1个节点上成功获取锁,且总耗时小于锁过期时间才能成功获得锁 客户端获得锁之后,该锁的有效期不再是最初的过期时间,因为客户端要从多个节点上获得锁,需要去掉这些过程耗时 如果客户端最终获得锁失败,必须在所有的节点上执行锁释放的操作 执行完毕后,主动释放所有的节点上的锁 redLock保证了 锁的互斥性,同一时间只能有一个锁 不会死锁 多节点容错,只要大部分节点获取锁成功就算得到了锁 使用redisson的例子 1234567891011121314Config config = new Config();config.useSingleServer().setAddress("redis://192.168.198.128:6379");RedissonClient redisson1 = Redisson.create(config);// 同样的方法再创建两个新的连接 redisson2, redisson3RLock lock1 = redisson1.getLock("resource");RLock lock2 = redisson2.getLock("resource");RLock lock3 = redisson3.getLock("resource");RedissonRedLock lock = new RedissonRedLock(lock1, lock2, lock3);// 获取锁boolean res = lock.tryLock(WAIT_TIME, TIME_OUT, TimeUnit.SECONDS);// 解锁lock.unlock(); 一个简单的工具类 123456789101112131415161718192021222324252627282930313233343536373839404142434445public class RedissonRedLocker &#123; private static final int WAIT_TIME = 10; // 10s private static final long TIME_OUT = 10; // 10s private static final String REDIS_NODES_URL = "ip1:port,ip2:port,ip3:port"; private static RedissonClient[] clients; static &#123; initRedisInstance(); &#125; private static void initRedisInstance() &#123; String[] redisAddrs = REDIS_NODES_URL.split(","); List&lt;RedissonClient&gt; list = new ArrayList&lt;RedissonClient&gt;(); for(String addr: redisAddrs) &#123; list.add(getRedisInstance(addr)); &#125; clients = list.toArray(clients); &#125; private static RedissonClient getRedisInstance(String addr) &#123; Config config = new Config(); config.useSingleServer().setAddress("redis://" + addr); return Redisson.create(config); &#125; private static RedissonRedLock getRedLock(String resource) &#123; List&lt;RLock&gt; locks = new ArrayList&lt;RLock&gt;(); for(RedissonClient client : clients) &#123; locks.add(client.getLock(resource)); &#125; return new RedissonRedLock((RLock[]) locks.toArray()); &#125; private static boolean tryLock(RedissonRedLock lock) &#123; boolean res = false; try &#123; res = lock.tryLock(WAIT_TIME, TIME_OUT, TimeUnit.SECONDS); &#125; catch(InterruptedException e) &#123; e.printStackTrace(); lock.unlock(); &#125; return res; &#125;&#125; 参考内容: http://baijiahao.baidu.com/s?id=1596540166265981065&amp;wfr=spider&amp;for=pc https://blog.csdn.net/l1028386804/article/details/73523810 https://crossoverjie.top/2018/03/29/distributed-lock/distributed-lock-redis/ https://blog.csdn.net/forezp/article/details/70305336]]></content>
      <categories>
        <category>redis</category>
      </categories>
      <tags>
        <tag>redis</tag>
        <tag>分布式</tag>
        <tag>lock</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Lua语法基础]]></title>
    <url>%2F2018%2F08%2F09%2FLua%E8%AF%AD%E6%B3%95%E5%9F%BA%E7%A1%80%2F</url>
    <content type="text"><![CDATA[常用语法 单行注释: 两个减号 多行注释: 1234--[[ 多行注释 多行注释]]-- 标示符: 不允许使用@$%等特殊字符,并且区分大小写 关键字: 与一般与语言差别不大,特别的有until,elseif 全局变量: 默认情况下,变量总是全局变量,变量不需要声明,没有初始化也不会错,只不过得到的结果是nil,删除一个全局变量,只需要给它赋值nil 数据类型: 12345678nil 表示一个无效值boolean 布尔类型:true/falsenumber 表示双精度类型的实浮点数string 字符串由一对双引号或者单引号来表示function 由C或者Lua编写的函数userdata 表示任意存储在变量中的C数据结构thread 表示执行的独立线路,用于执行协同程序table Lua中的表其实是一个&quot;关联数组&quot;,表的创建通过&quot;构造表达式&quot;来完成 nil 打印一个没有赋值的变量,会输出nil 对于table和全局变量,nil有删除的作用 nil比较时应该加上双引号: type(x)==&quot;nil&quot; 输出true boolean 布尔 12345if false or nil then print("至少一个是true")else print("false和nil都为false")end string 字符串类型 可以用一对双引号或者单引号来表示 也可以用两个方括号来表示”一块”字符串 在对一个数字字符串进行运算时,lua会尝试将这个数字字符串转为数字 print(&quot;2&quot; + 6)&rArr;8.0 连接两个字符串使用” .. “: print(&quot;a&quot; .. &#39;b&#39;)&rArr;ab print(123 .. 1243)&rArr;1231243 使用#来计算字符串的长度,放在字符串的前面 len = “helloworld” print(#len)&rArr;10 table 表 创建一个空的表: local tbl1 = {} 直接初始化: local tbl2 = {“apple”, “grape”} table不会固定长度大小,有新的数据时table长度会自动增长 function 函数 在Lua中,函数被看作是”第一类值”,可以存在变量里12345678910111213141516171819202122232425function factorial1(n) if n == 0 then return 1 else return n * factorial1(n - 1) endendprint(factorial1(5))factorial2 = factorial1print(factorial2(5))-- -------------------------------- 通过匿名函数的方式传参function testFun(tab,fun) for k, v in pairs(tab) do print(fun(k,v)); endendtab=&#123;key1="var1",key2="val2"&#125;testFun(tab, function(key,val) return key.."="..val; end); thread 线程 在 Lua 里，最主要的线程是协同程序（coroutine）。它跟线程（thread）差不多，拥有自己独立的栈、局部变量和指令指针，可以跟其他协同程序共享全局变量和其他大部分东西。 线程跟协程的区别：线程可以同时多个运行，而协程任意时刻只能运行一个，并且处于运行状态的协程只有被挂起（suspend）时才会暂停。 userdata 自定义类型 userdata 是一种用户自定义数据，用于表示一种由应用程序或 C/C++ 语言库所创建的类型，可以将任意 C/C++ 的任意数据类型的数据（通常是 struct 和 指针）存储到 Lua 变量中调用。 lua中的变量 共有三种变量: 全局变量,局部变量,表中的域 lua中所有的变量都是全局变量,哪怕是语句块或者函数里,除非用local显示的声明为局部变量 局部变量的作用域为从声明位置开始到所在的语句块结束 变量的默认值均为nil 赋值语句: lua可以对多个变量同时赋值,a = &quot;hello&quot; .. &quot;world&quot;,a,b = 10,2*x, x,y = y,x 当变量的个数和值的个数不一致时, lua会以变量个数为基础采取以下策略 变量个数 &gt; 值的个数 –&gt; 按照变量个数补足nil 变量个数 &lt; 值得个数 –&gt; 多余得值会被忽略 索引 对table的索引使用[] t[i] t.i 循环 几种方式: while 循环 for循环 repeat..until 循环嵌套 循环控制: break1234while(true)do print("循环将永远执行下去")end 流程控制 控制结构的条件表达式结果可以是任何值, lua认为false和nil为假,true和非nil为真,所以lua中0也是真 12345--[ 0 为 true ]if(0)then print("0为true")end lua中的控制结构的语句 if语句 if..else 语句 if嵌套语句 函数定义 1234optional_function_scope function_name(argument1, argument2,argument3...,argumentn) function_body return result_params_comma_separatedend 解析 optional_function_scope: 该参数是可选的, 制定行函数是全局函数还是局部函数,未设置参数则默认是全局的,局部函数需要使用关键字local function_name: 指定函数的名称 argument1,argument2,argument3…,函数的参数,会以逗号隔开 function_body: 函数体,函数中需要执行的代码语句块 result_params_comma_separated: 函数返回值,Lua语言函数可以返回多个值, 以逗号隔开 实例 123456789101112--[[ 函数返回两个值的最大值 --]]function max(num1, num2) if(num1 &gt; num2) then result = num1; else result = num2; end return result;end-- 调用函数print("两个值比较最大值为 ", max(10,4))print("两个值比较最大值为 ", max(5,6)) lua中,将函数作为参数传递给函数 123456789101112myprint = function(param) print("这是打印函数 - ##", param, "##")endfunction add(num1, num2, functionPrint) result = num1 + num2 -- 调用传递的函数参数 functionPrint(result)endmyprint(10)-- myprint 函数作为参数传递add(2,5,myprint) 多返回值 lua函数可以返回多个结果值,比如string.find,其返回匹配串”开始和结束的下标”(如果不存在匹配串返回nil) 123&gt; s,e = string.find(&quot;www.runoob.com&quot;,&quot;runoob&quot;)&gt; print(s,e)5, 10 lua函数中, 在return后列出要返回的值的列表即刻返回多值 123456789101112function maximun(a) local mi = 1 -- 最大值索引 local m = a[mi] -- 最大值 for i, val in ipairs(a) do if val &gt; m then mi = i m = val end end return m, miendprint(maximun(&#123;8,10,23,12,5&#125;)) 可变参数 lua函数可以接受可变数目的参数,和C类似,在函数参数列表中使用... 表示有可可变的参数12345678function add(...)local s = 0 for i,v in ipairs&#123;...&#125; do --&gt; &#123;...&#125;表示一个由所有的变长的参数构成的数组 s = s + v end return sendprint(add(33,4,5,6,7)) ---&gt; 25 我们可以将可变参数赋值给一个变量 1234567891011121314151617181920212223function average(...) result = 0 local arg=&#123;...&#125; ---&gt; arg为一个局部表,局部变量 for i,v in ipairs(arg) do result = result + v end print("总共传入 ".. #arg .. "个数") return result/#argendprint("平均值为",average(10,5,3,4,5,6))// -------------执行结果为:总共传入 6 个数平均值为 5.5// -------------------------- 有时候我们可能需要几个固定参数加上可变参数,固定参数必须放在变长参数之前:function fwrite(fmt, ...) -- -&gt; 固定参数fmt return io.write(string.format(fmt, ...))endfwrite("runoob\n") -- -&gt; fmt = "runoob", 没有变长参数fwrite("%d%d\n",1,2) -- &gt; fmt = "%d%d", 变长参数为1和2 通常在遍历变长参数的时候只需要使用{…}, 然而变长参数可能会包含一些nil, 那么就可以用select函数来访问变长参数了: select(‘#’, …) 或者 select(n, …) select(‘#’, …) 返回可变参数的长度 select(n, …) 用于访问n到select(‘#’, …)的参数 调用select时, 必须传入一个固定实参selector(选择开关)和一系列变长参数,如果selector为数字n,那么select返回它的第n个可变实参,否则只能为字符串”#”,这样select会返回变长参数的总数12345678910do function foo(...) for i = 1, select('#', ...) do -- -&gt; 获取参数总数 local arg = select(i, ...); -- -&gt; 读取参数 print("arg", arg); end end foo(1,2,3,4);end 常用的字符串的操作 string.upper(argument): 字符串全部转为大写字母 string.lower(argument): 字符串转换为小写字母 string.gsub(mainString,findString,num): 在字符串中替换, mainString为要替换的字符串,findString为被替换的字符,replaceString要替换的字符, num替换次数(可以忽略,则全部忽略)string.gsub(&quot;aaaa&quot;,&quot;a&quot;,&quot;z&quot;,3) string.find(str,substr,[init,[end]]): 在一个指定的目标字符串中搜索指定的内容(第三个参数为索引),返回其具体位置,不存在就返回nil string.reverse(&quot;Lua&quot;): 字符串的反转 string.format(..): 返回一个类似printf的格式化字符串 string.char(arg)和string.byte(arg[,int]): char将整型数字转成支付并连接,byte转换字符为整数值(可以指定某个字符,默认第一个字符) string.len(arg): 计算字符串长度 string.rep(string,n): 返回字符串string的n个拷贝 string.gmatch(str,pattern): 回一个迭代器函数，每一次调用这个函数，返回一个在字符串 str 找到的下一个符合 pattern 描述的子串。如果参数 pattern 描述的字符串没有找到，迭代函数返回nil 1for word in string.gmatch("Hello Lua user","%a+") do print(word) end string.match(str, pattern, init): string.match()只寻找源字串str中的第一个配对. 参数init可选, 指定搜寻过程的起点, 默认为1. 在成功配对时, 函数将返回配对表达式中的所有捕获结果; 如果没有设置捕获标记, 则返回整个配对字符串. 当没有成功的配对时, 返回nil。 1string.match("I have 2 questions for you.", "%d+ %a+") lua迭代器 泛型for迭代器,泛型 for 在自己内部保存迭代函数，实际上它保存三个值：迭代函数、状态常量、控制变量。泛型 for 迭代器提供了集合的 key/value 对 123456789101112-- 语法格式for k,v in pairs(t) do print(k,v)end-- k,v 为变量列表,pairs为表达式列表-- 例子array = &#123;"Lua", "Tutorial"&#125;for key,value in ipairs(array)do print(key,value)end 泛型for的执行过程 初始化，计算in后面表达式的值，表达式应该返回泛型 for 需要的三个值：迭代函数、状态常量、控制变量；与多值赋值一样，如果表达式返回的结果个数不足三个会自动用nil补足，多出部分会被忽略 将状态常量和控制变量作为参数调用迭代函数（注意：对于for结构来说，状态常量没有用处，仅仅在初始化时获取他的值并传递给迭代函数） 将迭代函数返回的值赋给变量列表 如果返回的第一个值为nil循环结束，否则执行循环体 回到第二步再次调用迭代函数 无状态迭代器 无状态迭代器是指不保留任何状态的迭代器,因此在循环中我们可以利用无状态迭代器避免创建闭包花费额外的代价,每一次迭代,迭代函数都是用两个变量(状态常量和控制常量)的值作为参数被调用,一个无状态的迭代器只利用这两个值可以获取下一个元素 12345678910111213141516171819202122232425262728-- 使用一个简单的函数来实现迭代器,实现数字n的平方:function square(iteratorMaxCount,currentNumber) if currentNumber &lt; iteratorMaxCount then currentNumber = currentNumber + 1 return currentNumebr, currentNumber*currentNumber endendfor i,n in square,3,0do print(i,n)end-- 迭代的状态包括被遍历的表(循环过程中不会改变的状态的常量)和当前的索引的下标(控制变量),ipairs和迭代函数function iter(a,i) i = i + 1 local v = a[i] if v then return i,v endendfunction ipairs(a) return iter, a, 0end-- 当Lua调用ipairs(a)开始循环时，他获取三个值：迭代函数iter、状态常量a、控制变量初始值0；然后Lua调用iter(a,0)返回1,a[1]（除非a[1]=nil）；第二次迭代调用iter(a,1)返回2,a[2]……直到第一个nil元素 多状态的迭代器 很多情况下,迭代器需要保存多个状态信息而不是简单的状态常量和控制变量,,还有一种方法是将所有的状态信息封装到table内,将table作为迭代器的状态常量,因为这种情况下可以将所有的信息存放在table内,所以迭代函数通常不需要第二个参数 123456789101112131415161718192021-- 创建自己的迭代器array = &#123;"lua","tutorial"&#125;function elementIterator(collection) local index = 0 local count = #collection -- 闭包函数 return function() index = index + 1 if index &lt;= count then -- 返回迭代器的当前的元素 return collection[index] end endendfor element in elementIterator(array)do print(element)end table表 table 是lua的一种数据结构用来帮我们创建不同的数据类型,如:数组,字典等lua table 使用关联型数组,你可以用任意类型的值来做数组恩典索引,但是这个值不能是nillua也是通过table来解决模块(module),包(package)和对象(Object)的 12345678910111213141516171819202122232425262728293031323334353637-- 初始化表mytable = &#123;&#125;-- 指定值mytable[1] = "lua"-- 移除引用mytable = nil-- lua垃圾回收会释放内存---------------------------------------- 我们为a设置元素,然后将a赋值给b,则a与b都指向同一个内存.如果a设置为nil,则b同样能访问table元素.如果没有指定的变量指向a,lua的垃圾回收机制会清理相对应的内存-- 简单的tablemytable = &#123;&#125;print("mytable的类型是 ",type(mytable))mytable[1] = "lua"print("mytable 索引为1的元素是:",mytable[1])print("mytable 索引为wow的元素是",mytable["wow"])-- alternatetable和mytable是指向同一个tablealternatetable = mytableprint("alternatetable索引为1的元素是 ", alternatetable[1])print("mytable索引为wow的元素是 ",alternatetable["wow"])alternatetable["wow"] = "修改后"print("mytable索引为wow的元素是 ",mytable["wow"])-- 释放变量alternatetable = nilprint("alternatetable是 ",alternatetable)-- mytable 仍然可以访问print("mytable索引为wow的元素是 ", mytable["wow"])mytbale = nilprint("mytable是 ",mytable) table 操作 常用的方法 table th:first-of-type { width: 100px; } 序号 方法&amp;用途 1 table.concat(table[,sep[,start[,end]]]):concat是concatenate(连锁, 连接)的缩写. table.concat()函数列出参数中指定table的数组部分从start位置到end位置的所有元素, 元素间以指定的分隔符(sep)隔开 2 table.insert(table,[pos[,value]]):在table数组部分指定位置(pos)插入值为value的一个元素,pos参数可选,默认为数组部分末尾 3 table.maxn(table):指定table中所有正数key值中最大的key值. 如果不存在key值为正数的元素, 则返回0。(Lua5.2之后该方法已经不存在了,本文使用了自定义函数实现) 4 table.remove(table[,pos]):返回table数组部分位于pos位置的元素. 其后的元素会被前移. pos参数可选, 默认为table长度, 即从最后一个元素删起 5 table.sort(table[,comp]):对给定的table进行升序排列 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273-- 方法实例:-- table连接-- 使用concat()方法来连接两个tablefruits = &#123;"banana","orange","apple"&#125;-- 返回table连接后的字符串print("连接后的字符串",table.concat(fruits))-- 指定连接字符print("连接后的字符串 ",table.concat(fruits,", "))-- 指定索引来连接tableprint("连接后的字符串 ",table.concat(fruits,", ", 2, 3))-- 插入和移除-- 演示table的插入和移除操作-- 在末尾插入table.insert(fruits,"mango")print("索引为4的元素为 ",fruits[4])-- 在索引为2的键处插入table.insert(fruits,2,"grapes")print("索引为2的元素为 ",fruits[2])print("最后一个元素为 ",fruits[5])table.remove(fruits)print("移除后最后一个元素为 ",fruits[5])-- table排序fruits = &#123;"banana","apple","grapes"&#125;print("排序前")for k,v in ipairs(fruits) do print(k,v)endtable.sort(fruits)print("排序后")for k,v in ipairs(fruits) do print(k,v)end-- table最大值-- 自定义table_maxn来实现-- 获取table中的最大值function table_maxn(t) local mn=nil for k,v in pairs(t) do if(mn==nil) then mn=v end if mn &lt; v then mn = v end end return mnendtb1 = &#123;[1] = 2, [2] = 6, [3] = 34, [26] = 5&#125;print("tb1最大值: ",table_maxn(tb1))print("tb1长度 ",#tb1)-- 代码执行的结果是: -- tb1最大值: 34-- tb1长度: 3-- 当我们获取 table 的长度的时候无论是使用 # 还是 table.getn 其都会在索引中断的地方停止计数，而导致无法正确取得 table 的长度。-- 使用以下方法替换:function table_leng(t) local leng = 0 for k,v in pairs(t) do leng=leng+1 end return lengend]]></content>
      <categories>
        <category>lua</category>
      </categories>
      <tags>
        <tag>redis</tag>
        <tag>lua</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[rabbitMq基本用法]]></title>
    <url>%2F2018%2F08%2F01%2FrabbitMq%E5%9F%BA%E6%9C%AC%E7%94%A8%E6%B3%95%2F</url>
    <content type="text"><![CDATA[简介MQ简介 MQ是啥? MQ是Message Queue消息队列的缩写,是一种应用程序对应用程序的通信方法、应用程序通过写和检索入列队的针对应用程序的数据来进行通信，而不需要专用连接来链接它们。队列的使用除去了接收和发送应用程序同时执行的要求。 概况 是分布式应用之间交换信息的一种技术,消息队列可以驻留在内存或者磁盘中,直到被程序读走,通过消息队列,应用程序可以独立执行,不需要消息收发者彼此的位置 基本概念 消息message 消息是mq中最小的概念,本质上是一段数据,能被一个或者多个应用程序所理解,是传递信息的载体 队列Queue 初始化队列: 用作消息的触发功能 传输队列: 暂存待传消息,条件许可的情况下,通过管道将消息传送到其他队列 目标队列: 是消息的目的地,可以长期存放 死信队列: 当消息不能送到目标队列,也不再路由出去,则自动放入死信队列 应用场景: 所有可以异步操作的功能都可以用mq rabbitMq简介 简介: rabbitMq是一个由Erlang语言开发的AMQP的开源实现 AMQP: Advanced Message Queuing Protocol, 高级消息队列协议,它是应用层协议的一个开放的标准,以解决众多的消息中间件的需求和拓扑结构问题,并不受产品,语言等条件的限制 安装安装 先安装erlang语言环境 可以使用yum工具安装 这里下载官方的tar包安装,下载源码包otp_src_21.0.tar.gz 先解压 tar -zxvf otp_src_21.0.tar.gz 进入目录后,设置安装目录 ./configure --prefix=/opt/erlang/ 如果出现报错信息如下,可以使用yum搜索相关的组件,并且安装即可: 然后make &amp;&amp; make install 在/etc/profile配置环境变量即可 输入erl看是否安装成功 再安装rabbitMq 官网下载rabbitmq-server-generic-unix-3.7.7.tar,下载的rabbitMq的版本要和erlang适配,具体适配的版本机见rabbitMq官网每个版本的说明 解压后配置环境变量即可 运行: rabbitmq-server 如果有docker环境,可以直接拉取rabbitMQ的镜像,直接启动 搜索相关的镜像: docker search rabbitmq 拉取镜像: docker pull rabbitmq 启动镜像,指定hostname,映射相关的端口,映射rabbitmq的数据库文件到宿主机: docker run -tid --hostname rabbitmq_2 --name my_rabbitmq_2 -p 5672:5672 -p 15672:15672 -v /root/rabbitmq/lib/:/var/lib/rabbitmq/ rabbitmq:latest /bin/bash 进入镜像启动rabbitmq: rabbitmq-server -detached 添加新的rabbitmq用户 添加管理界面的插件 rabbitmq-plugins enable rabbitmq_management 基本操作基本概念 生产者和消费者 生产者: 消息投递的一方,投递的消息一般包含两部分:消息体(payload)和标签(tag),消息一般是带哦有业务逻辑结构的数据,标签用来描述这条消息,比如一个交换器的名称和一个路由键 消费者: 接收消息的一方,消费者消费消息时,消费的只是消息体payload,在消息路由的过程中,消息的标签会被丢弃掉,存入队列的只有消息体,消费者也不会知道消息的生产者是谁 broker: 服务节点,一个broker可以看作一个简单的服务节点,rabbitmq整体架构 队列 rabbitMq的内部对象,用来存储消息 交换器,路由,绑定 Exchange: 交换器,决定最终投递到哪个队列的路由的一部分,消息被发送到Exchange,交换器将消息路由到一个或者多个队列中 fanout: 会将所有发送到交换器的消息路由到所有与交换器绑定的队列中 direct: 会把消息路由到所有的BindingKey和RoutingKey完全匹配的队列中交换器direct topic: 将消息路由到RoutingKey和BindingKey满足一定的匹配规则的队列中 RoutingKey为点号.分隔的一些单词组成 BindingKey也是点号.分隔的字符串 BindingKey中存在两种特殊的字符*,#,用于模糊匹配,*用于匹配一个单词,#用于匹配多个单词 例如: routingKey为com.rabbitMq.client的消息会路由到bindingKey为*.rabbitMq.*和*.*.client和com.#的队列交换器topic headers: 根据发送内容中的headers属性进行匹配 RoutingKey: 路由键 生产者将消息发送到交换器时,一般会指定一个RoutingKey,它和交换器类型还有绑定键联合使用才能最终生效 BindingKey: 绑定键 在交换器的类型为direct或者topic时,消息将发送到routingKey和bindingKey匹配的队列中 添加用户 添加一个root用户,密码是rootrabbitmqctl add_user root root 设置所有权限: rabbitmqctl set_permissions -p / root &quot;.*&quot; &quot;.*&quot; &quot;.*&quot; 设置管理员角色: rabbitmqctl set_user_tags root administrator 开启管理界面 使用命令 rabbitmq-plugins enable rabbitmq_management 重启rabbitMq rabbitmqctl stop, rabbitmq-server -detached 如果需要在其他机器上访问,需要放开15672端口,centos7使用firewall而不是iptables,需要注意 消息的流转过程 生产者: 生产者连接到RabbitMQ Broker,建立一个连接(Connection),开启一个信道(Channel) 生产者声明一个交换器,并且设置相关的属性,比如交换机类型,是否持久化等 生产者声明一个队列并且设置相关的属性,比如是否排他,是否持久化,是否自动删除等 生产者通过路由键将交换器和队列绑定起来 生产者发送消息到RabbitMq Broker,其中包含路由键,交换器等信息(tag和payload两部分) 相应的交换器根据接收到的路由键查找相匹配的队列 如果找到,将从生产者发过来的消息存入到相应的队列 如果没有找到,则根据生产者配置的属性选择丢弃还是回退给生产者 关闭信道 关闭连接 消费者: 消费者连接到RabbitMQ Broker, 建立一个连接(Connection),开启一个信道(Channel) 消费者向RabbitMQ Broker 请求消费相应的队列中的消息,可能会设置相应的回调函数,以及做一些准备工作 等待RabbitMQ Broker 回应并投递相应的队列中的消息,消费者接收消息 消费者确认(ack)接收到的消息 RabbitMQ从队列中删除相应的已经被确认的消息 关闭信道 关闭连接 实践示例代码 首先需要导入依赖 12345&lt;dependency&gt; &lt;groupId&gt;com.rabbitmq&lt;/groupId&gt; &lt;artifactId&gt;amqp-client&lt;/artifactId&gt; &lt;version&gt;4.2.1&lt;/version&gt;&lt;/dependency&gt; 生产者代码: 12345678910111213141516171819202122232425262728293031323334353637383940import com.rabbitmq.client.*;import java.io.IOException;import java.util.concurrent.TimeoutException;/** * rabbitMq 生产者 * @author zonzie * @date 2018/6/30 15:43 */public class RabbitProducer &#123; private static final String EXCHANGE_NAME = "exchange_demo"; private static final String ROUTING_KEY = "routingkey_demo"; private static final String QUEUE_NAME = "queue_demo"; private static final String IP_ADDRESS = "192.168.198.128"; private static final int PORT = 5672;// rabbitmq 服务端默认的端口 public static void main(String[] args) throws IOException, TimeoutException &#123; ConnectionFactory factory = new ConnectionFactory(); factory.setHost(IP_ADDRESS); factory.setPort(PORT); factory.setUsername("root"); factory.setPassword("root"); // 创建连接 Connection connection = factory.newConnection(); // 创建信道 Channel channel = connection.createChannel(); // 创建一个type="direct",持久化的,非自动删除的交换器 AMQP.Exchange.DeclareOk direct = channel.exchangeDeclare(EXCHANGE_NAME, "direct", true, false, null); // 创建一个持久化的,非排他的,非自动删除的队列 channel.queueDeclare(QUEUE_NAME, true, false, false, null); // 将交换器与队列通过路由键绑定,因为交换器类型为direct,所以ROUTING_KEY和BINDING_KEY保持一致,这里使用ROUTING_KEY就行 channel.queueBind(QUEUE_NAME, EXCHANGE_NAME, ROUTING_KEY); // 发送一条持久化的消息:hello world! String message = "hello world"; channel.basicPublish(EXCHANGE_NAME, ROUTING_KEY, MessageProperties.PERSISTENT_TEXT_PLAIN, message.getBytes()); // 关闭资源 channel.close(); connection.close(); &#125;&#125; 消费者代码: 123456789101112131415161718192021222324252627282930313233343536373839404142434445import com.rabbitmq.client.*;import java.io.IOException;import java.util.concurrent.TimeUnit;import java.util.concurrent.TimeoutException;/** * rabbitMq 消费者 * @author zonzie * @date 2018/6/30 16:30 */public class RabbitConsumer &#123; private static final String QUEUE_NAME = "queue_demo"; private static final String IP_ADDRESS = "192.168.198.128"; private static final int PORT = 5672; public static void main(String[] args) throws IOException, TimeoutException, InterruptedException &#123; Address[] addresses = &#123;new Address(IP_ADDRESS, PORT)&#125;; ConnectionFactory factory = new ConnectionFactory(); factory.setUsername("root"); factory.setPassword("root"); // 创建连接 Connection connection = factory.newConnection(addresses); // 创建信道 final Channel channel = connection.createChannel(); // 设置客户端最多接收未被ACK的消息的个数 channel.basicQos(64); DefaultConsumer defaultConsumer = new DefaultConsumer(channel)&#123; @Override public void handleDelivery(String consumerTag, Envelope envelope, AMQP.BasicProperties properties, byte[] body) throws IOException &#123; System.out.println("recv message: " + new String(body)); try &#123; TimeUnit.SECONDS.sleep(1); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; channel.basicAck(envelope.getDeliveryTag(), false); &#125; &#125;; channel.basicConsume(QUEUE_NAME, defaultConsumer); // 等待回调函数执行完毕, 关闭资源 TimeUnit.SECONDS.sleep(20); channel.close(); connection.close(); &#125;&#125; 在spring中的使用-rabbitTemplate 相关的spring配置: 12345678910spring: application: name: spring-boot-rabbitmq rabbitmq: host: 192.168.198.128 port: 5672 username: root password: root # 设置手动确认 publisher-confirms: true 生产者: 配置队列和交换器,还有绑定关系 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109import org.springframework.amqp.core.*;import org.springframework.context.annotation.Bean;import org.springframework.context.annotation.Configuration;import java.util.HashMap;/** * @author zonzie * @date 2018/7/12 18:08 */@Configurationpublic class AmqpConfig &#123; /** * 创建一个队列 -&gt; "hello" */ @Bean public Queue queue() &#123; HashMap&lt;String, Object&gt; map = new HashMap&lt;String, Object&gt;(); // 设置超时时间 map.put("x-message-ttl", 1000); // 设置死信交换器 map.put("x-dead-letter-exchange", "dead-letter-exchange"); // 设置死信路由键 map.put("x-dead-letter-routing-key", "dead-letter-routing"); return new Queue("hello",false, false, false, map); &#125; /** * 创建一个队列 -&gt; "object" */ @Bean public Queue objectQueue() &#123; return new Queue("object"); &#125; /** * 创建一个队列 -&gt; "test" */ @Bean public Queue testQueue() &#123; return new Queue("test"); &#125; /** * 死信队列 */ @Bean public Queue deadQueue() &#123; return new Queue("deadqueue"); &#125; /** * 死信交换器 */ @Bean public DirectExchange deadExchange() &#123; return new DirectExchange("dead-letter-exchange"); &#125; /** * 绑定死信队列和死信交换器 */ @Bean public Binding deadBinding() &#123; return BindingBuilder.bind(deadQueue()).to(deadExchange()).with("dead-letter-routing"); &#125; /** * 创建一个direct交换器 */ @Bean public DirectExchange directExchange() &#123; return new DirectExchange("com.zonzie.directtest"); &#125; /** * 通过bindingKey -&gt; "hellotest", 绑定queue-&gt;"hello"和上面的交换器 */ @Bean public Binding bindingKey() &#123; return BindingBuilder.bind(queue()).to(directExchange()).with("hellotest"); &#125; /** * 创建topic交换器 */ @Bean public TopicExchange topicExchange() &#123; return new TopicExchange("com.zonzie.topictest"); &#125; /** * 通过bindingKey -&gt; "com.*.test" 绑定queue-&gt;"test"和上面的topicExchange */ @Bean public Binding topicBindKey() &#123; return BindingBuilder.bind(testQueue()).to(topicExchange()).with("com.*.test"); &#125; /** * 通过bindingKey -&gt; "com.#" 绑定 queue-&gt;"hello"和topicExchange */ @Bean public Binding topicBindKey2() &#123; return BindingBuilder.bind(queue()).to(topicExchange()).with("com.#"); &#125;&#125; 生产者: 设置rabbitTemplate 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778/** * @author zonzie * @date 2018/7/13 17:48 */@Configuration@Slf4jpublic class AmqpTemplateConfig&#123; @Bean(name = "myTemplate") public RabbitTemplate rabbitTemplate(ConnectionFactory connectionFactory) &#123; RabbitTemplate rabbitTemplate = new RabbitTemplate(connectionFactory); // 设置messageConverter,确定消息传递时序列化的方式 rabbitTemplate.setMessageConverter(messageConverter()); // 设置重试次数 RetryTemplate retryTemplate = new RetryTemplate(); ExponentialBackOffPolicy exponentialBackOffPolicy = new ExponentialBackOffPolicy(); exponentialBackOffPolicy.setInitialInterval(500); exponentialBackOffPolicy.setMultiplier(10.0); exponentialBackOffPolicy.setMaxInterval(10000); retryTemplate.setBackOffPolicy(exponentialBackOffPolicy); rabbitTemplate.setRetryTemplate(retryTemplate); // 设置回调方法 rabbitTemplate.setConfirmCallback(new ConfirmCallbackDemo()); // 失败后return回调 rabbitTemplate.setReturnCallback(new ReturnCallBackDemo()); // return 回调需要设置,不然不会生效 rabbitTemplate.setMandatory(true); // 事务// rabbitTemplate.setChannelTransacted(true);// rabbitTemplate.setExchange(); return rabbitTemplate; &#125; private Jackson2JsonMessageConverter messageConverter() &#123; return new Jackson2JsonMessageConverter(); &#125;&#125;// ---------------------import lombok.extern.slf4j.Slf4j;import org.springframework.amqp.rabbit.core.RabbitTemplate;import org.springframework.amqp.rabbit.support.CorrelationData;/** * 手动确认回调的方法 * @author zonzie * @date 2018/7/14 15:31 */@Slf4jpublic class ConfirmCallbackDemo implements RabbitTemplate.ConfirmCallback &#123; @Override public void confirm(CorrelationData correlationData, boolean ack, String cause) &#123; log.info(" 消息id:" + correlationData); if (ack) &#123; log.info("消息发送确认成功"); &#125; else &#123; log.info("消息发送确认失败:" + cause); &#125; &#125;&#125;//---------------------import lombok.extern.slf4j.Slf4j;import org.springframework.amqp.core.Message;import org.springframework.amqp.rabbit.core.RabbitTemplate;/** * 设置消息消费失败后回调的方法 * @author zonzie * @date 2018/7/15 13:07 */@Slf4jpublic class ReturnCallBackDemo implements RabbitTemplate.ReturnCallback &#123; @Override public void returnedMessage(Message message, int replyCode, String replyText, String exchange, String routingKey) &#123; System.out.println("return--message:"+new String(message.getBody())+",replyCode:"+replyCode+",replyText:"+replyText+",exchange:"+exchange+",routingKey:"+routingKey); &#125;&#125; 用到的实体 1234567891011import lombok.Data;/** * @author zonzie * @date 2018/7/13 15:08 */@Datapublic class User &#123; private String username; private String password;&#125; 生产者: 发送消息 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647import com.zonzie.domian.User;import io.swagger.annotations.Api;import io.swagger.annotations.ApiOperation;import lombok.extern.slf4j.Slf4j;import org.springframework.amqp.rabbit.core.RabbitTemplate;import org.springframework.amqp.rabbit.support.CorrelationData;import org.springframework.web.bind.annotation.GetMapping;import org.springframework.web.bind.annotation.RequestMapping;import org.springframework.web.bind.annotation.RestController;import javax.annotation.Resource;import java.util.UUID;/** * @author zonzie * @date 2018/7/13 14:22 */@RestController@RequestMapping(value = "sender", produces = MediaType.APPLICATION_JSON_UTF8_VALUE)@Slf4jpublic class RabbitSender &#123; @Resource(name = "myTemplate") private RabbitTemplate rabbitTemplate; @GetMapping("/send") public String send(String context) &#123; System.out.println(context); CorrelationData correlationData = new CorrelationData(UUID.randomUUID().toString());// rabbitTemplate.convertAndSend("hello", context, correlationData);// rabbitTemplate.convertAndSend("test","helloTest");// rabbitTemplate.convertAndSend("com.zonzie.directtest","hellotest","helloTEST"); rabbitTemplate.convertAndSend("com.zonzie.topictest", "com.zonzie.test",context);// rabbitTemplate.convertAndSend("hellotest","helloTEST"); return "success"; &#125; @GetMapping("/user") public String sendUser() &#123; User user = new User(); user.setUsername("ybq"); user.setPassword("123"); rabbitTemplate.convertAndSend("object",user); return "bingo!"; &#125;&#125; 消费者: 消费者配置 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253/** * @author zonzie * @date 2018/7/13 17:48 */@Configuration@Slf4jpublic class AmqpConsumeConfig&#123; @Bean(name="myListenContainer") public SimpleRabbitListenerContainerFactory rabbitListenerContainerFactory(ConnectionFactory connectionFactory, @Qualifier("rabbitTransactionManager") PlatformTransactionManager manager) &#123; SimpleRabbitListenerContainerFactory factory = new SimpleRabbitListenerContainerFactory(); // 设置messageConverter,需要同生产者保持一致 factory.setMessageConverter(messageConverter()); // 设置事务管理,事务管理和手动确认的方式只能使用一种// factory.setChannelTransacted(true);// factory.setTransactionManager(manager); factory.setConnectionFactory(connectionFactory); // 设置手动应答模式 factory.setAcknowledgeMode(AcknowledgeMode.MANUAL); return factory; &#125; @Bean(name = "rabbitTransactionManager") public RabbitTransactionManager getTransactionManager(ConnectionFactory connectionFactory) &#123; return new RabbitTransactionManager(connectionFactory); &#125;// 另一种配置消费者的方式// @Bean// public SimpleMessageListenerContainer messageContainer(ConnectionFactory connectionFactory) &#123;// SimpleMessageListenerContainer container = new SimpleMessageListenerContainer(connectionFactory);// container.setMessageConverter(messageConverter());// container.setQueues(new Queue("hello"), new Queue("object"));// container.setExposeListenerChannel(true);// container.setMaxConcurrentConsumers(1);// container.setConcurrentConsumers(1);// container.setAcknowledgeMode(AcknowledgeMode.MANUAL);// container.setMessageListener(new ChannelAwareMessageListener() &#123;//// @Override// public void onMessage(Message message, com.rabbitmq.client.Channel channel) throws Exception &#123;// byte[] body = message.getBody();// log.info("消费端接收到消息 : " + new String(body));// // 手动确认消息已被消费// channel.basicAck(message.getMessageProperties().getDeliveryTag(), false);// &#125;// &#125;);// return container;// &#125; private Jackson2JsonMessageConverter messageConverter() &#123; return new Jackson2JsonMessageConverter(); &#125; 消息监听并且消费 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061import com.google.common.base.Objects;import com.rabbitmq.client.Channel;import com.zonzie.domian.User;import lombok.extern.slf4j.Slf4j;import org.springframework.amqp.rabbit.annotation.RabbitHandler;import org.springframework.amqp.rabbit.annotation.RabbitListener;import org.springframework.amqp.support.AmqpHeaders;import org.springframework.messaging.handler.annotation.Header;import org.springframework.stereotype.Component;import java.io.IOException;/** * @author zonzie * @date 2018/7/13 15:27 */@Slf4j@Componentpublic class ObjectReceiver &#123; /** 消息的标识，false只确认当前一个消息收到，true确认所有consumer获得的消息 channel.basicAck(message.getMessageProperties().getDeliveryTag(), false); ack返回false，并重新回到队列，api里面解释得很清楚 channel.basicNack(message.getMessageProperties().getDeliveryTag(), false, true); 拒绝消息 channel.basicReject(message.getMessageProperties().getDeliveryTag(), true); 如果消息没有到exchange,则confirm回调,ack=false 如果消息到达exchange,则confirm回调,ack=true exchange到queue成功,则不回调return exchange到queue失败,则回调return(需设置mandatory=true,否则不回回调,消息就丢了) */ @RabbitHandler @RabbitListener(containerFactory = "myListenContainer", queues = "object") public void process(User user, @Header(AmqpHeaders.DELIVERY_TAG) long deliveryTag, Channel channel) throws IOException &#123; System.out.println(user); // 确认消息收到 channel.basicAck(deliveryTag,false); System.out.print("这里是接收者1答应消息： "); System.out.println("SYS_TOPIC_ORDER_CALCULATE_ZZ_FEE process1 : " + user); &#125; @RabbitHandler @RabbitListener(containerFactory = "myListenContainer",queues = &#123;"hello","test"&#125;) public void process(String hello, Channel channel, @Header(AmqpHeaders.DELIVERY_TAG) long deliverTag) throws IOException &#123; System.out.println("Receiver: " + hello); if(Objects.equal(hello, "tttt")) &#123; // 对于业务中遇到的一些不满足条件的消息,使用channel.reject(),或者channel.Nack(),会触发生产者的returnCallBack配置并且被处理或者会被发送到死信队列 channel.basicReject(deliverTag, false); &#125; channel.basicAck(deliverTag, false); &#125; @RabbitHandler @RabbitListener(containerFactory = "myListenContainer",queues = &#123;"test"&#125;) public void process2(String hello, Channel channel, @Header(AmqpHeaders.DELIVERY_TAG) long deliverTag) throws IOException &#123; System.out.println("Receiver222: " + hello); channel.basicAck(deliverTag, false); &#125;&#125; 集群配置单机多节点集群配置 一台机器部署多个rabbitMQ服务节点,需要确保每个节点都有独立的名称,数据存储位置,端口号(包括插件的端口号),我们在主机名为node1的机器上创建一个由rabbit1@node1,rabbit2@node1和rabbit3@node1这三个节点组成的RabbitMQ集群 没有安装任何插件的情况,依次启动三个节点: RABBITMQ_NODE_PORT=5672 RABBITMQ_NODENAME=rabbit1 rabbitmq-server -detached RABBITMQ_NODE_PORT=5673 RABBITMQ_NODENAME=rabbit2 rabbitmq-server -detached RABBITMQ_NODE_PORT=5674 RABBITMQ_NODENAME=rabbit3 rabbitmq-server -detached 如果安装了managemnet插件,还需要配置插件的端口号,不然按照上面的启动方式会报错 RABBITMQ_NODE_PORT=5672 RABBITMQ_NODENAME=rabbit1 RABBITMQ_SERVER_START_ARGS=&quot;-rabbitmq_management listener [{port,15672}]&quot; rabbitmq-server -detached RABBITMQ_NODE_PORT=5673 RABBITMQ_NODENAME=rabbit2 RABBITMQ_SERVER_START_ARGS=&quot;-rabbitmq_management listener [{port,15673}]&quot; rabbitmq-server -detached RABBITMQ_NODE_PORT=5674 RABBITMQ_NODENAME=rabbit3 RABBITMQ_SERVER_START_ARGS=&quot;-rabbitmq_management listener [{port,15674}]&quot; rabbitmq-server -detached 3个节点都启动了之后, 将rabbit2@node1节点加入到rabbit1@node1的集群之中,并且按照同样的方法,将rabbit3加入到集群之中 rabbitmqctl -n rabbit2@node1 stop_app rabbitmqctl -n rabbit2@node1 reset rabbitmqctl -n rabbit2@node1 join_cluster rabbit1@node1 rabbitmqctl -n rabbit2@node1 start_app 集群状态查看 rabbitmqctl -n rabbit1@node1 cluster_status 多机多节点配置 为了让每个节点能够识别其他节点,首先需要修改/etc/hosts文件,添加ip和节点名称的映射文件 123192.168.0.1 node1192.168.0.2 node2192.168.0.3 node3 编辑RabitMQ的cookie文件,确保每个节点的cookie文件使用的是同一个值,可以读取一个节点的cookie的值,将其复制到node2和node3节点中.cookie文件默认的路径为/var/lib/rabbitmq/.erlang.cookie或者$HOME/.erlang.cookie, cookie相当于密钥令牌,集群中的RabbitMQ节点需要通过交换密钥令牌以获得相互认证,不然在配置节点时会报错 启动三个节点的RabbitMQ服务 分别在三个节点下执行: rabbitmq-server -detached 以node1为基准,分别将node2和node3加入到node1节点的集群中 rabbitmqctl stop_app rabbitmqctl reset rabbitmqctl join_cluster rabbit@node1 rabbitmqctl start_app 如果关闭了集群中的所有的节点,则需要确保在启动的时候最后关闭的节点是第一个启动的,如果第一个启动的不是最后关闭的节点,那这个节点会等待最后关闭的节点启动,这个等待时间是30s,如果没有等到,那么这个节点的启动也会失败,最新的版本中会默认重试10次,每次30s 如果最后一个节点因为某些异常而无法启动,可以通过rabbitmqctl forget_cluster_node命令将此节点剔除出集群 如果集群中所有节点都因为某些原因非正常关闭,比如断电,那么集群中的节点都会认为还有节点在它后面关闭,此时需要调用rabbitmqctl force_boot强制启动某一个节点,其他节点才会正常启动 剔除单个节点 有多种方法可以将一个节点剔除出集群 如果由于启动顺序的原因不得不剔除一个节点,有两种情况 node2节点已经不再运行rabbitMQ了, 可以在node1或者node3中将其剔除: rabbitmqctl forget_cluster_node rabbit@node2 如果此时没有节点处于启动状态,需要剔除掉node1节点,可以在node2或者node3执行命令: rabbitmqctl forget_cluster_node rabbit@node1 --offline,这里如果不加”–offline”,则需要保证执行命令的节点处于运行状态,如果node2和node3无法先行启动,可以加这个参数,在没有启动rabbitmq的情况下将node1剔除出节点 正常情况下,剔除一个节点的方法 rabbitmqctl stop_app rabbitmqctl reset rabbitmqctl start_app 以上代码地址: https://github.com/zonzie/rabbitMQ_demo]]></content>
      <categories>
        <category>mq</category>
      </categories>
      <tags>
        <tag>rabbitMq</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[dokcer基本操作(二)]]></title>
    <url>%2F2018%2F07%2F19%2Fdokcer%E5%9F%BA%E6%9C%AC%E6%93%8D%E4%BD%9C-%E4%BA%8C%2F</url>
    <content type="text"><![CDATA[docker镜像的制作 一般docker的镜像有两种制作方式 通过Dockerfile和build制作镜像 通过docker commit制作镜像 Dockerfile使用基本的基于DSL语法的指令来构建一个Docker镜像，之后使用docker builder命令基于该Dockerfile中的指令构建一个新的镜像。 Dockerfile常用的指令 FROM 设置镜像使用的的基础镜像 语法: FROM &lt;image&gt;[:&lt;tag&gt; | @&lt;digest&gt;] MAINTAINER 设置镜像的作者 语法: MAINTAINER &lt;name&gt; RUN 编译镜像时运行的脚本以及命令 语法：RUN &lt;command&gt;;RUN [&quot;executable&quot;,&quot;param1&quot;,&quot;param2&quot;] CMD 设置容器的启动命令 语法: CMD [&quot;executable&quot;,&quot;param1&quot;,&quot;param2&quot;];CMD [&quot;param1&quot;,&quot;param2&quot;];CMD &lt;command&gt; LABEL 设置镜像的标签 语法: LABEL &lt;key&gt;=&lt;value&gt; &lt;key&gt;=&lt;value&gt; … 镜像标签可以通过docker inspect查看 EXPOSE 设置镜像要暴露的端口 语法: EXPOSE &lt;port&gt; &lt;port&gt; … 提示：容器启动时，Docker Daemon会扫描镜像中暴露的端口，如果加入-P参数，Docker Daemon会把镜像中所有暴露端口导出，并为每个暴露端口分配一个随机的主机端口（暴露端口是容器监听端口，主机端口为外部访问容器的端口） 注意：EXPOSE只设置暴露端口并不导出端口，只有启动容器时使用-P/-p才导出端口，这个时候才能通过外部访问容器提供的服务 ENV 设置容器的环境变量 语法: ENV &lt;key&gt;=&lt;value&gt;…|&lt;key&gt; &lt;value&gt; 注意：环境变量在整个编译周期都有效，第一种方式可设置多个环境变量，第二种方式只设置一个环境变量 提示：通过${变量名}或者 $变量名使用变量，使用方式${变量名}时可以用${变量名:-default} ${变量名:+cover}设定默认值或者覆盖值 ADD 编译镜像时添加文件到镜像 语法：ADD &lt;src&gt;… &lt;dest&gt;|[“&lt;src&gt;”,… “&lt;dest&gt;”] 注意：当路径中有空格时，需要使用第二种方式, 当src为文件或目录时，Docker Daemon会从编译目录寻找这些文件或目录，而dest为镜像中的绝对路径或者相对于WORKDIR的路径 COPY 编译镜像时复制文件到镜像 语法：COPY &lt;src&gt;… &lt;dest&gt;|[“&lt;src&gt;”,… “&lt;dest&gt;”] 提示：指令逻辑和ADD十分相似，同样Docker Daemon会从编译目录寻找文件或目录，dest为镜像中的绝对路径或者相对于WORKDIR的路径 ENTRYPOINT 设置容器的入口程序 语法：ENTRYPOINT [“executable”,”param1”,”param2”], ENTRYPOINT command param1 param2（shell方式） 提示：入口程序是容器启动时执行的程序，docker run中最后的命令将作为参数传递给入口程序, 入口程序有两种格式：exec、shell，其中shell使用/bin/sh -c运行入口程序，此时入口程序不能接收信号量, 当Dockerfile有多条ENTRYPOINT时只有最后的ENTRYPOINT指令生效, 如果使用脚本作为入口程序，需要保证脚本的最后一个程序能够接收信号量，可以在脚本最后使用exec或gosu启动传入脚本的命令 注意：通过shell方式启动入口程序时，会忽略CMD指令和docker run中的参数, 为了保证容器能够接受docker stop发送的信号量，需要通过exec启动程序；如果没有加入exec命令，则在启动容器时容器会出现两个进程，并且使用docker stop命令容器无法正常退出（无法接受SIGTERM信号），超时后docker stop发送SIGKILL，强制停止容器 VOLUME 设置容器的挂载卷 语法：VOLUME [“/data”], VOLUME /data1 /data2 提示：启动容器时，Docker Daemon会新建挂载点，并用镜像中的数据初始化挂载点，可以将主机目录或数据卷容器挂载到这些挂载点 USER 设置运行命令以及脚本时的用户 语法：USER &lt;name&gt; WORKDIR 设置指令运行时的工作目录 语法：WORKDIR 提示：如果工作目录不存在，则Docker Daemon会自动创建, Dockerfile中多个地方都可以调用WORKDIR，如果后面跟的是相对位置，则会跟在上条WORKDIR指定路径后（如WORKDIR /A WORKDIR B WORKDIR C，最终路径为/A/B/C） ARG 设置编译镜像时加入的参数 ONBUILD 设置镜像的ONBUILD指令 语法：ONBUILD [INSTRUCTION] 提示：从该镜像生成子镜像，在子镜像的编译过程中，首先会执行父镜像中的ONBUILD指令，所有编译指令都可以成为钩子指令 STOPSIGNAL 设置容器的退出信号量 docker build命令使用 --build-arg，设置构建时的变量 --no-cache，默认false。设置该选项，将不使用Build Cache构建镜像 --pull，默认false。设置该选项，总是尝试pull镜像的最新版本 --compress，默认false。设置该选项，将使用gzip压缩构建的上下文 --disable-content-trust，默认true。设置该选项，将对镜像进行验证 --file, -f，Dockerfile的完整路径，默认值为‘PATH/Dockerfile’ --isolation，默认–isolation=”default”，即Linux命名空间；其他还有process或hyperv --label，为生成的镜像设置metadata --squash，默认false。设置该选项，将新构建出的多个层压缩为一个新层，但是将无法在多个镜像之间共享新层；设置该选项，实际上是创建了新image，同时保留原有image。 --tag, -t，镜像的名字及tag，通常name:tag或者name格式；可以在一次构建中为一个镜像设置多个tag --network，默认default。设置该选项，Set the networking mode for the RUN instructions during build --quiet, -q ，默认false。设置该选项，Suppress the build output and print image ID on success --force-rm，默认false。设置该选项，总是删除掉中间环节的容器 --rm，默认–rm=true，即整个构建过程成功后删除中间环节的容器 docker run命令使用 Usage: docker run [OPTIONS] IMAGE [COMMAND] [ARG...] -d, --detach=false 指定容器运行于前台还是后台，默认为false -i, --interactive=false 打开STDIN，用于控制台交互 -t, --tty=false 分配tty设备，该可以支持终端登录，默认为false -u, --user=&quot;&quot; 指定容器的用户 -a, --attach=[] 登录容器（必须是以docker run -d启动的容器） -w, --workdir=&quot;&quot; 指定容器的工作目录 -c, --cpu-shares=0 设置容器CPU权重，在CPU共享场景使用 -e, --env=[] 指定环境变量，容器中可以使用该环境变量 -m, --memory=&quot;&quot; 指定容器的内存上限 -P, --publish-all=false 指定容器暴露的端口 -p, --publish=[] 指定容器暴露的端口 -h, --hostname=&quot;&quot; 指定容器的主机名 -v, --volume=[] 给容器挂载存储卷，挂载到容器的某个目录 --volumes-from=[] 给容器挂载其他容器上的卷，挂载到容器的某个目录 --cap-add=[] 添加权限，权限清单详见：http://linux.die.net/man/7/capabilities --cap-drop=[] 删除权限，权限清单详见：http://linux.die.net/man/7/capabilities --cidfile=&quot;&quot; 运行容器后，在指定文件中写入容器PID值，一种典型的监控系统用法 --cpuset=&quot;&quot; 设置容器可以使用哪些CPU，此参数可以用来容器独占CPU --device=[] 添加主机设备给容器，相当于设备直通 --dns=[] 指定容器的dns服务器 --dns-search=[] 指定容器的dns搜索域名，写入到容器的/etc/resolv.conf文件 --entrypoint=&quot;&quot; 覆盖image的入口点 --env-file=[] 指定环境变量文件，文件格式为每行一个环境变量 --expose=[] 指定容器暴露的端口，即修改镜像的暴露端口 --link=[] 指定容器间的关联，使用其他容器的IP、env等信息 --lxc-conf=[] 指定容器的配置文件，只有在指定–exec-driver=lxc时使用 --name=&quot;&quot; 指定容器名字，后续可以通过名字进行容器管理，links特性需要使用名字 --net=&quot;bridge&quot; 12345容器网络设置: bridge 使用docker daemon指定的网桥 host //容器使用主机的网络 container:NAME_or_ID &gt;//使用其他容器的网路，共享IP和PORT等网络资源 none 容器使用自己的网络（类似--net=bridge），但是不进行配置 --privileged=false 指定容器是否为特权容器，特权容器拥有所有的capabilities --restart=&quot;no&quot; 123no：容器退出时不重启 on-failure：容器故障退出（返回值非零）时重启 always：容器退出时总是重启 --rm=false 指定容器停止后自动删除容器(不支持以docker run -d启动的容器) --sig-proxy=true 设置由代理接受并处理信号，但是SIGCHLD、SIGSTOP和SIGKILL不能被代理 示例 12345678910111213141516171819202122232425262728293031323334# Dockerfile 示例# version: 1.0.0FROM ubuntu:latestMAINTAINER &quot;yaobq13@gmail.com&quot;# 修改apt-get源# 备份默认的文件RUN mv /etc/apt/sources.list ./source.list_bak# 创建新的文件RUN touch /etc/apt/sources.list# 写入RUN echo deb http://mirrors.163.com/ubuntu/ trusty main restricted universe multiverse &gt;&gt; /etc/apt/sources.listRUN echo deb http://mirrors.163.com/ubuntu/ trusty-security main restricted universe multiverse &gt;&gt; /etc/apt/sources.listRUN echo deb http://mirrors.163.com/ubuntu/ trusty-updates main restricted universe multiverse &gt;&gt; /etc/apt/sources.listRUN echo deb http://mirrors.163.com/ubuntu/ trusty-proposed main restricted universe multiverse &gt;&gt; /etc/apt/sources.listRUN echo deb http://mirrors.163.com/ubuntu/ trusty-backports main restricted universe multiverse &gt;&gt; /etc/apt/sources.listRUN echo deb-src http://mirrors.163.com/ubuntu/ trusty main restricted universe multiverse &gt;&gt; /etc/apt/sources.listRUN echo deb-src http://mirrors.163.com/ubuntu/ trusty-security main restricted universe multiverse &gt;&gt; /etc/apt/sources.listRUN echo deb-src http://mirrors.163.com/ubuntu/ trusty-updates main restricted universe multiverse &gt;&gt; /etc/apt/sources.listRUN echo deb-src http://mirrors.163.com/ubuntu/ trusty-proposed main restricted universe multiverse &gt;&gt; /etc/apt/sources.listRUN echo deb-src http://mirrors.163.com/ubuntu/ trusty-backports main restricted universe multiverse &gt;&gt; /etc/apt/sources.list# 更新apt-get工具RUN apt-get update# 下载安装nginxRUN apt-get install -y nginx# 安装vimRUN apt-get install -y vim# 写入&quot;hello world&quot;到文件index.htmlRUN echo &apos;Hello World!!!&apos; \ &gt;/usr/share/nginx/html/index.html# 暴露80端口EXPOSE 80# ENTRYPOINT service nginx start# 容器启动时要执行的命令,执行完成后容器会自动退出,因此使用`tail -f`命令ENTRYPOINT nginx &amp;&amp; tail -f /var/log/nginx/access.log 使用Dockerfile制作镜像:docker build -t &quot;ubuntu_nginx:v1.0&quot; -f &quot;/root/static_web/Dfile&quot; . 启动容器: docker run -tid -p 8080:80 --name ubuntu_nginx_container ubuntu_nginx:v1.0 /bin/bash 进入容器内部: docker exec -ti ubuntu_nginx_container /bin/bash 退出容器: exit 使用docker commit制作镜像 需要一个基础镜像,下载最新的Ubuntu的docker: docker pull centos:7 镜像下载完毕后,启动容器 docker run --name centos_test --privileged -t -i centos:7 /sbin/init 进入容器: docker exec -it centos_test /bin/bash 在容器内安装vim和nginx: yum install -y vim,yum install -y nginx 安装完毕后退出容器: exit 停止容器的运行: docker stop centos_test 将容器提交为新的镜像: docker commit centos_test my_centos_nginx 容器的目录映射 在部署应用容器的时候，最好将容器的配置文件及数据目录跟宿主机目录做个映射关系！最好不要在容器内修改数据 启动tomcat容器, 将tomcat的配置文件和数据目录跟宿主机做个映射 docker cp tomcat:/usr/local/tomcat7/webapps /mnt/ docker cp tomcat:/usr/local/tomcat7/conf /mnt/ 关闭和删除容器,重新启动时,做目录映射关系 docker stop tomcat docker rm tomcat 重新启动容器 docker run -t -i -d --name=tomcat -v /mnt/webapps:/usr/local/tomcat7/webapps -v /mnt/conf:/usr/local/tomcat7/conf -p 8888:8080 tomcat7 /bin/bash 进入容器启动tomcat进程或者 docker exec tomcat /usr/local/tomcat7/bin/startup.sh]]></content>
      <categories>
        <category>容器</category>
      </categories>
      <tags>
        <tag>docker</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[抽象工厂模式]]></title>
    <url>%2F2018%2F06%2F06%2F%E6%8A%BD%E8%B1%A1%E5%B7%A5%E5%8E%82%E6%A8%A1%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[抽象工厂模式的定义: Provide an interface for creating families of related or dependent objects without specifying their concrete classes.(为创建一组相关的或者相互依赖的对象提供一个接口,而且无需指定他们的具体类) 一个例子123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869// 抽象的产品public abstract class AbstractProductA &#123; public void shareMethod() &#123; // 所有的产品共有的方法 &#125; // 不同实现的方法 public abstract void doSomething();&#125;// 具体的产品A1public class ProductA1 extends AbstractProductA &#123; // 具体实现 public void doSomething() &#123; System.out.println("this is productA1..."); &#125;&#125;// 具体的产品A2public class ProductA2 extends AbstractProductA &#123; // 具体的实现 public void doSomthing() &#123; System.out.println("this is productA2..."); &#125;&#125;// 抽象工厂类public abstract class AbstractCreator &#123; // 创建A类产品工厂 public abstract AbstractProductA createProductA(); // 创建B类产品工厂 public abstract AbstractProductB createProductB();&#125;// 产品等级1的实现类public class Creator1 extends AbstractCreator &#123; public AbstractProductA createProductA() &#123; // 只生产产品等级为1的A产品 return new ProductA1(); &#125; public AbstractProductB createProductB() &#123; // 只生产产品等级为1的B产品 return new ProductB1(); &#125;&#125;// 产品等级为2的实现类public class Creator2 extends AbstractCreator &#123; // 只生产产品等级为2的A产品 public AbstractProductA createProductA() &#123; return new ProductA2(); &#125; // 只生产产品等级为2的B产品 public AbstractProductB createProductB() &#123; return new ProductB2(); &#125;&#125;// 场景类public class Client &#123; public static void main(String... args) &#123; // 定义工厂 AbstractCreator creator1 = new Creator1(); AbstractCreator creator2 = new Creator2(); // 产生A1对象 AbstractProductA a1 = creator1.createProductA(); // 对象b1 AbstractProductB b1 = creator1.createProductB(); // 对象A2 AbstractProductA a2 = creator2.createProductA(); // 对象B2 AbstractProductB b2 = creator2,createProductB(); // 对相关对象的相关操作 // ... &#125;&#125; 抽象工厂模式的优点 封装性,只需要关心接口而不是实现类 产品族内的约束为非公开的状态 抽象工厂模式的缺点 扩展工厂类非常困难,需要改动大量的代码 抽象工厂使用场景 一组对象都有相同的约束,就可以使用抽象工厂模式,例如一个应用需要在不同的平台运行,就可以通过抽象工厂模式屏蔽掉不同平台的影响,不同平台上的软件功能,应用逻辑,UI都应该是非常类似的,唯一不同的是,调用不同的工厂方法,由不同的产品类去处理与操作系统的交互.]]></content>
      <categories>
        <category>design pattern</category>
      </categories>
      <tags>
        <tag>design pattern</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[工厂方法模式]]></title>
    <url>%2F2018%2F06%2F03%2F%E5%B7%A5%E5%8E%82%E6%96%B9%E6%B3%95%E6%A8%A1%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[工厂方法模式的定义: Define an interface for creating an object, but let subclasses decide which class to instantiate.Factory Method lets a class defer instantiation to subclasses.(定义一个用于创建对象的接口,让子类决定实例化哪一个类.工厂方法使一个类的实例化延迟到子类) 一个简单的例子12345678910111213141516171819202122232425262728293031323334353637383940414243444546// 抽象产品类public abstract class Product &#123; // 产品类的公共方法 public void methodA() &#123; // 业务逻辑处理 &#125; // 抽象方法 public abstract void methodB();&#125;// 具体产品类public void productA extends Product &#123; public void methodB() &#123; // 业务逻辑处理 &#125;&#125;public void productB extends Product &#123; public void methodB() &#123; // 业务逻辑处理 &#125;&#125;// 抽象工厂类public abstract class Creator() &#123; // 创建一个产品对象,输入的参数类型自行设置(通常为String,Enumm,Class等,也可以为空) public abstract &lt;T extends Product&gt; T createProduct(Class&lt;T&gt; c);&#125;// 具体工厂类public class ConcreteCreator extends Creator &#123; public &lt;T extends Product&gt; T createProduct(Class&lt;T&gt; c) &#123; Product product = null; try &#123; product = (Product) Class.forName(c.getName()).newInstance(); &#125; catch(Exception e) &#123; e.printStackTrace(); &#125; return (T)product; &#125;&#125;// 场景类public class Client &#123; public static void main(String...args) &#123; Creator creator = new ConcreteCreator(); Product productA = creator.createProduct(ProductA.class); // 处理业务逻辑 // ... &#125;&#125; 工厂方法模式的优点 封装良好,结构清晰,只需要类名,不需要知道创建对象的具体过程 扩展性非常的优秀,增加新的类型,只需要修改具体的工厂类就可以了 屏蔽具体的对象,只需要关心接口,只要接口不发生变化,上层模块就不用发生变化 工厂方法模式是典型的解耦框架,符合迪米特法则,也符合依赖倒置原则,也符合里氏替换原则,使用子类替换父类 工厂方法模式的使用场景 需要灵活,可扩展的框架时,可以考虑使用工厂方法模式 使用在异构项目中,通过webService与非java项目交互 可以使用在测试驱动的开发框架下 工厂方法模式的扩展 缩小为简单工厂模式,即去掉工厂的抽象类,直接使用工厂类 升级为多个工厂类 123456789101112131415161718192021222324252627// 多工厂模式的抽象工厂类public abstract class AbstractFactory &#123; public abstract Product createProduct();&#125;// 产品A的工厂public class ProductAFactory extends AbstractFactory &#123; public Product createProduct() &#123; return new ProductA(); &#125;&#125;// 产品B的工厂public class ProductBFactory extends AbstractFactory &#123; public Product createProduct() &#123; return new ProductB(); &#125;&#125;// 场景类public class client &#123; public static void main(String... args) &#123; Product ProductA = new ProductAFactory().createProduct(); // 产品A的相关操作 // ... Product productB = new ProductBFactory().createProduct(); // 产品B的相关操作 // ... &#125; &#125; 替代单例模式,通过反射生成实例 1234567891011121314151617181920212223242526// 单例类public class Singleton &#123; private Singleton() &#123;&#125; public void doSomthing() &#123; // ...... &#125;&#125;public class SingletonFactory &#123; private static Singleton singleton; static &#123; try &#123; class clazz = Class.forName(Singleton.class.getName()); // 获得无参数的构造方法 Constructor constructor = clazz.getDeclaredConstructor(); constructor.setAccessible(true); // 产生一个实例对象 singleton = (Singleton) constructor.newInstance(); &#125; catch(Exception e) &#123; // 异常处理 &#125; &#125; public static Singleton getSingleton() &#123; return singleton; &#125;&#125; 延迟加载工厂类 1234567891011121314151617181920public class ProductFactory &#123; private static final Map&lt;String, Product&gt; prMap = new hashMap(); public static synchronized Product createProduct(String type) &#123; Product product = null; // 如果map中存在这个对象 if(prMap.containsKey(type)) &#123; product = prMap.get(type); &#125; else &#123; if(type.equals("ProductA")) &#123; product = new ProductA(); &#125; if(type.equals("ProductB")) &#123; product = new ProductB(); &#125; // 将对象放入map容器中 prMap.put(type, product); &#125; return product; &#125;&#125;]]></content>
      <categories>
        <category>design pattern</category>
      </categories>
      <tags>
        <tag>design pattern</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[单例模式]]></title>
    <url>%2F2018%2F06%2F03%2F%E5%8D%95%E4%BE%8B%E6%A8%A1%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[单例模式的定义 单例模式(singleton pattern) 是一个比较简单的模式,定义如下:Ensure a class has only one instance, and provide a global point of access to it.(确保某一个类只有一个实例,而且自行实例化并向这个系统提供这个实例) 单例模式的通用代码:12345678910111213public class Sinigleton &#123; private static final Singleton singleton = new Singleton(); // 限制产生多个对象 private Singleton() &#123; &#125; // 通过该方法获得实例对象 public static Singleton getSingleton() &#123; return singelton; &#125; // 类中其他方法 public static void doSomething() &#123; &#125;&#125; 单例模式的优点 减少内存开支,特别是一个对象需要频繁创建,销毁时 当一个对象的产生需要比较多的资源时,比如读取配置文件,产生其他依赖度对象时 避免对资源的多重占用,例如写文件的动作,只有一个实例存在内存中,避免对同一个资源文件的同时写操作 可以在系统中设置全局的访问点,优化共享资源的访问 单例模式的缺点 单例模式没有接口,扩展困难 对测试不利,并行开发环境中,单例未开发完成,无法进行测试 单例模式和单一职责原则有冲突 单例模式的使用场景 要求生成唯一序列号的环境 在整个项目中需要一个共享的数据访问点或者共享数据 创建一个对象消耗资源过多时,如访问IO和数据库资源等 需要大量的静态常量或者静态方法的环境,可以采用单例模式,也可以是枚举类(也是一种单例)或者定义为static的方式 单例模式的几种形式 懒汉式单例(线程不安全),在第一次调用时实例化自己 1234567891011public class Singleton &#123; private Singleton()&#123;&#125; private static Singleton single = null; // 静态工厂方法 public static Singleton getInstance() &#123; if(single == null) &#123; single = new Singleton(); &#125; return single; &#125;&#125; 懒汉式(线程安全) 12345678910111213141516171819202122232425262728// 1. 加锁public static synchronized Singelton getInstance() &#123; if(single == null) &#123; single = new Singleton(); &#125; return single;&#125;// 2. 双重检查public static Singleton getInstance() &#123; if(singleton == null) &#123; synchronized (Singleton.class) &#123; if(singleton == null) &#123; singleton = new Singleton(); &#125; &#125; &#125; return singleton;&#125;// 3. 静态内部类public class Singleton &#123; private static class LazyHolder &#123; private static final Singleton INSTANCE = new Singelton(); &#125; private Singleton ()&#123;&#125; public static final Singleton getInstance() &#123; return LazyHolder.INSTANCE; &#125;&#125; 饿汉式 123456789//在类初始化时,已经实例化public static Singleton &#123; private Singleton() &#123;&#125; private static final Singleton single = new Singleton(); // 静态工厂方法 public static Singleton getInstance() &#123; return single; &#125;&#125; 产生固定个数实例的单例模式 123456789101112131415161718192021222324252627282930313233public class Singleton &#123; // 最多产生几个实例 private static int maxNumber = 2; // 存储每个实例的名字 private static List&lt;String&gt; nameList = new ArrayList&lt;String&gt;(); // 定义一个列表,容纳所有的实例 private static List&lt;Singleton&gt; instancelist = new ArrayList&lt;Singelton&gt;(); // 当前实例的序列号 private static int countNumOfInstance = 0; // 产生所有的实例 static &#123; for(int i = 0; i &lt; maxNumber; i++) &#123; instanceList.add(new Emperor("实例"+(i+1))); &#125; &#125; // 私有化构造 private Singelton()&#123;&#125; // 传入名称,建立对象 private Singleton (String name) &#123; nameList.add(name); &#125; // 随机获得一个实例 public static Singleton getInstance() &#123; Random random = new Random(); countNumOfInstance = random.nextInt(maxNumOfSingelton); return instanceList.get(countNumOfInstance); &#125; // 获取当前实例的名称 public static void currentInstance() &#123; System.out.println(nameList.get(countNumOfSingleton)); &#125; &#125; 登记式单例 123456789101112131415161718192021222324public class singleton &#123; private static Map&lt;String,Singleton&gt; map = new HashMap&lt;String,Singleton&gt;(); static &#123; Singleton single = new Singelton(); map.put(single.getClass().getName(), single); &#125; // 私有的构造 private Singelton()&#123;&#125; // 实例工厂 public static Singleton getInstance(String name) &#123; if(name == null) &#123; name = Singelton.class.getName(); System.out.println("name == null"+"----&gt;name:"+name); &#125; if(map.get(name) == null) &#123; try&#123; map.put(name, (Singleton)Class.forName(name).newInstance()); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125; return map.get(name); &#125;&#125;]]></content>
      <categories>
        <category>design pattern</category>
      </categories>
      <tags>
        <tag>design pattern</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[centos7_64在vmWare中的联网配置]]></title>
    <url>%2F2018%2F04%2F24%2Fcentos7-64%E5%9C%A8vmWare%E4%B8%AD%E7%9A%84%E8%81%94%E7%BD%91%E9%85%8D%E7%BD%AE%2F</url>
    <content type="text"><![CDATA[vmware使用NAT模式的网络配置 首先在虚拟机下的 编辑虚拟机设置-&gt;网络设配器-&gt;网络连接中的自定义-&gt;选择VMnet8(NAT模式) 虚拟机的选项卡 编辑-&gt;虚拟网络编辑器-&gt;添加网络-&gt;选择VMnet8(如果之前有就不能再次添加了,只能有一个) 添加后修改子网IP为centos7的ip地址,最后一位改为0,点击 NAT设置-&gt;设置网关为IP地址最后一位改为2 修改centos7的网卡配置: 进入网卡文件 cd /etc/sysconfig/network-scripts/ 备份原有的网卡,我的是ifcfg-ens33 cp ifcfg-ens33 ./ifcfg-ens33.bak 修改原来的网卡,具体配置如下: vi ifcfg-ens33 123456789101112131415161718192021DEVICE=ens33TYPE=Ethernet# 静态ip staticBOOTPROTO=static DEFROUTE=yesPEERDNS=yesNM_CONTROLLED=yesPEERROUTES=yesIPV4_FAILURE_FATAL=noIPV6INIT=noNAME=&quot;system eth0&quot;UUID=5df66116-fefc-4c67-84ec-3153c8d0d893ONBOOT=yes# ip地址IPADDR=192.168.198.88# 网关GATEWAY=192.168.198.2NETMASK=255.255.255.0# 需要配置一个DNS,不然无法解析域名DNS1=8.8.8.8USERCTL=no 修改完毕后,保存文件 重启网卡,依次执行以下命令systemctl stop NetworkManager,systemctl disable NetworkManager,systemctl restart network 查看网卡配置 ip addr 查看MAC地址: vim /etc/udev/rules.d/70-persistent-net.rules 网卡的MAC地址 ifcfg-eth* 要和上述的文件中的网卡地址保持一致]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>vmWare</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[logback日志记录策略]]></title>
    <url>%2F2018%2F04%2F22%2Flogback%E6%97%A5%E5%BF%97%E8%AE%B0%E5%BD%95%E7%AD%96%E7%95%A5%2F</url>
    <content type="text"><![CDATA[近期需要将日志文件分开存储,因为流量监控部分数据采集接口的日志文件过多,需要将其单独存放 以前的日志打印策略很简单,采用logback日志框架,LOG_FILE的值来自application.yml文件中的logging.file的值,具体配置如下: 12345678910111213141516171819202122232425262728&lt;?xml version="1.0" encoding="UTF-8" ?&gt;&lt;configuration&gt; &lt;!--&lt;property name="LOG_FILE" value="/u02/tomcat/flowsystem/logs/fs"/&gt;--&gt; &lt;!-- 控制台 --&gt; &lt;appender name="STDOUT" class="ch.qos.logback.core.ConsoleAppender"&gt; &lt;encoder&gt; &lt;pattern&gt;%d&#123;'yyyy-MM-dd HH:mm:ss,SSS'&#125; %highlight(%5level) - %boldYellow([%-21thread]) %boldGreen(%-50logger&#123;50&#125;) : %m%n&lt;/pattern&gt; &lt;/encoder&gt; &lt;/appender&gt; &lt;!-- 通用日志 appender --&gt; &lt;appender name="COMMON" class="ch.qos.logback.core.rolling.RollingFileAppender"&gt; &lt;rollingPolicy class="ch.qos.logback.core.rolling.TimeBasedRollingPolicy"&gt; &lt;fileNamePattern&gt;$&#123;LOG_FILE&#125;-%d&#123;yyyy-MM-dd&#125;.log&lt;/fileNamePattern&gt; &lt;!-- 日志最大的历史 90天 --&gt; &lt;maxHistory&gt;90&lt;/maxHistory&gt; &lt;/rollingPolicy&gt; &lt;encoder&gt; &lt;pattern&gt;%d&#123;'yyyy-MM-dd HH:mm:ss,SSS'&#125; %5level - [%-21thread] %-50logger&#123;50&#125; : %m%n&lt;/pattern&gt; &lt;/encoder&gt; &lt;/appender&gt; &lt;root level="INFO"&gt; &lt;appender-ref ref="STDOUT" /&gt; &lt;appender-ref ref="COMMON" /&gt; &lt;/root&gt;&lt;/configuration&gt; 这里我们将其改造一下,将数据采集接口的日志以及所有ERROR级别的文件单独存放 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485&lt;?xml version="1.0" encoding="UTF-8" ?&gt;&lt;configuration&gt; &lt;!-- 控制台 --&gt; &lt;appender name="STDOUT" class="ch.qos.logback.core.ConsoleAppender"&gt; &lt;encoder&gt; &lt;pattern&gt;%d&#123;'yyyy-MM-dd HH:mm:ss,SSS'&#125; %highlight(%5level) - %boldYellow([%-21thread]) %boldGreen(%-50logger&#123;50&#125;) : %m%n&lt;/pattern&gt; &lt;/encoder&gt; &lt;/appender&gt; &lt;!-- 通用日志 appender --&gt; &lt;appender name="COMMON" class="ch.qos.logback.core.rolling.RollingFileAppender"&gt; &lt;!--&lt;file&gt;$&#123;LOG_FILE&#125;.log&lt;/file&gt;--&gt; &lt;rollingPolicy class="ch.qos.logback.core.rolling.TimeBasedRollingPolicy"&gt; &lt;fileNamePattern&gt;$&#123;LOG_FILE&#125;-%d&#123;yyyy-MM-dd&#125;.log&lt;/fileNamePattern&gt; &lt;!-- 日志最大的历史 90天 --&gt; &lt;maxHistory&gt;90&lt;/maxHistory&gt; &lt;/rollingPolicy&gt; &lt;encoder&gt; &lt;pattern&gt;%d&#123;'yyyy-MM-dd HH:mm:ss,SSS'&#125; %5level - [%-21thread] %-50logger&#123;50&#125; : %m%n&lt;/pattern&gt; &lt;/encoder&gt; &lt;!--添加过滤器,ERROR级别的日志不会被记录--&gt; &lt;filter class="ch.qos.logback.classic.filter.LevelFilter"&gt; &lt;level&gt;ERROR&lt;/level&gt; &lt;onMatch&gt;DENY&lt;/onMatch&gt; &lt;onMismatch&gt;ACCEPT&lt;/onMismatch&gt; &lt;/filter&gt; &lt;/appender&gt; &lt;!--数据采集接口的 appender--&gt; &lt;appender name="COLLECT_APPENDER" class="ch.qos.logback.core.rolling.RollingFileAppender"&gt; &lt;!--&lt;file&gt;$&#123;LOG_FILE&#125;.log&lt;/file&gt;--&gt; &lt;rollingPolicy class="ch.qos.logback.core.rolling.TimeBasedRollingPolicy"&gt; &lt;fileNamePattern&gt;$&#123;LOG_FILE&#125;-COLLECT-%d&#123;yyyy-MM-dd&#125;.log&lt;/fileNamePattern&gt; &lt;!-- 日志最大的历史 90天 --&gt; &lt;maxHistory&gt;90&lt;/maxHistory&gt; &lt;/rollingPolicy&gt; &lt;encoder&gt; &lt;pattern&gt;%d&#123;'yyyy-MM-dd HH:mm:ss,SSS'&#125; %5level - [%-21thread] %-50logger&#123;50&#125; : %m%n&lt;/pattern&gt; &lt;/encoder&gt; &lt;!--添加过滤器,ERROR级别的日志不会被记录--&gt; &lt;filter class="ch.qos.logback.classic.filter.LevelFilter"&gt; &lt;level&gt;ERROR&lt;/level&gt; &lt;onMatch&gt;DENY&lt;/onMatch&gt; &lt;onMismatch&gt;ACCEPT&lt;/onMismatch&gt; &lt;/filter&gt; &lt;/appender&gt; &lt;!--ERROR级别的 appender--&gt; &lt;appender name="ERROR_APPENDER" class="ch.qos.logback.core.rolling.RollingFileAppender"&gt; &lt;!--&lt;file&gt;$&#123;LOG_FILE&#125;.log&lt;/file&gt;--&gt; &lt;!--基于时间的日志记录策略--&gt; &lt;rollingPolicy class="ch.qos.logback.core.rolling.TimeBasedRollingPolicy"&gt; &lt;!--每天一个日志文件--&gt; &lt;fileNamePattern&gt;$&#123;LOG_FILE&#125;-ERROR-%d&#123;yyyy-MM-dd&#125;.log&lt;/fileNamePattern&gt; &lt;!-- 日志最大的历史 90天 --&gt; &lt;maxHistory&gt;90&lt;/maxHistory&gt; &lt;/rollingPolicy&gt; &lt;encoder&gt; &lt;pattern&gt;%d&#123;'yyyy-MM-dd HH:mm:ss,SSS'&#125; %5level - [%-21thread] %-50logger&#123;50&#125; : %m%n&lt;/pattern&gt; &lt;/encoder&gt; &lt;!--添加过滤器,只记录ERROR级别的日志--&gt; &lt;filter class="ch.qos.logback.classic.filter.LevelFilter"&gt; &lt;level&gt;ERROR&lt;/level&gt; &lt;onMatch&gt;ACCEPT&lt;/onMatch&gt; &lt;onMismatch&gt;DENY&lt;/onMismatch&gt; &lt;/filter&gt; &lt;/appender&gt; &lt;!--对应数据采集的包下的日志文件配置,additivity设置为false,避免将root中的配置再记录一次--&gt; &lt;logger name="com.taikang.flowsystem.datacollection" level="INFO" additivity="false"&gt; &lt;appender-ref ref="STDOUT" /&gt; &lt;appender-ref ref="COLLECT_APPENDER"/&gt; &lt;appender-ref ref="ERROR_APPENDER"/&gt; &lt;/logger&gt; &lt;!--root配置,所有的包遵循的日志打印方式--&gt; &lt;root level="INFO"&gt; &lt;appender-ref ref="STDOUT" /&gt; &lt;appender-ref ref="COMMON" /&gt; &lt;appender-ref ref="ERROR_APPENDER"/&gt; &lt;/root&gt; &lt;/configuration&gt; 这样datacollection包下的日志和ERROR级别的日志就会分别存放在${LOG_FILE}-COLLECT-{yyyy-MM-dd}.log和${LOG_FILE}-ERROR-{yyyy-MM-dd}.log文件中了.]]></content>
      <categories>
        <category>log</category>
      </categories>
      <tags>
        <tag>logback</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[kafka的基本使用]]></title>
    <url>%2F2018%2F04%2F18%2Fkafka%E7%9A%84%E5%9F%BA%E6%9C%AC%E4%BD%BF%E7%94%A8%2F</url>
    <content type="text"><![CDATA[一些基本信息 Apache Kafka: 消息中间件的一种, 一般的消息中间件会有消息的生产者,消息的消费者,主题等概念,kafka也有,除此之外,kafka是一个分布式的流处理平台 作为一个流处理平台,主要有以下三点能力: 从流的记录中进行发布订阅,类似于企业消息系统中的消息队列 以一种高可用的方式存储记录流 实时的处理记录流 应用场景: 构建实时的数据流管道,在系统和应用之间可靠的获取数据 构建实时的流式处理应用,转变或者反应数据流 为了理解kafka做的事情,可以从以下了解到kafka的能力 首先是几个概念 kafka以一个集群的方式运行在一个或者多个服务器上而且可以跨越多个数据中心 kafka集群在叫做topic的目录中存储流式的记录 每条记录包括一个key,一个value,一个timestamp kafka包括以下四个核心API producer API consumer API Streams API Connector API快速开始 下载kafka,地址:http://kafka.apache.org/downloads 下载二进制包,解压 12tar -xzf kafka_2.11-1.1.0.tgzcd kafka_2.11-1.1.0 启动服务,kafka需要使用zookeeper,如果没有下载单独的zookeeper,kafka提供了一个 启动kafka自带的zookeeper,可以使用nohup命令后台启动 1bin/zookeeper-server-start.sh config/zookeeper.properties 再启动kafka (我在启动时有报错,xxx:找不到名称或者服务,只需要再/etc/hosts文件中加入xxx到本地ip对应的名称中,再启动就可以了) 1bin/kafka-server-start.sh config/server.properties 创建一个topic 创建一个叫做test的topic,并且只有一个副本,一个分区 1bin/kafka-topic.sh --create --zookeeper localhost:2181 --replication-factor 1 --partition 1 --topic test 我们可以查看topic列表 1bin/kafka-topics.sh --list --zookeeper locahost:2181 也可以通过配置broker在不存在topic时自动创建topic,以替代手动创建topic 发送一些消息 kafka提供了命令行客户端可以从文件中或者标准输入中向kafka集群中发送消息 1bin/kafka-console-producer.sh --broker-list localhost:9092 --topic test 然后就可以在标准输入中写消息了 开启命令行客户端的消费者 1bin/kafka-console-consumer.sh --bootstrap-server localhost:9092 --topic test --from-beginning 然后之前输入的消息就会打印在控制台上 设置一个有多个broker的集群 复制server.properties文件cp config/server/properties config/server-1.propertiescp config/server/properties config/server-2.properties 修改其中的配置 123456789config/server-1.properties: broker.id=1 listeners=PLAINTEXT://:9093 log.dir=/tmp/kafka-logs-1 config/server-2.properties: broker.id=2 listeners=PLAINTEXT://:9094 log.dir=/tmp/kafka-logs-2 broker.id表示集群中每一个节点的唯一的,永久的名称,修改端口号和log目录是因为我们将多个broker运行在一台机器上,不修改将会导致多个broker的数据相互覆盖 此时我们可以将配置好的两个新的节点启动bin/kafka-server-start.sh config/server-1.properties &amp; bin/kafka-server-start.sh config/server-2.properties &amp; 现在我们可以创建一个新的topic,它拥有3个副本 1bin/kafka-topics.sh --create --zookeeper localhost:2181 --replication-factor 3 --partitions 1 --topic myreplicated-topic 可以运行”describe topics”命令查看topic信息 1bin/kafka-topics.sh --describe --zookeeper localhost:2181 --topic my-replicated-topic]]></content>
      <categories>
        <category>kafka</category>
      </categories>
      <tags>
        <tag>kafka</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[docker基本操作]]></title>
    <url>%2F2018%2F04%2F16%2Fdocker%E5%9F%BA%E6%9C%AC%E6%93%8D%E4%BD%9C%2F</url>
    <content type="text"><![CDATA[docker安装 centos7以下版本安装太麻烦,这里只说centos7安装docker的过程 Docker官方建议在Ubuntu中安装，因为Docker是基于Ubuntu发布的，而且一般Docker出现的问题Ubuntu是最先更新或者打补丁的。在很多版本的CentOS中是不支持更新最新的一些补丁包的。 docker安装 通过yum安装 yum -y install docker 可以通过 docker -v 查看当前的docker版本 安装最新版的docker curl -sSL https://get.daocloud.io/docker | sh 开机启动：systemctl enable docker.service/docker 启动docker：systemctl start docker.service 停止docker：systemctl stop docker.service 重启docker：systemctl restart docker.service 查看docker状态：systemctl status docker.service 查看docker概要信息：docker info 查看docker帮助文档：docker --help docker镜像文件 Docker镜像是由文件系统叠加而成（是一种文件的存储形式）。最底端是一个文件引导系统，即bootfs，这很像典型的Linux/Unix的引导文件系统。Docker用户几乎永远不会和引导系统有什么交互。实际上，当一个容器启动后，它将会被移动到内存中，而引导文件系统则会被卸载，以留出更多的内存供磁盘镜像使用。Docker容器启动是需要的一些文件，而这些文件就可以称为Docker镜像。 列出docker下所有的镜像 docker images 这些镜像都是存储在Docker宿主机的/var/lib/docker目录下 REPOSITORY：镜像所在的仓库名称 TAG：镜像标签（version） IMAGE ID：镜像ID CREATED：镜像的创建日期（不是获取该镜像的日期） SIZE：镜像大小 镜像TAG 为了区分同一个仓库下的不同镜像，Docker提供了一种称为标签（Tag）的功能。每个镜像在列出来时都带有一个标签，例如12.10、12、04等等。每个标签对组成特定镜像的一些镜像层进行标记（比如，标签12.04就是对所有Ubuntu12.04镜像层的标记）。这种机制使得同一个仓库中可以存储多个镜像。 我们在运行同一个仓库中的不同镜像时，可以通过在仓库名后面加上一个冒号和标签名来指定该仓库中的某一具体的镜像，例如docker run --name custom_container_name –i –t docker.io/ubunto:12.04 /bin/bash， 表明从镜像Ubuntu:12.04启动一个容器，而这个镜像的操作系统就是Ubuntu:12.04。在构建容器时指定仓库的标签也是一个好习惯。 拉取镜像 国内访问docker hub 速度太慢,需要配置镜像加速 使用ustc的镜像 编辑该文件 vim /etc/docker/daemon.json ,如果该文件不存在就手动创建 在文件中输入以下内容 123&#123; &quot;registry-mirrors&quot;: [&quot;https://docker.mirrors.ustc.edu.cn&quot;]&#125; 然后重启docker systemctl restart docker.service 通过 docker pull 下载镜像 docker pull centos:7 docker pull ubuntu DaoCloud也提供了docker加速器，但是跟ustc不同，需要用户注册后才能使用，并且每月限制流量10GB。linux上使用比较简单，一条脚本命令搞定。 执行该命令：curl -sSL https://get.daocloud.io/daotools/set_mirror.sh | sh -s http://{your_id}.m.daocloud.io 实际上面的脚本执行后，改的是/usr/lib/systemd/system/docker.service文件，加了个–registry-mirror参数。如果不执行上面的脚本命令，可以如下直接修改这个文件也可. 然后重启配置 systemctl daemon-reload 重启docker服务 systemctl restart docker 其他的镜像加速服务 阿里云|网易蜂巢,配置过程与daocloud类似 启动镜像 启动命令 docker run -it docker.io/centos 创建容器常用的参数说明: 创建容器的命令: docker run -i: 表示以”交互模式”运行容器 -t: 表示容器启动后会进入其命令行. 加入-it两个参数后容器启动后就能登陆进去.即分配一个伪终端 --name: 表示创建的容器名称 -v: 表示目录映射关系（前者是宿主机目录，后者是映射到宿主机上的目录），可以使用多个-v做多个目录或文件映射。注意：最好做目录映射，在宿主机上做修改，然后共享到容器上。 -d: 在run后面加上-d参数,则会创建一个守护式容器在后台运行（这样创建容器后不会自动登录容器，如果只加-i -t两个参数，创建后就会自动进去容器）。 -p：表示端口映射，前者是宿主机端口，后者是容器内的映射端口。可以使用多个-p做多个端口映射 启动之前拉取的centos7镜像并且进入容器 docker run -it centos:7 创建一个守护式的容器 docker run -d -t ubuntu:latest /bin/bash 登陆容器的方式: docker attach container_name 或者 container_id /bin/bash （exit，容器退出） docker exec –it container_name 或者 container_id /bin/bash（exit，容器正常运行） 查看所有的容器(启动过的): docker ps -a 查看最后一次运行的容器: docker ps -I 查看正在运行的容器: docker ps 停止正在运行的容器: docker stop $CONTAINER_NAME/ID 启动已经运行过的容器: docker start $CONTAINEr_NAME/ID 进入守护式容器内部: docker exec -t -i $CONTAINER_NAME /bin/bash 深入容器内部: docker inspech $CONTAINER_NAME 删除所有的容器: docker rm `docker ps -a -q` 删除指定的容器: docker rm $CONTAINER_ID 查看运行的容器日志: docker logs $CONTAINER_ID]]></content>
      <categories>
        <category>容器</category>
      </categories>
      <tags>
        <tag>docker</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[java8中的函数式编程]]></title>
    <url>%2F2018%2F02%2F04%2Fjava8%E4%B8%AD%E7%9A%84%E5%87%BD%E6%95%B0%E5%BC%8F%E7%BC%96%E7%A8%8B%2F</url>
    <content type="text"><![CDATA[java8出现以来,lambda是最重要的特性之一,它可以让我们用简洁流畅的代码完成一个功能。lambda表达式是一段可以传递的代码，他的核心思想是将面向对象中的传递数据变成传递行为。 使用lambda表达式替换匿名内部类使用lambda表达式创建一个线程12345678910//java8以前new Thread(new Runnable() &#123; @Override public void run() &#123; System.out.println("以前的写法"); &#125;&#125;).start();//java8,lambda只需要一行代码new Thread(() -&gt; System.out.println("lambda的写法")).start(); 一般都会把lambda表达式的变量名起的短一些,这样能使代码更加的简洁。 使用lambda表达式对列表进行迭代123456789List&lt;String&gt; list = Arrays.asList("a", "b", "c", "e");//8之前for (String s : list) &#123; System.out.println(s);&#125;//java8中列表有了一个foreach()的方法,可以迭代所有的对象,并将你的lambda代码应用在其中list.forEach(System.out::println); //使用方法引用更加的简短,C++里面的双冒号、范围解析操作符现在在Java 8中用来表示方法引用list.forEach(n -&gt; System.out.println(n)); 使用lambda表达式和函数式接口java8中添加了一个包,叫做java.util.function,它包含了很多的类,用来支持java的函数式编程下面是java.util.function包中的接口示例12345678910111213141516171819202122232425262728293031323334353637383940414243444546//消费型的接口 private void consume(Integer money, Consumer&lt;Integer&gt; consumer) &#123; consumer.accept(money); &#125; void test11() &#123; consume(1000,money -&gt; System.out.println("this number is: "+money)); &#125; //供给型接口 List&lt;Integer&gt; supply(Integer num, Supplier&lt;Integer&gt; supplier) &#123; ArrayList&lt;Integer&gt; resultList = new ArrayList&lt;&gt;(); for(int x = 0; x &lt; num; x++) &#123; resultList.add(supplier.get()); &#125; return resultList; &#125; void test12() &#123; List&lt;Integer&gt; supply = supply(10, () -&gt; (int) (Math.random() * 100)); supply.forEach(System.out::println); &#125; //函数型接口 Integer convert(String str, Function&lt;String,Integer&gt; function) &#123; return function.apply(str); &#125; void test13() &#123; convert("28",Integer::parseInt); &#125; //断言型接口 List&lt;String&gt; isOrNot(List&lt;String&gt; fruit,Predicate&lt;String&gt; predicate) &#123; ArrayList&lt;String&gt; list = new ArrayList&lt;&gt;(); for(String s: fruit) &#123; if(predicate.test(s)) &#123; list.add(s); &#125; &#125; return list; &#125; void test14() &#123; List&lt;String&gt; fruits = Arrays.asList("香蕉", "哈密瓜", "榴莲", "火龙果", "水蜜桃"); List&lt;String&gt; orNot = isOrNot(fruits, f -&gt; f.length() == 2); System.out.println(orNot); &#125; 使用lambda表达式和Predicate接口 12345678910111213141516171819202122232425262728293031 /* * 函数式接口Predicate */ void test3() &#123; List&lt;String&gt; list = Arrays.asList("Java", "Scala", "C++", "Haskell", "Lisp"); //以J开头的 filter(list,str -&gt; str.startsWith("J")); //以a结尾的 filter(list,str -&gt; str.endsWith("a")); //打印所有的 filter(list,str -&gt; true); //都不打印 filter(list,str -&gt; false); //长度大于4的 betterFilter(list,str -&gt; str.length() &gt; 4); &#125; private void filter(List&lt;String&gt; names, Predicate&lt;String&gt; condition) &#123; for (String name : names) &#123; if(condition.test(name)) &#123; System.out.println(name+""); &#125; &#125; &#125; //更好的办法 private void betterFilter(List&lt;String&gt; names, Predicate&lt;String&gt; condition) &#123;// names.stream().filter(name -&gt; condition.test(name)).forEach(name -&gt; System.out.println(name)); //可以简化如下 names.stream().filter(condition).forEach(System.out::println); &#125; 在lambda表达式中加入Predicate 12345678910111213/* * 在表达式中加入Predicate * java.util.function.Predicate 允许将两个或更多的 Predicate 合成一个。它提供类似于逻辑操作符AND和OR的方法，名字叫做 and()、or() 和 xor()，用于将传入 filter() 方法的条件合并起来。 * 例如，要得到所有以J开始，长度为四个字母的语言，可以定义两个独立的 Predicate 示例分别表示每一个条件，然后用 Predicate.and() 方法将它们合并起来 */void test4() &#123; List&lt;String&gt; list = Arrays.asList("Java", "Scala", "C++", "Haskell", "Lisp"); Predicate&lt;String&gt; startWithJ = n -&gt; n.startsWith("J"); //其实就是函数式接口Predicate接口的实现 Predicate&lt;String&gt; fourLetterLong = n -&gt; n.length() == 4; list.stream() .filter(startWithJ.and(fourLetterLong)) .forEach(System.out::println);&#125; java8中使用lambda表达式的Map和Reduce示例 map 1234567891011121314/* * 使用lambda表达式的Map和reduce示例 * map允许你将对象进行转换 */void test5() &#123; List&lt;Integer&gt; costBeforeTax = Arrays.asList(100,200,300,400,500); //不使用lambda表达式为每一个订单加上12%的税 for (Integer cost : costBeforeTax) &#123; double price = cost + .12*cost; System.out.println(price); &#125; //使用lambda表达式 costBeforeTax.stream().map(cost -&gt; cost + .12*cost).forEach(System.out::println);&#125; reduce 12345678/* * 使用reduce()函数进行折叠操作,类似于sql中的聚合函数 */void test6() &#123; List&lt;Integer&gt; costBeforeTax = Arrays.asList(100,200,300,400,500); Double aDouble = costBeforeTax.stream().map(cost -&gt; cost + .12 * cost).reduce((n, m) -&gt; n + m).get(); System.out.println("Total: "+aDouble);&#125; 通过过滤创建一个string的列表12345678910/* * 通过过滤创建一个String列表 * 过滤是Java开发者在大规模集合上的一个常用操作，而现在使用lambda表达式和流API过滤大规模数据集合非常的简单。 * 流提供了一个 filter() 方法，接受一个 Predicate 对象，即可以传入一个lambda表达式作为过滤逻辑 */private void test7() &#123; List&lt;String&gt; strList = Arrays.asList("as","artfg","asdf","shat"); List&lt;String&gt; collect = strList.stream().filter(x -&gt; x.length() &gt; 2).collect(Collectors.toList()); System.out.printf("原始串:%s,过滤后:%s",strList,collect);&#125; 对列表的每个元素应用函数123456789 /* * 对列表的每个元素应用函数 */ void test8() &#123;// 将字符串换成大写并用逗号链接起来 List&lt;String&gt; g7 = Arrays.asList("USA", "Japan", "France", "Germany", "Italy", "U.K.","Canada"); String collect = g7.stream().map(String::toUpperCase).collect(Collectors.joining(",")); System.out.println(collect); &#125; 复制不同的值,创建一个子列表123456// 数字去重的例子void test9() &#123; List&lt;Integer&gt; numbers = Arrays.asList(9, 10, 3, 4, 7, 3, 4); List&lt;Double&gt; collect = numbers.stream().map(Math::sqrt).distinct().collect(Collectors.toList()); System.out.printf("原来的: %s,现在的: %s",numbers,collect);&#125; 计算集合元素的最大值、最小值、总和以及平均值12345678910111213/* * 计算集合元素的最大数值,最小值,总和以及平均值 * IntStream、LongStream 和 DoubleStream 等流的类中，有个非常有用的方法叫做 summaryStatistics() 。可以返回 IntSummaryStatistics、LongSummaryStatistics 或者 DoubleSummaryStatistics，描述流中元素的各种摘要数据。 * 在本例中，我们用这个方法来计算列表的最大值和最小值。它也有 getSum() 和 getAverage() 方法来获得列表的所有元素的总和及平均值。 */void test10() &#123; List&lt;Integer&gt; primes = Arrays.asList(2, 3, 5, 7, 11, 13, 17, 19, 23, 29); IntSummaryStatistics stat = primes.stream().mapToInt((x -&gt; x)).summaryStatistics(); System.out.println("最大值: "+stat.getMax()); System.out.println("最小值: "+stat.getMin()); System.out.println("求和: "+stat.getSum()); System.out.println("平均值: "+stat.getAverage());&#125;]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>java8</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[mysql的一些函数]]></title>
    <url>%2F2018%2F01%2F23%2Fmysql%E7%9A%84%E4%B8%80%E4%BA%9B%E5%87%BD%E6%95%B0%2F</url>
    <content type="text"><![CDATA[字符串函数 ascii(str) 返回字符串str的第一个字符的ascii值(str是空串时返回0) ord(str) 返回 若字符串str的最左字符是一个多字节字符,则返回该字符的代码,代码的计算通过使用以下公式计算其组成字节的数值而得出: (1st byte code) + (2nd byte code × 256) + (3rd byte code × 256^2) … conv(n,from_base,to_base) 对数字n进制转换,并转换为字串返回(任何参数为null时返回null,进制范围为2-36进制,当to_base是负数时n作为有符号数否则作无符号数,conv以64位点精度工作) 123456mysql&gt; select conv(&quot;a&quot;,16,2); -&gt; &apos;1010&apos; mysql&gt; select conv(&quot;6e&quot;,18,8); -&gt; &apos;172&apos; mysql&gt; select conv(-17,10,-18); -&gt; &apos;-h&apos; bin(n) 把n转为二进制值并以字串返回(n是bigint数字,等价于conv(n,10,2)) 12mysql&gt; select bin(12); -&gt; &apos;1100&apos; oct(n) 把n转为八进制值并以字串返回(n是bigint数字,等价于conv(n,10,8)) hex(n) 把n转为十六进制并以字串返回(n是bigint数字,等价于conv(n,10,16)) char(n,...) 返回由参数n,…对应的ascii代码字符组成的一个字串(参数是n,…是数字序列,null值被跳过) 12mysql&gt; select char(77,121,83,81,&apos;76&apos;); -&gt; &apos;mysql&apos; concat(str1,str2,...) 把参数连成一个长字符串并返回(任何参数是null时返回null) length(str),octet_length(str),char_length(str),character_length(str) 返回字符串str的长度(对于多字节字符char_length仅计算一次) locate(substr,str),position(substr in str) 返回字符串substr在字符串str第一次出现的位置(str不包含substr时返回0) 12mysql&gt; select locate(&apos;bar&apos;, &apos;foobarbar&apos;); -&gt; 4 locate(substr,str,pos) 返回字符串substr在字符串str的第pos个位置起第一次出现的位置(str不包含substr时返回0) 12mysql&gt; select locate(&apos;bar&apos;, &apos;foobarbar&apos;,5); -&gt; 7 instr(str,substr) 返回字符串substr在字符串str第一次出现的位置(str不包含substr时返回0) lpad(str,len,padstr) 用字符串padstr填补str左端直到字串长度为len并返回 12mysql&gt; select lpad(&apos;hi&apos;,4,&apos;??*&apos;); -&gt; &apos;??hi&apos; rpad(str,len,padstr) 用字符串padstr填补str右端直到字串长度为len并返回 left(str,len) 返回字符串str的左端len个字符 right(str,len) 返回字符串str的右端len个字符 substring(str,pos,len),substring(str from pos for len),mid(str,pos,len) 返回字符串str的位置pos起len个字符 substring(str,pos),substring(str from pos) 返回字符串str的位置pos起的一个子串 substring_index(str,delim,count) 返回从字符串str的第count个出现的分隔符delim之后的子串(count为正数时返回左端,否则返回右端子串) 1234mysql&gt; select substring_index(&apos;www.mysql.com&apos;, &apos;.&apos;, 2); -&gt; &apos;www.mysql&apos; mysql&gt; select substring_index(&apos;www.mysql.com&apos;, &apos;.&apos;, -2); -&gt; &apos;mysql.com&apos; ltrim(str) 返回删除了左空格的字符串str 12mysql&gt; select ltrim(&apos; barbar&apos;); -&gt; &apos;barbar&apos; rtrim(str) 返回删除了右空格的字符串str trim([[both | leading | trailing] [remstr] from] str) 返回前缀或后缀remstr被删除了的字符串str(位置参数默认both,remstr默认值为空格) 12345678mysql&gt; select trim(&apos; bar &apos;); -&gt; &apos;bar&apos; mysql&gt; select trim(leading &apos;x&apos; from &apos;xxxbarxxx&apos;); -&gt; &apos;barxxx&apos; mysql&gt; select trim(both &apos;x&apos; from &apos;xxxbarxxx&apos;); -&gt; &apos;bar&apos; mysql&gt; select trim(trailing &apos;xyz&apos; from &apos;barxxyz&apos;); -&gt; &apos;barx&apos; soundex(str) 返回str的一个同音字符串(听起来“大致相同”字符串有相同的同音字符串,非数字字母字符被忽略,在a-z外的字母被当作元音) 1234mysql&gt; select soundex(&apos;hello&apos;); -&gt; &apos;h400&apos; mysql&gt; select soundex(&apos;quadratically&apos;); -&gt; &apos;q36324&apos; space(n) 返回由n个空格字符组成的一个字符串 replace(str,from_str,to_str) 用字符串to_str替换字符串str中的子串from_str并返回 reverse(str) 颠倒字符串str的字符顺序并返回 insert(str,pos,len,newstr) 把字符串str由位置pos起len个字符长的子串替换为字符串newstr并返回 elt(n,str1,str2,str3,...) 返回第n个字符串(n小于1或大于参数个数返回null) field(str,str1,str2,str3,...) 返回str等于其后的第n个字符串的序号(如果str没找到返回0) find_in_set(str,strlist) 返回str在字符串集strlist中的序号(任何参数是null则返回null,如果str没找到返回0,参数1包含”,”时工作异常) make_set(bits,str1,str2,...) 把参数bits的数字转为二进制,假如某个位置的二进制位等于bits,对应位置的字串选入字串集并返回(null串不添加到结果中) 123456mysql&gt; select make_set(1,&apos;a&apos;,&apos;b&apos;,&apos;c&apos;); -&gt; &apos;a&apos; mysql&gt; select make_set(1 | 4,&apos;hello&apos;,&apos;nice&apos;,&apos;world&apos;); -&gt; &apos;hello,world&apos; mysql&gt; select make_set(0,&apos;a&apos;,&apos;b&apos;,&apos;c&apos;); -&gt; &apos;&apos; export_set(bits,on,off,[separator,[number_of_bits]]) 按bits排列字符串集,只有当位等于1时插入字串on,否则插入off(separator默认值”,”,number_of_bits参数使用时长度不足补0而过长截断) 12mysql&gt; select export_set(5,&apos;y&apos;,&apos;n&apos;,&apos;,&apos;,4) -&gt; y,n,y,n lcase(str),lower(str) 返回小写的字符串str ucase(str),upper(str) 返回大写的字符串str load_file(file_name) 读入文件并且作为一个字符串返回文件内容(文件无法找到,路径不完整,没有权限,长度大于max_allowed_packet会返回null)12mysql&gt; update table_name set blob_column=load_file (&quot;/tmp/picture&quot;) where id=1; 数学函数 abs(n) 返回n的绝对值 sign(n) 返回参数的符号(为-1、0或1) mod(n,m) 取模运算,返回n被m除的余数(同%操作符) floor(n) 返回不大于n的最大整数值 ceiling(n) 返回不小于n的最小整数值 round(n,d) 返回n的四舍五入值,保留d位小数(d的默认值为0) exp(n) 返回值e的n次方(自然对数的底) log(n) 返回n的自然对数 log10(n) 返回n以10为底的对数 pow(x,y),power(x,y) 返回值x的y次幂 sqrt(n) 返回非负数n的平方根 pi() 返回圆周率 cos(n) 返回n的余弦值 sin(n) 返回n的正弦值 tan(n) 返回n的正切值 acos(n) 返回n反余弦(n是余弦值,在-1到1的范围,否则返回null) asin(n) 返回n反正弦值 atan(n) 返回n的反正切值 atan2(x,y) 返回2个变量x和y的反正切(类似y/x的反正切,符号决定象限) cot(n) 返回x的余切 rand(),rand(n) 返回在范围0到1.0内的随机浮点值(可以使用数字n作为初始值) degrees(n) 把n从弧度变换为角度并返回 radians(n) 把n从角度变换为弧度并返回 truncate(n,d) 保留数字n的d位小数并返回 least(x,y,...) 返回最小值(如果返回值被用在整数(实数或大小敏感字串)上下文或所有参数都是整数(实数或大小敏感字串)则他们作为整数(实数或大小敏感字串)比较,否则按忽略大小写的字符串被比较) greatest(x,y,...) 返回最大值(其余同least()) 时间日期函数 dayofweek(date) 返回日期date是星期几(1=星期天,2=星期一,……7=星期六,odbc标准) weekday(date) 返回日期date是星期几(0=星期一,1=星期二,……6= 星期天) dayofmonth(date) 返回date是一月中的第几日(在1到31范围内) dayofyear(date) 返回date是一年中的第几日(在1到366范围内) month(date) 返回date中的月份数值 dayname(date) 返回date是星期几(按英文名返回) monthname(date) 返回date是几月(按英文名返回) quarter(date) 返回date是一年的第几个季度 week(date,first) 返回date是一年的第几周(first默认值0,first取值1表示周一是周的开始,0从周日开始) year(date) 返回date的年份(范围在1000到9999) 12mysql&gt; select year(&apos;98-02-03&apos;); -&gt; 1998 hour(time) 返回time的小时数(范围是0到23) 12mysql&gt; select hour(&apos;10:05:03&apos;); -&gt; 10 minute(time) 返回time的分钟数(范围是0到59) second(time) 返回time的秒数(范围是0到59) period_add(p,n) 增加n个月到时期p并返回(p的格式yymm或yyyymm) 12mysql&gt; select period_add(9801,2); -&gt; 199803 period_diff(p1,p2) 返回在时期p1和p2之间月数(p1和p2的格式yymm或yyyymm) date_add(date,interval expr type) date_sub(date,interval expr type) adddate(date,interval expr type) subdate(date,interval expr type)对日期时间进行加减法运算,adddate()和subdate()是date_add()和date_sub()的同义词,也可以用运算符+和-而不是函数,date是一个datetime或date值,expr对date进行加减法的一个表达式字符串,type指明表达式expr应该如何被解释 [type值 含义 期望的expr格式]: second 秒 seconds minute 分钟 minutes hour 时间 hours day 天 days month 月 months year 年 years minute_second 分钟和秒 “minutes:seconds” hour_minute 小时和分钟 “hours:minutes” day_hour 天和小时 “days hours” year_month 年和月 “years-months” hour_second 小时, 分钟， “hours:minutes:seconds” day_minute 天, 小时, 分钟 “days hours:minutes” day_second 天, 小时, 分钟, 秒 “dayshours:minutes:seconds” expr中允许任何标点做分隔符,如果所有是date值时结果是一个date值,否则结果是一个datetime值 如果type关键词不完整,则mysql从右端取值,day_second因为缺少小时分钟等于minute_second 如果增加month、year_month或year,天数大于结果月份的最大天数则使用最大天数 12345678910111213141516171819202122232425262728293031mysql&gt; select &quot;1997-12-31 23:59:59&quot; + interval 1 second; -&gt; 1998-01-01 00:00:00 mysql&gt; select interval 1 day + &quot;1997-12-31&quot;; -&gt; 1998-01-01 mysql&gt; select &quot;1998-01-01&quot; - interval 1 second; -&gt; 1997-12-31 23:59:59 mysql&gt; select date_add(&quot;1997-12-31 23:59:59&quot;,interval 1second); -&gt; 1998-01-01 00:00:00 mysql&gt; select date_add(&quot;1997-12-31 23:59:59&quot;,interval 1day); -&gt; 1998-01-01 23:59:59 mysql&gt; select date_add(&quot;1997-12-31 23:59:59&quot;,interval&quot;1:1&quot; minute_second); -&gt; 1998-01-01 00:01:00 mysql&gt; select date_sub(&quot;1998-01-01 00:00:00&quot;,interval &quot;11:1:1&quot; day_second); -&gt; 1997-12-30 22:58:59 mysql&gt; select date_add(&quot;1998-01-01 00:00:00&quot;, interval &quot;-110&quot; day_hour); -&gt; 1997-12-30 14:00:00 mysql&gt; select date_sub(&quot;1998-01-02&quot;, interval 31 day); -&gt; 1997-12-02 mysql&gt; select extract(year from &quot;1999-07-02&quot;); -&gt; 1999 mysql&gt; select extract(year_month from &quot;1999-07-0201:02:03&quot;); -&gt; 199907 mysql&gt; select extract(day_minute from &quot;1999-07-0201:02:03&quot;); -&gt; 20102 to_days(date) 返回日期date是西元0年至今多少天(不计算1582年以前) from_days(n) 给出西元0年至今多少天返回date值(不计算1582年以前) date_format(date,format) 根据format字符串格式化date值 在format字符串中可用标志符: %m 月名字(january……december) %w 星期名字(sunday……saturday) %d 有英语前缀的月份的日期(1st, 2nd, 3rd, 等等。） %y 年, 数字, 4 位 %y 年, 数字, 2 位 %a 缩写的星期名字(sun……sat) %d 月份中的天数, 数字(00……31) %e 月份中的天数, 数字(0……31) %m 月, 数字(01……12) %c 月, 数字(1……12) %b 缩写的月份名字(jan……dec) %j 一年中的天数(001……366) %h 小时(00……23) %k 小时(0……23) %h 小时(01……12) %i 小时(01……12) %l 小时(1……12) %i 分钟, 数字(00……59) %r 时间,12 小时(hh:mm:ss [ap]m) %t 时间,24 小时(hh:mm:ss) %s 秒(00……59) %s 秒(00……59) %p am或pm %w 一个星期中的天数(0=sunday ……6=saturday ） %u 星期(0……52), 这里星期天是星期的第一天 %u 星期(0……52), 这里星期一是星期的第一天 %% 字符% curdate(),current_date() 以’yyyy-mm-dd’或yyyymmdd格式返回当前日期值(根据返回值所处上下文是字符串或数字) curtime(),current_time() 以’hh:mm:ss’或hhmmss格式返回当前时间值(根据返回值所处上下文是字符串或数字) now(),sysdate(),current_timestamp() 以’yyyy-mm-dd hh:mm:ss’或yyyymmddhhmmss格式返回当前日期时间(根据返回值所处上下文是字符串或数字) unix_timestamp(),unix_timestamp(date) 返回一个unix时间戳(从’1970-01-01 00:00:00’gmt开始的秒数,date默认值为当前时间) from_unixtime(unix_timestamp) 以’yyyy-mm-dd hh:mm:ss’或yyyymmddhhmmss格式返回时间戳的值(根据返回值所处上下文是字符串或数字) from_unixtime(unix_timestamp,format) 以format字符串格式返回时间戳的值 sec_to_time(seconds) 以’hh:mm:ss’或hhmmss格式返回秒数转成的time值(根据返回值所处上下文是字符串或数字) time_to_sec(time) 返回time值有多少秒 转换函数 cast 用法：cast(字段 as 数据类型) [当然是否可以成功转换，还要看数据类型强制转化时注意的问题] 实例：select cast(a as unsigned) as b from cardserver where order by b desc; convert 用法：convert(字段,数据类型) 实例：select convert(a ,unsigned) as b from cardserver where order by b desc;]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[给本站配置一级域名以及https]]></title>
    <url>%2F2018%2F01%2F19%2F%E7%BB%99%E6%9C%AC%E7%AB%99%E9%85%8D%E7%BD%AEhttps%2F</url>
    <content type="text"><![CDATA[配置一级域名有关域名的配置部分挺简单的,登录阿里云,将域名以前的解析配置都删除掉,新增两个A记录,主机记录一个配置”@”直接解析主域名,一个使用”www”,解析www,记录值就填写服务器的ip地址.基本上不用等待,直接就能使用了. 配置https配置好了以后,再配置https,这个需要申请一个https的证书,阿里云有免费的证书可以申请,申请好后配置到nginx里面,就可以了. nginx主要配置内容记录如下:1234567891011121314151617181920212223242526272829server &#123; listen 443 ssl; listen 80; server_name yaoboqi.cn; ssl on; root html; index index.html index.htm; ssl_certificate ../cert/214354456760134.pem; ssl_certificate_key ../cert/214354456760134.key; ssl_session_timeout 5m; ssl_ciphers ECDHE-RSA-AES128-GCM-SHA256:ECDHE:ECDH:AES:HIGH:!NULL:!aNULL:!MD5:!ADH:!RC4; ssl_protocols TLSv1 TLSv1.1 TLSv1.2; ssl_prefer_server_ciphers on; error_page 497 https://yaoboqi.cn; location / &#123; proxy_pass https://zonzie.github.io; root html; index index.html index.htm; proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header REMOTE-HOST $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; &#125;&#125; 当网站只允许https访问时,nginx会报出497错误码,这里利用nginx的497状态码将默认的http访问后出现的错误页面重定向到https://yaoboqi.cn这个域名上.网站的流量统计用了leancloud,需要将新的域名添加到安全域名列表里,不然访问量是看不到的,对leancloud的请求会报出401未授权的错误.]]></content>
      <categories>
        <category>blog</category>
      </categories>
      <tags>
        <tag>nginx</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[git使用方法]]></title>
    <url>%2F2017%2F12%2F24%2Fgit%2F</url>
    <content type="text"><![CDATA[准备工作 首先需要安装git命令行工具gitbash 需要注册一个github账号 初始配置 安装完毕后,第一次使用: 设置用户名和邮箱,设置自己的用户名和邮箱 12git config --global user.name "zonzie"git config --global user.email "yaobq13@gmail.com" 生成ssh-key,之后可以不用每次提交代码时都输入账号密码 1ssh-keygen -t rsa -C &quot;yaobq13@gmail.com&quot; 之后会有提示:这时可以什么都不输入,三个回车 123Enter file in which to save the key (/c/Users/zonzie/.ssh/id_rsa): Enter passphrase (empty for no passphrase):Enter same passphrase again: 然后会生成公钥和私钥在用户根目录下的.ssh目录下id_rsa是私钥, id_rsa.pub是公钥 使用 ssh-agent 管理公钥 eval “$(ssh-agent -s)” ssh-add id_rsa.pub 登录github账户,将公钥添加到 settings/SSH and GPG keys 中 在gitbash中登录github ssh -T git@github.com 常用命令 git的常用命令 先建一个目录 mkdir myRepo 变成仓库 git init — 显示隐藏文件 `ls -ah 新建一个文件readme.txt,要在myRepo目录下或者子目录下 添加文件到仓库 git add readme.txt 然后提交 git commit -m &quot;some message&quot; 查看一段时间内文件的修改内容 git diff 查看当前的状态,是否有未提交的内容 git status 提交修改的内容和添加新文件方法一致 `git add &lt;file&gt;,git commit -m &quot;some msg&quot; 查看操作的历史记录 git log 可以使用参数 --pretty=oneline 使输出信息变得简洁 版本回退: 回退到上一个版本 git reset --hard HEAD^ 回退几个版本就加几个 ^ 可以用数字代替 回退100次 git reset --hard HEAD~100 回到未来的版本 需要知道提交时的commit id 然后使用 git reset --hard &quot;commit id&quot; 如果没有了commit id 可以使用 git reflog 查看历史的每一次记录 撤销修改 撤销工作区的修改 git checkout -- file 例如: git checkout -- readme.txt 撤销暂存区的修改 git reset HEAD file 就会撤销暂存区的修改,但是内容会回到工作区,需要再撤销工作区的修改 删除修改 直接区目录下删除 或者用命令 rm file git rm file git commit 就删除了 如果删错了,使用 git checkout -- readme.txt 就可以了 git checkout 其实是用版本库里的版本替换工作区的版本，无论工作区是修改还是删除，都可以“一键还原” 密钥管理 密钥管理工具 ssh-agent 的使用 ssh-add -D 删除所有管理的密钥 ssh-add -d 删除指定的 ssh-add -l 查看现在增加进去的指纹信息 ssh-add -L 查看现在增加进去的私钥 如果重启之后，会发现需要重新load一下ssh-agent ssh-add -K 将指纹加到钥匙串里面去 ssh-add -A 可以把钥匙串里面的私钥密码，load进ssh-agent 推送到github 在github端创建一个新的仓库,也在本地建一个仓库 git init 将本地的仓库和远程仓库关联起来 git remote add origin git@github.com:zonzie/zonzie.github.io.git 添加后，远程库的名字就是origin，这是Git默认的叫法，也可以改成别的，但是origin这个名字一看就知道是远程库。 将本地库的内容推送到远程库 git push -u origin master 实际上是把当前分支master推送到远程 由于远程库是空的，我们第一次推送master分支时，加上了-u参数，Git不但会把本地的master分支内容推送的远程新的master分支，还会把本地的master分支和远程的master分支关联起来，在以后的推送或者拉取时就可以简化命令 现在起 只要本地做了提交,就可以通过命令,把把本地master分支的最新修改推送至GitHub git push origin master 克隆 使用 git clone 命令 git clone 项目地址git clone git@github.com:zonzie/zonzie.github.io.git 修改后推送到远程仓库git push 更新本地仓库git pull 分支管理 创建一个分支git checkout -b dev 加上-b表示创建并且切换到新的分支,相当于以下两条命令git branch dev,git checkout dev 查看所有的分支git branch 合并分支 git merge xxx 合并xxx分支到当前分支 是快进模式,合并速度非常快 删除分支 git branch -d xxx 删除xxx分支 删除远程分支 xxx git push origin --delete xxx 解决冲突 git merge xxx 合并分支后,可能出现冲突 需要手动修改冲突文件,再提交–冲突解决 使用git log查看分支的合并情况或者git log --graph 合并分支,禁用fast forward模式(默认)–删除分支后,任然保留分支信息 合并时使用命令 git merge --no-ff xxx 表示禁用fast forward模式,合并xxx分支到当前分支 推送分支 命令 git push origin master 推送到dev分支,就改成 git push origin dev 放弃本地修改,强制拉取更新 git fetch 指令是下载远程仓库最新内容，不做合并 git reset 指令把HEAD指向master最新版本 步骤: git fetch --all git reset --hard origin/master git pull //可以省略 新建远程分支 先创建一个本地的分支 git checkout -b newBranch 推送本地分支到远程,远程分支也叫newBranch,可以是别的 git push origin newBranch:newBranch 删除远程分支 可以推送空的分支到远程分支,就可以删除远程分支 git push origin :newBranch 也可以直接删除远程分支 git push origin --delete newBranch 其他 修改commit: git commit --amend, 如果要修改已push到远端的commit, 只能强制推送git push --force one_branch 合并commit记录: 123git reset --soft "HEAD~n"# -n means ~1, ~2 ...git commit --amend 快速解决冲突 12345# 全部使用别人的git pull -X theirsgit checkout --theirs path/to/file# 使用自己的git pull -X ours 批量删除tag 123git tag -d TAG1 TAG2 TAG3# delete remove taggit push REMOTE --delete TAG1 TAG2 TAG3]]></content>
      <categories>
        <category>git</category>
      </categories>
      <tags>
        <tag>git</tag>
      </tags>
  </entry>
</search>
